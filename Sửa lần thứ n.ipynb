{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5a2bf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số mã HOSE: 415\n",
      "Fetching data, it may take a while. Please wait...\n",
      "History ban đầu:   ticker         timestamp      open      high       low     close     volume  \\\n",
      "0    AAA  2023-01-03 00:00  6539.643  6866.145  6539.643  6866.145  1543984.0   \n",
      "1    AAA  2023-01-04 00:00  6866.145  7000.587  6827.733  6827.733  1302505.0   \n",
      "2    AAA  2023-01-05 00:00  6866.145  6904.557  6808.527  6885.351   980473.0   \n",
      "3    AAA  2023-01-06 00:00  6885.351  6990.984  6818.130  6856.542  1431699.0   \n",
      "4    AAA  2023-01-09 00:00  6914.160  6962.175  6760.512  6789.321  1121385.0   \n",
      "\n",
      "         bu        sd           fs           fn  \n",
      "0  938600.0  504700.0   40579000.0  899404000.0  \n",
      "1  462900.0  780600.0  151639000.0   36850000.0  \n",
      "2  487200.0  473700.0  343911000.0  -59103000.0  \n",
      "3  564300.0  828300.0  345999000.0 -294312000.0  \n",
      "4  414000.0  631800.0  514557000.0 -483197000.0  \n"
     ]
    }
   ],
   "source": [
    "# Block 1 — Login & Lấy dữ liệu tất cả HOSE/HNX/UPCOM\n",
    "import pandas as pd\n",
    "from FiinQuantX import FiinSession, BarDataUpdate\n",
    "\n",
    "# --- Login ---\n",
    "username = \"DSTC_18@fiinquant.vn\"\n",
    "password = \"Fiinquant0606\"\n",
    "\n",
    "client = FiinSession(\n",
    "    username=username,\n",
    "    password=password\n",
    ").login()\n",
    "\n",
    "# --- Lấy danh sách cổ phiếu từng sàn ---\n",
    "tickers_hose  = list(client.TickerList(ticker=\"VNINDEX\"))     # HOSE\n",
    "print(f\"Số mã HOSE: {len(tickers_hose)}\")\n",
    "\n",
    "# --- Lấy dữ liệu lịch sử toàn bộ (có thể nặng, nên lấy theo batch nếu cần) ---\n",
    "event_history = client.Fetch_Trading_Data(\n",
    "    realtime=False,\n",
    "    tickers=tickers_hose,\n",
    "    fields=['open','high','low','close','volume','bu','sd','fs','fn'], \n",
    "    adjusted=True,\n",
    "    by=\"1d\",\n",
    "    from_date=\"2023-01-01\"   # backtest từ 2023 tới nay\n",
    ")\n",
    "\n",
    "df_all = event_history.get_data()\n",
    "print(\"History ban đầu:\", df_all.head())\n",
    "\n",
    "# --- Callback realtime ---\n",
    "def onDataUpdate(data: BarDataUpdate):\n",
    "    global df_all\n",
    "    df_update = data.to_dataFrame()\n",
    "    df_all = pd.concat([df_all, df_update])\n",
    "    df_all = df_all.drop_duplicates()\n",
    "    print(\"Realtime update:\")\n",
    "    print(df_update.head())\n",
    "\n",
    "# --- Bật realtime nối tiếp dữ liệu ---\n",
    "event_realtime = client.Fetch_Trading_Data(\n",
    "    realtime=True,\n",
    "    tickers=tickers_hose,\n",
    "    fields=['open','high','low','close','volume','bu','sd','fs','fn'], \n",
    "    adjusted=True,\n",
    "    by=\"1d\",\n",
    "    period=1,\n",
    "    callback=onDataUpdate\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c93b463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Lỗi khi lấy FA cho FUETPVND: 'FUETPVND'\n",
      "Số mã HOSE ban đầu: 415\n",
      "Số mã có dữ liệu FA: 392\n",
      "FA Data sample:\n",
      "   organizationId ticker  year  quarter  \\\n",
      "0          894364    CCC  2023        4   \n",
      "1          894364    CCC  2024        1   \n",
      "2          894364    CCC  2024        2   \n",
      "3          894364    CCC  2024        3   \n",
      "4          894364    CCC  2024        4   \n",
      "\n",
      "                                              ratios ReportDate  \n",
      "0  {'SolvencyRatio': {'DebtToEquityRatio': 1.5102...        NaT  \n",
      "1  {'SolvencyRatio': {'DebtToEquityRatio': 0.7722...        NaT  \n",
      "2  {'SolvencyRatio': {'DebtToEquityRatio': 0.7357...        NaT  \n",
      "3  {'SolvencyRatio': {'DebtToEquityRatio': 0.7914...        NaT  \n",
      "4  {'SolvencyRatio': {'DebtToEquityRatio': 0.6437...        NaT  \n"
     ]
    }
   ],
   "source": [
    "# Block 2 — Lấy dữ liệu FA theo quý (HOSE only)\n",
    "\n",
    "def fetch_fa_quarterly(ticker, latest_year=2025, n_periods=32):\n",
    "    try:\n",
    "        fi_list = client.FundamentalAnalysis().get_ratios(\n",
    "            tickers=[ticker],\n",
    "            TimeFilter=\"Quarterly\",\n",
    "            LatestYear=latest_year,\n",
    "            NumberOfPeriod=n_periods,\n",
    "            Consolidated=True\n",
    "        )\n",
    "\n",
    "        # Nếu không có dữ liệu thì bỏ qua\n",
    "        if not fi_list or not isinstance(fi_list, list):\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        df = pd.DataFrame(fi_list)\n",
    "        if df.empty:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        df[\"ticker\"] = ticker\n",
    "        if \"ReportDate\" in df.columns:\n",
    "            df[\"ReportDate\"] = pd.to_datetime(df[\"ReportDate\"])\n",
    "        else:\n",
    "            # Nếu không có ReportDate thì tạo cột null để tránh lỗi concat\n",
    "            df[\"ReportDate\"] = pd.NaT\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Lỗi khi lấy FA cho {ticker}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "# --- Lọc danh sách: chỉ giữ những mã có dữ liệu FA ---\n",
    "fa_list = []\n",
    "valid_tickers = []\n",
    "\n",
    "for t in tickers_hose:   # lấy theo danh sách HOSE từ Block 1\n",
    "    df_fa = fetch_fa_quarterly(t, latest_year=2025, n_periods=32)\n",
    "    if not df_fa.empty:\n",
    "        fa_list.append(df_fa)\n",
    "        valid_tickers.append(t)\n",
    "\n",
    "# --- Gộp DataFrame ---\n",
    "if fa_list:\n",
    "    fa_data = pd.concat(fa_list, ignore_index=True)\n",
    "else:\n",
    "    fa_data = pd.DataFrame()\n",
    "\n",
    "print(f\"Số mã HOSE ban đầu: {len(tickers_hose)}\")\n",
    "print(f\"Số mã có dữ liệu FA: {len(valid_tickers)}\")\n",
    "print(\"FA Data sample:\")\n",
    "print(fa_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "831a3096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample merged:\n",
      "  ticker  timestamp      open      high       low     close     volume  \\\n",
      "0    AAA 2023-01-03  6539.643  6866.145  6539.643  6866.145  1543984.0   \n",
      "1    AAA 2023-01-04  6866.145  7000.587  6827.733  6827.733  1302505.0   \n",
      "2    AAA 2023-01-05  6866.145  6904.557  6808.527  6885.351   980473.0   \n",
      "3    AAA 2023-01-06  6885.351  6990.984  6818.130  6856.542  1431699.0   \n",
      "4    AAA 2023-01-09  6914.160  6962.175  6760.512  6789.321  1121385.0   \n",
      "\n",
      "         bu        sd           fs  ...  DebtToEquityRatio  EBITMargin  \\\n",
      "0  938600.0  504700.0   40579000.0  ...           0.507521   -0.049731   \n",
      "1  462900.0  780600.0  151639000.0  ...           0.507521   -0.049731   \n",
      "2  487200.0  473700.0  343911000.0  ...           0.507521   -0.049731   \n",
      "3  564300.0  828300.0  345999000.0  ...           0.507521   -0.049731   \n",
      "4  414000.0  631800.0  514557000.0  ...           0.507521   -0.049731   \n",
      "\n",
      "        ROA       ROE      ROIC    BasicEPS  PriceToBook  PriceToEarning  \\\n",
      "0  0.014669  0.029589  0.014784 -255.644791     0.737556       24.741322   \n",
      "1  0.014669  0.029589  0.014784 -255.644791     0.737556       24.741322   \n",
      "2  0.014669  0.029589  0.014784 -255.644791     0.737556       24.741322   \n",
      "3  0.014669  0.029589  0.014784 -255.644791     0.737556       24.741322   \n",
      "4  0.014669  0.029589  0.014784 -255.644791     0.737556       24.741322   \n",
      "\n",
      "   NetRevenueGrowthYoY  GrossProfitGrowthYoY  \n",
      "0             -0.18869             -0.910016  \n",
      "1             -0.18869             -0.910016  \n",
      "2             -0.18869             -0.910016  \n",
      "3             -0.18869             -0.910016  \n",
      "4             -0.18869             -0.910016  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "Số mã merge thành công: 391\n"
     ]
    }
   ],
   "source": [
    "# Block 3 — Chuẩn hoá FA + Merge với giá (HOSE only, dựa theo Block 2)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# --- Các chỉ số FA cần lấy ---\n",
    "fa_fields = [\n",
    "    \"DebtToEquityRatio\",\"EBITMargin\",\"ROA\",\"ROE\",\"ROIC\",\n",
    "    \"BasicEPS\",\"PriceToBook\",\"PriceToEarning\",\n",
    "    \"NetRevenueGrowthYoY\",\"GrossProfitGrowthYoY\"\n",
    "]\n",
    "\n",
    "# --- Hàm nổ ratios ---\n",
    "def explode_ratios(df, fa_fields):\n",
    "    records = []\n",
    "    for _, row in df.iterrows():\n",
    "        d = {\n",
    "            \"ticker\": row[\"ticker\"],\n",
    "            \"fa_year\": int(row[\"year\"]),\n",
    "            \"fa_quarter\": int(row[\"quarter\"])\n",
    "        }\n",
    "        ratios = row.get(\"ratios\", {})\n",
    "        if isinstance(ratios, dict):   # ✅ fix chỗ lỗi\n",
    "            for f in fa_fields:\n",
    "                val = None\n",
    "                for section in ratios.values():\n",
    "                    if isinstance(section, dict) and f in section:\n",
    "                        val = section[f]\n",
    "                d[f] = val\n",
    "        else:\n",
    "            # nếu ratios không phải dict thì gán NaN hết\n",
    "            for f in fa_fields:\n",
    "                d[f] = None\n",
    "        records.append(d)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# --- Chuẩn hoá FA ---\n",
    "fa_clean = explode_ratios(fa_data, fa_fields)\n",
    "\n",
    "# --- Chuẩn hoá giá ---\n",
    "df_price = df_all[df_all[\"ticker\"].isin(valid_tickers)].copy()\n",
    "df_price[\"timestamp\"] = pd.to_datetime(df_price[\"timestamp\"])\n",
    "df_price = df_price.sort_values([\"ticker\",\"timestamp\"])\n",
    "\n",
    "# tạo key (fa_year, fa_quarter) = quý trước\n",
    "pi = df_price[\"timestamp\"].dt.to_period(\"Q\")\n",
    "prev_pi = pi - 1\n",
    "df_price[\"fa_year\"] = prev_pi.dt.year.astype(int)\n",
    "df_price[\"fa_quarter\"] = prev_pi.dt.quarter.astype(int)\n",
    "\n",
    "# --- Xử lý FA: giữ duy nhất bản cuối cùng mỗi quý\n",
    "fa_clean = (\n",
    "    fa_clean.sort_values([\"ticker\",\"fa_year\",\"fa_quarter\"])\n",
    "            .drop_duplicates(subset=[\"ticker\",\"fa_year\",\"fa_quarter\"], keep=\"last\")\n",
    ")\n",
    "\n",
    "# --- Merge giá + FA ---\n",
    "df_merged = df_price.merge(\n",
    "    fa_clean,\n",
    "    on=[\"ticker\",\"fa_year\",\"fa_quarter\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# FFill theo thời gian trong từng ticker để lấp chỗ trống\n",
    "df_merged = df_merged.sort_values([\"ticker\",\"timestamp\"])\n",
    "df_merged[fa_fields] = df_merged.groupby(\"ticker\")[fa_fields].ffill()\n",
    "\n",
    "print(\"Sample merged:\")\n",
    "print(df_merged.head())\n",
    "print(\"Số mã merge thành công:\", df_merged[\"ticker\"].nunique())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73580df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del df_all\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b0de3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample with TA:\n",
      "  ticker  timestamp      open      high       low     close     volume  \\\n",
      "0    AAA 2023-01-03  6539.643  6866.145  6539.643  6866.145  1543984.0   \n",
      "1    AAA 2023-01-04  6866.145  7000.587  6827.733  6827.733  1302505.0   \n",
      "2    AAA 2023-01-05  6866.145  6904.557  6808.527  6885.351   980473.0   \n",
      "3    AAA 2023-01-06  6885.351  6990.984  6818.130  6856.542  1431699.0   \n",
      "4    AAA 2023-01-09  6914.160  6962.175  6760.512  6789.321  1121385.0   \n",
      "\n",
      "         bu        sd           fs  ...  ema_50  macd  macd_signal  macd_diff  \\\n",
      "0  938600.0  504700.0   40579000.0  ...     NaN   NaN          NaN        NaN   \n",
      "1  462900.0  780600.0  151639000.0  ...     NaN   NaN          NaN        NaN   \n",
      "2  487200.0  473700.0  343911000.0  ...     NaN   NaN          NaN        NaN   \n",
      "3  564300.0  828300.0  345999000.0  ...     NaN   NaN          NaN        NaN   \n",
      "4  414000.0  631800.0  514557000.0  ...     NaN   NaN          NaN        NaN   \n",
      "\n",
      "   rsi  bollinger_hband  bollinger_lband  atr        obv  vwap  \n",
      "0  NaN              NaN              NaN  NaN  1543984.0   NaN  \n",
      "1  NaN              NaN              NaN  NaN   241479.0   NaN  \n",
      "2  NaN              NaN              NaN  NaN  1221952.0   NaN  \n",
      "3  NaN              NaN              NaN  NaN  -209747.0   NaN  \n",
      "4  NaN              NaN              NaN  NaN -1331132.0   NaN  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "Shape sau khi thêm TA: (256151, 35)\n"
     ]
    }
   ],
   "source": [
    "# Block 4 — Tính các chỉ số TA (trên df_merged từ Block 3)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# --- Khởi tạo Indicator ---\n",
    "fi = client.FiinIndicator()\n",
    "\n",
    "# --- Hàm tính TA theo từng ticker ---\n",
    "def add_ta_indicators(df):\n",
    "    df = df.sort_values(\"timestamp\").copy()\n",
    "\n",
    "    # EMA\n",
    "    df['ema_5']  = fi.ema(df['close'], window=5)\n",
    "    df['ema_20'] = fi.ema(df['close'], window=20)\n",
    "    df['ema_50'] = fi.ema(df['close'], window=50)\n",
    "\n",
    "    # MACD\n",
    "    df['macd']        = fi.macd(df['close'], window_fast=12, window_slow=26)\n",
    "    df['macd_signal'] = fi.macd_signal(df['close'], window_fast=12, window_slow=26, window_sign=9)\n",
    "    df['macd_diff']   = fi.macd_diff(df['close'], window_fast=12, window_slow=26, window_sign=9)\n",
    "\n",
    "    # RSI\n",
    "    df['rsi'] = fi.rsi(df['close'], window=14)\n",
    "\n",
    "    # Bollinger Bands\n",
    "    df['bollinger_hband'] = fi.bollinger_hband(df['close'], window=20, window_dev=2)\n",
    "    df['bollinger_lband'] = fi.bollinger_lband(df['close'], window=20, window_dev=2)\n",
    "\n",
    "    # ATR\n",
    "    df['atr'] = fi.atr(df['high'], df['low'], df['close'], window=14)\n",
    "\n",
    "    # OBV\n",
    "    df['obv'] = fi.obv(df['close'], df['volume'])\n",
    "\n",
    "    # VWAP\n",
    "    df['vwap'] = fi.vwap(df['high'], df['low'], df['close'], df['volume'], window=14)\n",
    "\n",
    "    return df\n",
    "\n",
    "# --- Áp dụng cho toàn bộ df_merged ---\n",
    "df_with_ta = df_merged.groupby(\"ticker\", group_keys=False).apply(add_ta_indicators)\n",
    "\n",
    "print(\"Sample with TA:\")\n",
    "print(df_with_ta.head())\n",
    "print(\"Shape sau khi thêm TA:\", df_with_ta.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26204a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del df_merged\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbd7f105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample features:\n",
      "  ticker  timestamp  DebtToEquityRatio  EBITMargin       ROA       ROE  \\\n",
      "0    AAA 2023-06-14           0.559115    0.978956  0.368731  0.415728   \n",
      "1    AAA 2023-06-15           0.559115    0.978956  0.368731  0.415728   \n",
      "2    AAA 2023-06-16           0.559115    0.978956  0.368731  0.415728   \n",
      "3    AAA 2023-06-19           0.559115    0.978956  0.368731  0.415728   \n",
      "4    AAA 2023-06-20           0.559115    0.978956  0.368731  0.415728   \n",
      "\n",
      "     ROIC  BasicEPS  PriceToBook  PriceToEarning  ...  ema_50_z    macd_z  \\\n",
      "0  0.7533  0.158046      0.37764        0.537353  ...  1.799046 -0.008320   \n",
      "1  0.7533  0.158046      0.37764        0.537353  ...  1.761009 -0.314808   \n",
      "2  0.7533  0.158046      0.37764        0.537353  ...  1.701399 -0.891565   \n",
      "3  0.7533  0.158046      0.37764        0.537353  ...  1.651219 -1.278916   \n",
      "4  0.7533  0.158046      0.37764        0.537353  ...  1.609327 -1.509982   \n",
      "\n",
      "   macd_signal_z  macd_diff_z     rsi_z  bollinger_hband_z  bollinger_lband_z  \\\n",
      "0       0.591579    -1.164222 -1.530688           1.363061           1.839777   \n",
      "1       0.399630    -1.467105 -1.541599           1.317089           1.758209   \n",
      "2       0.112479    -2.139400 -2.893380           1.289737           1.634182   \n",
      "3      -0.209795    -2.311526 -2.429426           1.248184           1.569059   \n",
      "4      -0.526222    -2.190019 -2.020537           1.199384           1.537532   \n",
      "\n",
      "      atr_z     obv_z    vwap_z  \n",
      "0  0.589827  1.405288  1.603355  \n",
      "1  0.534358  1.364100  1.554836  \n",
      "2  0.710743  0.982966  1.479150  \n",
      "3  0.593083  1.154836  1.414003  \n",
      "4  0.484151  1.326566  1.346550  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "Shape sau khi scaling & dropna: (181828, 24)\n"
     ]
    }
   ],
   "source": [
    "# Block 5 — Feature engineering & scaling\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# --- Danh sách cột FA & TA ---\n",
    "fa_features = [\n",
    "    \"DebtToEquityRatio\",\"EBITMargin\",\"ROA\",\"ROE\",\"ROIC\",\n",
    "    \"BasicEPS\",\"PriceToBook\",\"PriceToEarning\",\n",
    "    \"NetRevenueGrowthYoY\",\"GrossProfitGrowthYoY\"\n",
    "]\n",
    "\n",
    "ta_features = [\n",
    "    \"ema_5\",\"ema_20\",\"ema_50\",\"macd\",\"macd_signal\",\"macd_diff\",\n",
    "    \"rsi\",\"bollinger_hband\",\"bollinger_lband\",\"atr\",\"obv\",\"vwap\"\n",
    "]\n",
    "\n",
    "# --- Chuẩn hoá FA: cross-section min-max scaling theo ngày ---\n",
    "def scale_fa_minmax(df):\n",
    "    df_scaled = df.copy()\n",
    "    for f in fa_features:\n",
    "        vals = df[f].astype(float)\n",
    "        vmin, vmax = vals.min(), vals.max()\n",
    "        if np.isfinite(vmin) and np.isfinite(vmax) and vmax > vmin:\n",
    "            df_scaled[f] = (vals - vmin) / (vmax - vmin)\n",
    "        else:\n",
    "            df_scaled[f] = np.nan\n",
    "    return df_scaled\n",
    "\n",
    "df_scaled_fa = df_with_ta.groupby(\"timestamp\", group_keys=False).apply(scale_fa_minmax)\n",
    "\n",
    "# --- Chuẩn hoá TA: rolling z-score theo từng ticker ---\n",
    "def zscore_rolling(series, window=60):\n",
    "    return (series - series.rolling(window).mean()) / series.rolling(window).std()\n",
    "\n",
    "df_scaled = df_scaled_fa.groupby(\"ticker\", group_keys=False).apply(\n",
    "    lambda g: g.assign(**{f\"{col}_z\": zscore_rolling(g[col], 60) for col in ta_features})\n",
    ")\n",
    "\n",
    "# --- Drop các cột gốc TA, giữ bản z-score ---\n",
    "keep_cols = [\"ticker\",\"timestamp\"] + fa_features + [f\"{col}_z\" for col in ta_features]\n",
    "df_features = df_scaled[keep_cols].dropna().reset_index(drop=True)\n",
    "\n",
    "print(\"Sample features:\")\n",
    "print(df_features.head())\n",
    "print(\"Shape sau khi scaling & dropna:\", df_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fee3d19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_with_ta, df_scaled, df_scaled_fa\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "466d47e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster sample:\n",
      "  ticker  timestamp  cluster     tsne_x     tsne_y    month\n",
      "0    AAA 2023-06-14       -1  34.417667 -21.641058  2023-06\n",
      "1    AAA 2023-06-15       -1  34.361568 -21.848602  2023-06\n",
      "2    AAA 2023-06-16       -1  35.918636 -42.906532  2023-06\n",
      "3    AAA 2023-06-19       -1  35.490566 -42.649422  2023-06\n",
      "4    AAA 2023-06-20       -1  34.553066 -42.459969  2023-06\n",
      "Số cụm mỗi tháng:\n",
      "month\n",
      "2023-06     16\n",
      "2023-07     65\n",
      "2023-08     80\n",
      "2023-09     39\n",
      "2023-10     82\n",
      "2023-11     55\n",
      "2023-12     84\n",
      "2024-01     83\n",
      "2024-02     33\n",
      "2024-03     66\n",
      "2024-04     44\n",
      "2024-05     67\n",
      "2024-06     92\n",
      "2024-07     88\n",
      "2024-08     65\n",
      "2024-09     88\n",
      "2024-10    107\n",
      "2024-11     77\n",
      "2024-12     71\n",
      "2025-01     48\n",
      "2025-02     70\n",
      "2025-03     92\n",
      "2025-04     51\n",
      "2025-05     76\n",
      "2025-06     96\n",
      "2025-07    109\n",
      "2025-08     72\n",
      "Name: cluster, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Block 6 — Dimensionality reduction & Clustering (t-SNE + DBSCAN)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# --- Chọn các cột features để clustering ---\n",
    "feature_cols = [\n",
    "    \"DebtToEquityRatio\",\"EBITMargin\",\"ROA\",\"ROE\",\"ROIC\",\n",
    "    \"BasicEPS\",\"PriceToBook\",\"PriceToEarning\",\n",
    "    \"NetRevenueGrowthYoY\",\"GrossProfitGrowthYoY\"\n",
    "] + [c for c in df_features.columns if c.endswith(\"_z\")]\n",
    "\n",
    "# --- Thêm cột tháng để snapshot ---\n",
    "df_features[\"month\"] = df_features[\"timestamp\"].dt.to_period(\"M\")\n",
    "\n",
    "cluster_results = []\n",
    "\n",
    "for (month, g) in df_features.groupby(\"month\"):\n",
    "    if len(g) < 10:   # quá ít cổ phiếu thì bỏ\n",
    "        continue\n",
    "\n",
    "    X = g[feature_cols].values\n",
    "\n",
    "    # --- t-SNE giảm chiều còn 2D ---\n",
    "    tsne = TSNE(n_components=2, perplexity=30, learning_rate=\"auto\", init=\"random\", random_state=42)\n",
    "    X_emb = tsne.fit_transform(X)\n",
    "\n",
    "    # --- DBSCAN clustering ---\n",
    "    db = DBSCAN(eps=0.5, min_samples=5).fit(X_emb)\n",
    "    labels = db.labels_\n",
    "\n",
    "    temp = g[[\"ticker\",\"timestamp\"]].copy()\n",
    "    temp[\"cluster\"] = labels\n",
    "    temp[\"tsne_x\"] = X_emb[:,0]\n",
    "    temp[\"tsne_y\"] = X_emb[:,1]\n",
    "    temp[\"month\"]  = str(month)\n",
    "\n",
    "    cluster_results.append(temp)\n",
    "\n",
    "df_clusters = pd.concat(cluster_results, ignore_index=True)\n",
    "\n",
    "print(\"Cluster sample:\")\n",
    "print(df_clusters.head())\n",
    "print(\"Số cụm mỗi tháng:\")\n",
    "print(df_clusters.groupby(\"month\")[\"cluster\"].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68a62783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: tensor (490, 64, 21, 22), mask (490, 64, 21, 22) saved.\n",
      "Cluster 1: tensor (490, 64, 14, 22), mask (490, 64, 14, 22) saved.\n",
      "Cluster 2: tensor (490, 64, 15, 22), mask (490, 64, 15, 22) saved.\n",
      "Cluster 3: tensor (490, 64, 15, 22), mask (490, 64, 15, 22) saved.\n",
      "Cluster 4: tensor (490, 64, 22, 22), mask (490, 64, 22, 22) saved.\n",
      "Cluster 5: tensor (490, 64, 23, 22), mask (490, 64, 23, 22) saved.\n",
      "Cluster 6: tensor (490, 64, 23, 22), mask (490, 64, 23, 22) saved.\n",
      "Cluster 7: tensor (490, 64, 26, 22), mask (490, 64, 26, 22) saved.\n",
      "Cluster 8: tensor (490, 64, 20, 22), mask (490, 64, 20, 22) saved.\n",
      "Cluster 9: tensor (490, 64, 21, 22), mask (490, 64, 21, 22) saved.\n",
      "Cluster 10: tensor (490, 64, 23, 22), mask (490, 64, 23, 22) saved.\n",
      "Cluster 11: tensor (490, 64, 23, 22), mask (490, 64, 23, 22) saved.\n",
      "Cluster 12: tensor (490, 64, 29, 22), mask (490, 64, 29, 22) saved.\n",
      "Cluster 13: tensor (490, 64, 21, 22), mask (490, 64, 21, 22) saved.\n",
      "Cluster 14: tensor (490, 64, 24, 22), mask (490, 64, 24, 22) saved.\n",
      "Cluster 15: tensor (490, 64, 25, 22), mask (490, 64, 25, 22) saved.\n",
      "Cluster 16: tensor (490, 64, 28, 22), mask (490, 64, 28, 22) saved.\n",
      "Cluster 17: tensor (490, 64, 26, 22), mask (490, 64, 26, 22) saved.\n",
      "Cluster 18: tensor (490, 64, 22, 22), mask (490, 64, 22, 22) saved.\n",
      "Cluster 19: tensor (490, 64, 24, 22), mask (490, 64, 24, 22) saved.\n",
      "Cluster 20: tensor (490, 64, 24, 22), mask (490, 64, 24, 22) saved.\n",
      "Cluster 21: tensor (490, 64, 25, 22), mask (490, 64, 25, 22) saved.\n",
      "Cluster 22: tensor (490, 64, 24, 22), mask (490, 64, 24, 22) saved.\n",
      "Cluster 23: tensor (490, 64, 25, 22), mask (490, 64, 25, 22) saved.\n",
      "Cluster 24: tensor (490, 64, 24, 22), mask (490, 64, 24, 22) saved.\n",
      "Cluster 25: tensor (490, 64, 26, 22), mask (490, 64, 26, 22) saved.\n",
      "Cluster 26: tensor (490, 64, 26, 22), mask (490, 64, 26, 22) saved.\n",
      "Cluster 27: tensor (490, 64, 30, 22), mask (490, 64, 30, 22) saved.\n",
      "Cluster 28: tensor (490, 64, 23, 22), mask (490, 64, 23, 22) saved.\n",
      "Cluster 29: tensor (490, 64, 25, 22), mask (490, 64, 25, 22) saved.\n",
      "Cluster 30: tensor (490, 64, 27, 22), mask (490, 64, 27, 22) saved.\n",
      "Cluster 31: tensor (490, 64, 27, 22), mask (490, 64, 27, 22) saved.\n",
      "Cluster 32: tensor (490, 64, 21, 22), mask (490, 64, 21, 22) saved.\n",
      "Cluster 33: tensor (490, 64, 23, 22), mask (490, 64, 23, 22) saved.\n",
      "Cluster 34: tensor (490, 64, 25, 22), mask (490, 64, 25, 22) saved.\n",
      "Cluster 35: tensor (490, 64, 26, 22), mask (490, 64, 26, 22) saved.\n",
      "Cluster 36: tensor (490, 64, 25, 22), mask (490, 64, 25, 22) saved.\n",
      "Cluster 37: tensor (490, 64, 28, 22), mask (490, 64, 28, 22) saved.\n",
      "Cluster 38: tensor (490, 64, 23, 22), mask (490, 64, 23, 22) saved.\n",
      "Cluster 39: tensor (490, 64, 24, 22), mask (490, 64, 24, 22) saved.\n",
      "Cluster 40: tensor (490, 64, 27, 22), mask (490, 64, 27, 22) saved.\n",
      "Cluster 41: tensor (490, 64, 24, 22), mask (490, 64, 24, 22) saved.\n",
      "Cluster 42: tensor (490, 64, 23, 22), mask (490, 64, 23, 22) saved.\n",
      "Cluster 43: tensor (490, 64, 25, 22), mask (490, 64, 25, 22) saved.\n",
      "Cluster 44: tensor (490, 64, 24, 22), mask (490, 64, 24, 22) saved.\n",
      "Cluster 45: tensor (490, 64, 23, 22), mask (490, 64, 23, 22) saved.\n",
      "Cluster 46: tensor (490, 64, 28, 22), mask (490, 64, 28, 22) saved.\n",
      "Cluster 47: tensor (490, 64, 21, 22), mask (490, 64, 21, 22) saved.\n",
      "Cluster 48: tensor (490, 64, 22, 22), mask (490, 64, 22, 22) saved.\n",
      "Cluster 49: tensor (490, 64, 21, 22), mask (490, 64, 21, 22) saved.\n",
      "Cluster 50: tensor (490, 64, 24, 22), mask (490, 64, 24, 22) saved.\n",
      "Cluster 51: tensor (490, 64, 23, 22), mask (490, 64, 23, 22) saved.\n",
      "Cluster 52: tensor (490, 64, 22, 22), mask (490, 64, 22, 22) saved.\n",
      "Cluster 53: tensor (490, 64, 22, 22), mask (490, 64, 22, 22) saved.\n",
      "Cluster 54: tensor (490, 64, 19, 22), mask (490, 64, 19, 22) saved.\n",
      "Cluster 55: tensor (490, 64, 17, 22), mask (490, 64, 17, 22) saved.\n",
      "Cluster 56: tensor (490, 64, 20, 22), mask (490, 64, 20, 22) saved.\n",
      "Cluster 57: tensor (490, 64, 22, 22), mask (490, 64, 22, 22) saved.\n",
      "Cluster 58: tensor (490, 64, 21, 22), mask (490, 64, 21, 22) saved.\n",
      "Cluster 59: tensor (490, 64, 21, 22), mask (490, 64, 21, 22) saved.\n",
      "Cluster 60: tensor (490, 64, 20, 22), mask (490, 64, 20, 22) saved.\n",
      "Cluster 61: tensor (490, 64, 19, 22), mask (490, 64, 19, 22) saved.\n",
      "Cluster 62: tensor (490, 64, 19, 22), mask (490, 64, 19, 22) saved.\n",
      "Cluster 63: tensor (490, 64, 22, 22), mask (490, 64, 22, 22) saved.\n",
      "Cluster 64: tensor (490, 64, 15, 22), mask (490, 64, 15, 22) saved.\n",
      "Cluster 65: tensor (490, 64, 18, 22), mask (490, 64, 18, 22) saved.\n",
      "Cluster 66: tensor (490, 64, 16, 22), mask (490, 64, 16, 22) saved.\n",
      "Cluster 67: tensor (490, 64, 17, 22), mask (490, 64, 17, 22) saved.\n",
      "Cluster 68: tensor (490, 64, 16, 22), mask (490, 64, 16, 22) saved.\n",
      "Cluster 69: tensor (490, 64, 14, 22), mask (490, 64, 14, 22) saved.\n",
      "Cluster 70: tensor (490, 64, 14, 22), mask (490, 64, 14, 22) saved.\n",
      "Cluster 71: tensor (490, 64, 12, 22), mask (490, 64, 12, 22) saved.\n",
      "Cluster 72: tensor (490, 64, 14, 22), mask (490, 64, 14, 22) saved.\n",
      "Cluster 73: tensor (490, 64, 14, 22), mask (490, 64, 14, 22) saved.\n",
      "Cluster 74: tensor (490, 64, 14, 22), mask (490, 64, 14, 22) saved.\n",
      "Cluster 75: tensor (490, 64, 15, 22), mask (490, 64, 15, 22) saved.\n",
      "Cluster 76: tensor (490, 64, 10, 22), mask (490, 64, 10, 22) saved.\n",
      "Cluster 77: tensor (490, 64, 11, 22), mask (490, 64, 11, 22) saved.\n",
      "Cluster 78: tensor (490, 64, 11, 22), mask (490, 64, 11, 22) saved.\n",
      "Cluster 79: tensor (490, 64, 11, 22), mask (490, 64, 11, 22) saved.\n",
      "Cluster 80: tensor (490, 64, 10, 22), mask (490, 64, 10, 22) saved.\n",
      "Cluster 81: tensor (490, 64, 9, 22), mask (490, 64, 9, 22) saved.\n",
      "Cluster 82: tensor (490, 64, 11, 22), mask (490, 64, 11, 22) saved.\n",
      "Cluster 83: tensor (490, 64, 7, 22), mask (490, 64, 7, 22) saved.\n",
      "Cluster 84: tensor (490, 64, 7, 22), mask (490, 64, 7, 22) saved.\n",
      "Cluster 85: tensor (490, 64, 6, 22), mask (490, 64, 6, 22) saved.\n",
      "Cluster 86: tensor (490, 64, 9, 22), mask (490, 64, 9, 22) saved.\n",
      "Cluster 87: tensor (490, 64, 5, 22), mask (490, 64, 5, 22) saved.\n",
      "Cluster 88: tensor (490, 64, 5, 22), mask (490, 64, 5, 22) saved.\n",
      "Cluster 89: tensor (490, 64, 5, 22), mask (490, 64, 5, 22) saved.\n",
      "Cluster 90: tensor (490, 64, 4, 22), mask (490, 64, 4, 22) saved.\n",
      "Cluster 91: tensor (490, 64, 4, 22), mask (490, 64, 4, 22) saved.\n",
      "Cluster 92: tensor (490, 64, 3, 22), mask (490, 64, 3, 22) saved.\n",
      "Cluster 93: tensor (490, 64, 4, 22), mask (490, 64, 4, 22) saved.\n",
      "Cluster 94: tensor (490, 64, 3, 22), mask (490, 64, 3, 22) saved.\n",
      "Cluster 95: tensor (490, 64, 2, 22), mask (490, 64, 2, 22) saved.\n",
      "Cluster 96: tensor (490, 64, 2, 22), mask (490, 64, 2, 22) saved.\n",
      "Cluster 97: tensor (490, 64, 2, 22), mask (490, 64, 2, 22) saved.\n",
      "Cluster 98: tensor (490, 64, 2, 22), mask (490, 64, 2, 22) saved.\n",
      "Cluster 99: tensor (490, 64, 2, 22), mask (490, 64, 2, 22) saved.\n",
      "Cluster 100: tensor (490, 64, 3, 22), mask (490, 64, 3, 22) saved.\n",
      "Cluster 101: tensor (490, 64, 2, 22), mask (490, 64, 2, 22) saved.\n",
      "Cluster 102: tensor (490, 64, 2, 22), mask (490, 64, 2, 22) saved.\n",
      "Cluster 103: tensor (490, 64, 1, 22), mask (490, 64, 1, 22) saved.\n",
      "Cluster 104: tensor (490, 64, 2, 22), mask (490, 64, 2, 22) saved.\n",
      "Cluster 105: tensor (490, 64, 2, 22), mask (490, 64, 2, 22) saved.\n",
      "Cluster 106: tensor (490, 64, 2, 22), mask (490, 64, 2, 22) saved.\n",
      "Cluster 107: tensor (490, 64, 1, 22), mask (490, 64, 1, 22) saved.\n",
      "✅ Done Block 7: tensors + masks saved for all clusters.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#block 7\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, gc, json\n",
    "\n",
    "LOOKBACK = 64   # window size\n",
    "DATA_DIR = \"./tensors/\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# --- chọn feature columns (bỏ các cột không phải feature) ---\n",
    "feature_cols = [c for c in df_features.columns if c not in [\"ticker\",\"timestamp\",\"cluster\",\"month\"]]\n",
    "\n",
    "tensor_index = []\n",
    "\n",
    "# --- Lặp qua từng cluster ---\n",
    "for c_id, g in df_clusters.groupby(\"cluster\"):\n",
    "    if c_id == -1:   # DBSCAN noise bỏ qua\n",
    "        continue\n",
    "\n",
    "    tickers = sorted(g[\"ticker\"].unique())\n",
    "    g_feat = df_features[df_features[\"ticker\"].isin(tickers)].copy()\n",
    "\n",
    "    # Pivot: index = timestamp, columns = MultiIndex (ticker, feature)\n",
    "    pivoted = g_feat.pivot(index=\"timestamp\", columns=\"ticker\", values=feature_cols)\n",
    "    pivoted.columns = pd.MultiIndex.from_product([tickers, feature_cols])\n",
    "\n",
    "    # Mask: 1 = có dữ liệu, 0 = NaN\n",
    "    mask_df = ~pivoted.isna()\n",
    "\n",
    "    # Fill NaN để reshape được (mask vẫn giữ thông tin missing)\n",
    "    pivoted_filled = pivoted.ffill().bfill()\n",
    "\n",
    "    T, N, F = len(pivoted_filled.index), len(tickers), len(feature_cols)\n",
    "\n",
    "    X = pivoted_filled.values.reshape(T, N, F)\n",
    "    M = mask_df.values.reshape(T, N, F).astype(int)\n",
    "\n",
    "    cluster_tensors, cluster_masks = [], []\n",
    "    for i in range(LOOKBACK, T):\n",
    "        cluster_tensors.append(X[i-LOOKBACK:i])\n",
    "        cluster_masks.append(M[i-LOOKBACK:i])\n",
    "\n",
    "    if cluster_tensors:\n",
    "        X_arr, M_arr = np.array(cluster_tensors), np.array(cluster_masks)\n",
    "\n",
    "        # Save file\n",
    "        tensor_file = f\"cluster_{c_id}_tensor.npy\"\n",
    "        mask_file   = f\"cluster_{c_id}_mask.npy\"\n",
    "        np.save(os.path.join(DATA_DIR, tensor_file), X_arr)\n",
    "        np.save(os.path.join(DATA_DIR, mask_file), M_arr)\n",
    "\n",
    "        tensor_index.append({\n",
    "            \"cluster\": int(c_id),\n",
    "            \"tickers\": tickers,\n",
    "            \"dates\": [str(d) for d in pivoted_filled.index[LOOKBACK:]],\n",
    "            \"tensor_file\": tensor_file,\n",
    "            \"mask_file\": mask_file\n",
    "        })\n",
    "\n",
    "        print(f\"Cluster {c_id}: tensor {X_arr.shape}, mask {M_arr.shape} saved.\")\n",
    "\n",
    "    # Giải phóng RAM\n",
    "    del g_feat, pivoted, pivoted_filled, mask_df, X, M, cluster_tensors, cluster_masks\n",
    "    gc.collect()\n",
    "\n",
    "# --- Lưu metadata ---\n",
    "with open(os.path.join(DATA_DIR, \"tensor_index.json\"), \"w\") as f:\n",
    "    json.dump(tensor_index, f, indent=2)\n",
    "\n",
    "print(\"✅ Done Block 7: tensors + masks saved for all clusters.\")\n",
    "\n",
    "# Sau Block 7 có thể xoá df_features cho nhẹ RAM\n",
    "del df_features\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf1ef80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Không lấy được benchmarks: FiinSession.Fetch_Trading_Data() missing 2 required positional arguments: 'tickers' and 'fields'\n",
      "✅ Done Block 7.5: df_backtest sẵn sàng cho reward.\n",
      "Kích thước df_backtest: (256151, 3)\n",
      "Tickers unique: 391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1052"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Block 7.5 — Chuẩn bị dữ liệu backtest cho reward thật\n",
    "import gc\n",
    "\n",
    "# Chỉ giữ dữ liệu cần thiết để tính reward (close price)\n",
    "# df_price có từ Block 1 (OHLCV đầy đủ)\n",
    "df_backtest = df_price[[\"ticker\", \"timestamp\", \"close\"]].copy()\n",
    "\n",
    "# Ép timestamp về dạng datetime để đồng bộ\n",
    "df_backtest[\"timestamp\"] = pd.to_datetime(df_backtest[\"timestamp\"])\n",
    "\n",
    "print(\"✅ Done Block 7.5: df_backtest sẵn sàng cho reward.\")\n",
    "print(\"Kích thước df_backtest:\", df_backtest.shape)\n",
    "print(\"Tickers unique:\", df_backtest[\"ticker\"].nunique())\n",
    "\n",
    "# Xóa những biến không còn cần để tiết kiệm RAM\n",
    "del df_price\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c49599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 8 — A3C multi-stock per-cluster\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json, os, gc\n",
    "\n",
    "DATA_DIR = \"./tensors/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Load metadata ---\n",
    "with open(os.path.join(DATA_DIR, \"tensor_index.json\"), \"r\") as f:\n",
    "    tensor_index = json.load(f)\n",
    "\n",
    "# --- Actor-Critic network ---\n",
    "class A3CClusterNet(nn.Module):\n",
    "    def __init__(self, n_features, hidden_size=64):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=n_features, hidden_size=hidden_size, batch_first=True)\n",
    "        self.actor_head = nn.Linear(hidden_size, 3)   # -1,0,1 actions\n",
    "        self.critic_head = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape = (batch, T, F)\n",
    "        out, _ = self.lstm(x)\n",
    "        h = out[:, -1, :]  # lấy hidden cuối\n",
    "        return self.actor_head(h), self.critic_head(h)\n",
    "\n",
    "# --- Loss function ---\n",
    "def a3c_loss(policy_logits, values, actions, rewards, gamma=0.99, entropy_beta=0.01):\n",
    "    advantage = rewards - values.squeeze(-1)\n",
    "\n",
    "    # critic loss\n",
    "    critic_loss = advantage.pow(2).mean()\n",
    "\n",
    "    # actor loss\n",
    "    log_probs = torch.log_softmax(policy_logits, dim=-1)\n",
    "    chosen_log_probs = log_probs.gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "    actor_loss = -(chosen_log_probs * advantage.detach()).mean()\n",
    "\n",
    "    # entropy bonus\n",
    "    entropy = -(torch.softmax(policy_logits, dim=-1) * log_probs).sum(-1).mean()\n",
    "\n",
    "    return actor_loss + 0.5 * critic_loss - entropy_beta * entropy\n",
    "\n",
    "# --- Train loop (per cluster) ---\n",
    "def train_cluster(cluster_meta, epochs=3, lr=1e-3):\n",
    "    tickers = cluster_meta[\"tickers\"]\n",
    "    dates = cluster_meta[\"dates\"]\n",
    "\n",
    "    # load tensors\n",
    "    X = np.load(os.path.join(DATA_DIR, cluster_meta[\"tensor_file\"]))\n",
    "    M = np.load(os.path.join(DATA_DIR, cluster_meta[\"mask_file\"]))\n",
    "\n",
    "    B, T, N, F = X.shape\n",
    "    print(f\"Training cluster {cluster_meta['cluster']} | X={X.shape}, tickers={len(tickers)}\")\n",
    "\n",
    "    model = A3CClusterNet(n_features=F).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # convert to torch\n",
    "    X_tensor = torch.tensor(X.reshape(B*N, T, F), dtype=torch.float32).to(device)\n",
    "\n",
    "    # tạo rewards từ df_backtest\n",
    "    rewards = []\n",
    "    for tk in tickers:\n",
    "        px = df_backtest[df_backtest[\"ticker\"] == tk].set_index(\"timestamp\")[\"close\"]\n",
    "        px = px.reindex(dates).ffill().bfill()\n",
    "        r = np.log(px.values[1:] / px.values[:-1])\n",
    "        rewards.append(np.concatenate([[0], r]))  # align length\n",
    "    rewards = np.array(rewards).T  # shape (B, N)\n",
    "    rewards_tensor = torch.tensor(rewards.reshape(B*N), dtype=torch.float32).to(device)\n",
    "\n",
    "    # giả định actions random để khởi động training\n",
    "    actions_tensor = torch.randint(0, 3, (B*N,), dtype=torch.long).to(device)\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        logits, values = model(X_tensor)\n",
    "        loss = a3c_loss(logits, values, actions_tensor, rewards_tensor)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"  Epoch {ep+1}/{epochs}, Loss={loss.item():.4f}\")\n",
    "\n",
    "    # --- inference: lấy action cuối cùng ---\n",
    "    with torch.no_grad():\n",
    "        logits, _ = model(X_tensor)\n",
    "        actions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "\n",
    "    # reshape về (B, N)\n",
    "    actions = actions.reshape(B, N)\n",
    "\n",
    "    # tạo DataFrame tín hiệu\n",
    "    signals = []\n",
    "    for i, d in enumerate(dates):\n",
    "        for j, tk in enumerate(tickers):\n",
    "            signals.append({\"date\": d, \"ticker\": tk, \"signal\": int(actions[i, j] - 1)})\n",
    "            # map: 0→-1, 1→0, 2→1\n",
    "\n",
    "    return pd.DataFrame(signals)\n",
    "\n",
    "# --- Chạy tất cả clusters ---\n",
    "a3c_signals = []\n",
    "for meta in tensor_index:\n",
    "    df_sig = train_cluster(meta, epochs=3)\n",
    "    a3c_signals.append(df_sig)\n",
    "    gc.collect()\n",
    "\n",
    "a3c_signals = pd.concat(a3c_signals, ignore_index=True)\n",
    "print(\"✅ Done Block 8: a3c_signals ready:\", a3c_signals.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b9877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 9 — DDPG cluster-level allocation (reward thật)\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "import numpy as np, pandas as pd, gc\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Actor & Critic ---\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, s_dim, a_dim): \n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(s_dim, 64), nn.ReLU(),\n",
    "            nn.Linear(64, a_dim), nn.Softmax(-1)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, s_dim, a_dim): \n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(s_dim+a_dim, 64), nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, s, a): return self.net(torch.cat([s,a], -1))\n",
    "\n",
    "# --- Replay buffer ---\n",
    "class Buffer:\n",
    "    def __init__(self, cap=2000): self.buf=[]; self.cap=cap\n",
    "    def push(self,*x):\n",
    "        if len(self.buf)>=self.cap: self.buf.pop(0)\n",
    "        self.buf.append(x)\n",
    "    def sample(self, bz):\n",
    "        idx=np.random.choice(len(self.buf),bz,False)\n",
    "        return map(np.array, zip(*[self.buf[i] for i in idx]))\n",
    "    def __len__(self): return len(self.buf)\n",
    "\n",
    "# --- Init ---\n",
    "clusters = [c for c in df_clusters[\"cluster\"].unique() if c!=-1]\n",
    "nC, feat_per_cluster = len(clusters), 5   # 5 feature mỗi cluster\n",
    "s_dim, a_dim = feat_per_cluster*nC, nC\n",
    "\n",
    "actor, critic = Actor(s_dim, a_dim).to(device), Critic(s_dim, a_dim).to(device)\n",
    "t_actor, t_critic = Actor(s_dim, a_dim).to(device), Critic(s_dim, a_dim).to(device)\n",
    "t_actor.load_state_dict(actor.state_dict()); t_critic.load_state_dict(critic.state_dict())\n",
    "optA, optC = optim.Adam(actor.parameters(),1e-3), optim.Adam(critic.parameters(),1e-3)\n",
    "buf = Buffer(); γ, τ = 0.99, 0.01\n",
    "\n",
    "# --- Update ---\n",
    "def update():\n",
    "    if len(buf)<64: return\n",
    "    s,a,r,s2 = buf.sample(64)\n",
    "    s,a,r,s2 = [torch.tensor(x,dtype=torch.float32).to(device) for x in [s,a,r[:,None],s2]]\n",
    "    q = critic(s,a); q_t = r + γ*t_critic(s2,t_actor(s2)).detach()\n",
    "    lC = nn.MSELoss()(q,q_t); optC.zero_grad(); lC.backward(); optC.step()\n",
    "    lA = -critic(s,actor(s)).mean(); optA.zero_grad(); lA.backward(); optA.step()\n",
    "    for t,s in zip(t_actor.parameters(),actor.parameters()): t.data.copy_(τ*s+(1-τ)*t)\n",
    "    for t,s in zip(t_critic.parameters(),critic.parameters()): t.data.copy_(τ*s+(1-τ)*t)\n",
    "\n",
    "# --- Helper: extract cluster features ---\n",
    "def get_cluster_state(date, prev_date):\n",
    "    feats = []\n",
    "    for c in clusters:\n",
    "        tickers = df_clusters[df_clusters.cluster==c].ticker.unique()\n",
    "\n",
    "        # A3C signals\n",
    "        sigs = a3c_signals[(a3c_signals.date==date)&(a3c_signals.ticker.isin(tickers))][\"signal\"]\n",
    "        mean_sig = sigs.mean() if len(sigs) else 0\n",
    "        long_r  = (sigs==1).mean() if len(sigs) else 0\n",
    "        short_r = (sigs==-1).mean() if len(sigs) else 0\n",
    "\n",
    "        # Returns\n",
    "        px = df_backtest[df_backtest.ticker.isin(tickers)].pivot(index=\"timestamp\",columns=\"ticker\",values=\"close\")\n",
    "        if date not in px.index or prev_date not in px.index:\n",
    "            ret, vol = 0, 0\n",
    "        else:\n",
    "            r = np.log(px.loc[date]/px.loc[prev_date])\n",
    "            ret, vol = r.mean(), r.std()\n",
    "\n",
    "        feats.extend([mean_sig,long_r,short_r,ret,vol])\n",
    "    return np.array(feats)\n",
    "\n",
    "# --- Train loop ---\n",
    "dates = sorted(a3c_signals[\"date\"].unique()); rec=[]\n",
    "for t in range(1,len(dates)):\n",
    "    day, prev = dates[t], dates[t-1]\n",
    "    s = get_cluster_state(day, prev); s_t=torch.tensor(s).float().unsqueeze(0).to(device)\n",
    "\n",
    "    # Action\n",
    "    a = actor(s_t).cpu().detach().numpy().squeeze()\n",
    "\n",
    "    # Reward (portfolio log-return)\n",
    "    px = df_backtest[df_backtest.timestamp.isin([prev,day])].pivot(index=\"timestamp\",columns=\"ticker\",values=\"close\")\n",
    "    if px.shape[0]<2: continue\n",
    "    ret = np.log(px.loc[day]/px.loc[prev])\n",
    "\n",
    "    merged = a3c_signals[a3c_signals.date==day].merge(ret.rename(\"ret\"),on=\"ticker\",how=\"left\")\n",
    "    merged[\"pnl\"] = merged[\"signal\"]*merged[\"ret\"].fillna(0)\n",
    "    cl_ret = merged.groupby(df_clusters[\"cluster\"]).pnl.mean().reindex(clusters).fillna(0).values\n",
    "\n",
    "    reward = float(np.dot(a, cl_ret))\n",
    "    s2 = get_cluster_state(day, prev)\n",
    "\n",
    "    buf.push(s,a,reward,s2); update()\n",
    "    rec.append({\"date\":day, **{f\"w{c}\":a[i] for i,c in enumerate(clusters)}})\n",
    "\n",
    "ddpg_weights = pd.DataFrame(rec)\n",
    "print(\"✅ Done Block 9:\", ddpg_weights.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66ec637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 10 — Portfolio Construction & Backtest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from FiinQuantX import FiinSession\n",
    "\n",
    "INIT_CAPITAL = 10000\n",
    "TCOST = 0.0005  # transaction cost 0.05%\n",
    "\n",
    "# --- Chuẩn hóa dữ liệu ---\n",
    "a3c_signals[\"date\"] = pd.to_datetime(a3c_signals[\"date\"])\n",
    "df_backtest[\"date\"] = pd.to_datetime(df_backtest[\"timestamp\"])\n",
    "ddpg_weights[\"date\"] = pd.to_datetime(ddpg_weights[\"date\"])\n",
    "df_clusters[\"timestamp\"] = pd.to_datetime(df_clusters[\"timestamp\"])\n",
    "\n",
    "# Map ticker → cluster\n",
    "cluster_map = df_clusters[[\"ticker\", \"timestamp\", \"cluster\"]].rename(columns={\"timestamp\":\"date\"})\n",
    "\n",
    "# --- Tải benchmark ---\n",
    "username = \"REPLACE_WITH_YOUR_USER_NAME\"\n",
    "password = \"REPLACE_WITH_YOUR_PASS_WORD\"\n",
    "client = FiinSession(username=username, password=password).login()\n",
    "\n",
    "benchmarks = client.Fetch_Trading_Data(\n",
    "    realtime=False,\n",
    "    tickers=[\"VNINDEX\"],\n",
    "    fields=[\"close\"],\n",
    "    adjusted=True,\n",
    "    by=\"1d\",\n",
    "    from_date=a3c_signals[\"date\"].min().strftime(\"%Y-%m-%d\")\n",
    ").get_data().reset_index()\n",
    "\n",
    "benchmarks[\"date\"] = pd.to_datetime(benchmarks[\"date\"])\n",
    "benchmarks = benchmarks[[\"date\", \"close\"]].rename(columns={\"close\":\"benchmark_close\"})\n",
    "benchmarks[\"benchmark_return\"] = benchmarks[\"benchmark_close\"].pct_change().fillna(0)\n",
    "\n",
    "# --- Backtest ---\n",
    "equity = INIT_CAPITAL\n",
    "portfolio_history = []\n",
    "positions = {}  # ticker → số vốn phân bổ\n",
    "\n",
    "for d in sorted(a3c_signals[\"date\"].unique()):\n",
    "    # Lấy tín hiệu A3C\n",
    "    sig_today = a3c_signals[a3c_signals[\"date\"] == d]\n",
    "    if sig_today.empty:\n",
    "        portfolio_history.append({\"date\": d, \"equity\": equity})\n",
    "        continue\n",
    "\n",
    "    # Map cluster\n",
    "    sig_today = sig_today.merge(cluster_map, on=[\"date\",\"ticker\"], how=\"left\")\n",
    "\n",
    "    # Lấy weights từ DDPG\n",
    "    w_today = ddpg_weights[ddpg_weights[\"date\"] == d]\n",
    "    if w_today.empty:\n",
    "        cluster_weights = {c: 1/len(sig_today[\"cluster\"].unique()) for c in sig_today[\"cluster\"].unique()}\n",
    "    else:\n",
    "        cluster_weights = {int(c.split(\"w\")[-1]): w_today.iloc[0][c] for c in w_today.columns if c.startswith(\"w\")}\n",
    "\n",
    "    # Tính phân bổ vốn\n",
    "    positions = {}\n",
    "    for clus, g in sig_today.groupby(\"cluster\"):\n",
    "        if clus not in cluster_weights:\n",
    "            continue\n",
    "        w_c = cluster_weights[clus] / max(len(g), 1)\n",
    "        for _, row in g.iterrows():\n",
    "            if row[\"signal\"] != 0:\n",
    "                positions[row[\"ticker\"]] = equity * w_c * row[\"signal\"]\n",
    "\n",
    "    # Tính lợi nhuận trong ngày\n",
    "    px_today = df_backtest[df_backtest[\"date\"] == d].set_index(\"ticker\")[\"close\"]\n",
    "    px_prev  = df_backtest[df_backtest[\"date\"] < d].groupby(\"ticker\").last()[\"close\"]\n",
    "\n",
    "    daily_ret = 0\n",
    "    for tk, alloc in positions.items():\n",
    "        if tk in px_today.index and tk in px_prev.index:\n",
    "            r = (px_today[tk] / px_prev[tk] - 1)\n",
    "            daily_ret += alloc / equity * r\n",
    "\n",
    "    equity = equity * (1 + daily_ret - TCOST)\n",
    "    portfolio_history.append({\"date\": d, \"equity\": equity})\n",
    "\n",
    "# --- Kết quả cuối ---\n",
    "df_trading = pd.DataFrame(portfolio_history)\n",
    "df_trading = df_trading.merge(benchmarks, on=\"date\", how=\"left\")\n",
    "\n",
    "print(\"✅ Done Block 10: Backtest finished\")\n",
    "print(\"Final equity:\", equity)\n",
    "print(\"Benchmark final:\", df_trading[\"benchmark_close\"].iloc[-1] / df_trading[\"benchmark_close\"].iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee458858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 11 — Walk-Forward Validation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Input từ Block 10 ---\n",
    "# df_trading: equity curve + benchmark\n",
    "# a3c_signals: tín hiệu\n",
    "# ddpg_weights: phân bổ vốn\n",
    "# df_backtest: giá đóng cửa\n",
    "\n",
    "# --- Chia dữ liệu ---\n",
    "train_end = \"2024-06-06\"\n",
    "val_end   = \"2024-12-31\"\n",
    "test_end  = df_trading[\"date\"].max().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "splits = {\n",
    "    \"train\": (df_trading[\"date\"] <= train_end),\n",
    "    \"val\":   (df_trading[\"date\"] > train_end) & (df_trading[\"date\"] <= val_end),\n",
    "    \"test\":  (df_trading[\"date\"] > val_end)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, mask in splits.items():\n",
    "    equity = df_trading.loc[mask, \"equity\"]\n",
    "    bench  = df_trading.loc[mask, \"benchmark_close\"]\n",
    "\n",
    "    if equity.empty: \n",
    "        continue\n",
    "\n",
    "    # CAGR\n",
    "    years = (equity.index[-1] - equity.index[0]).days / 365\n",
    "    cagr = (equity.iloc[-1] / equity.iloc[0])**(1/years) - 1 if years > 0 else 0\n",
    "\n",
    "    # Volatility (annualized)\n",
    "    daily_ret = equity.pct_change().dropna()\n",
    "    vol = daily_ret.std() * np.sqrt(252)\n",
    "\n",
    "    # Sharpe ratio (risk-free ~ 0)\n",
    "    sharpe = daily_ret.mean() / daily_ret.std() * np.sqrt(252) if daily_ret.std() > 0 else 0\n",
    "\n",
    "    # Max drawdown\n",
    "    roll_max = equity.cummax()\n",
    "    dd = (equity / roll_max - 1).min()\n",
    "\n",
    "    # Benchmark return\n",
    "    bench_ret = bench.iloc[-1] / bench.iloc[0] - 1 if len(bench) > 1 else 0\n",
    "\n",
    "    results[name] = {\n",
    "        \"CAGR\": round(cagr, 4),\n",
    "        \"Volatility\": round(vol, 4),\n",
    "        \"Sharpe\": round(sharpe, 2),\n",
    "        \"MaxDD\": round(dd, 4),\n",
    "        \"BenchmarkRet\": round(bench_ret, 4)\n",
    "    }\n",
    "\n",
    "# --- In kết quả ---\n",
    "print(\"✅ Done Block 11: Walk-forward validation results\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k.upper()} → {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96775830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 12 — Evaluation, Risk Controls & Reporting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Input: df_trading từ Block 10, results từ Block 11 ---\n",
    "# df_trading có: [\"date\",\"equity\",\"benchmark_close\",\"signal\",\"weight\",\"pnl\"]\n",
    "\n",
    "# Vẽ equity curve vs benchmark\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(df_trading[\"date\"], df_trading[\"equity\"], label=\"Strategy\", linewidth=2)\n",
    "plt.plot(df_trading[\"date\"], \n",
    "         df_trading[\"benchmark_close\"] / df_trading[\"benchmark_close\"].iloc[0] * 10000, \n",
    "         label=\"Benchmark (VNINDEX)\", linestyle=\"--\")\n",
    "plt.title(\"Equity Curve vs Benchmark\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Portfolio Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- Drawdowns ---\n",
    "df_trading[\"roll_max\"] = df_trading[\"equity\"].cummax()\n",
    "df_trading[\"drawdown\"] = df_trading[\"equity\"]/df_trading[\"roll_max\"] - 1\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.fill_between(df_trading[\"date\"], df_trading[\"drawdown\"], color=\"red\", alpha=0.3)\n",
    "plt.title(\"Drawdown over time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Drawdown\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- Histogram of daily returns ---\n",
    "daily_ret = df_trading[\"equity\"].pct_change().dropna()\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(daily_ret, bins=50, alpha=0.7)\n",
    "plt.title(\"Distribution of Daily Returns\")\n",
    "plt.xlabel(\"Daily Return\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- In summary stats ---\n",
    "print(\"✅ Done Block 12: Evaluation Report\")\n",
    "print(\"Final Equity:\", round(df_trading['equity'].iloc[-1],2))\n",
    "print(\"Total Return:\", round(df_trading['equity'].iloc[-1]/df_trading['equity'].iloc[0]-1,4))\n",
    "print(\"Sharpe:\", round(daily_ret.mean()/daily_ret.std()*np.sqrt(252),2))\n",
    "print(\"Max Drawdown:\", round(df_trading['drawdown'].min(),4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
