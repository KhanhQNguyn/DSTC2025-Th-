{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d4d6cad",
   "metadata": {},
   "source": [
    "**HƯỚNG DẪN CHẠY**\n",
    "\n",
    "*Nhóm chạy code theo thứ tự từng cell từ trên xuống xuống dưới*\n",
    "\n",
    "**Một số điểm lưu ý:**\n",
    "\n",
    "- *Thời gian chạy các block đa số lâu (Khoảng 10 phút riêng block 6 khoảng 25 phút)*\n",
    "\n",
    "- *Các block 8,9,10,11 có lưu kết quả file csv* \n",
    "\n",
    "- **Các file csv kết quả nhóm có upload lên github**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2bbe97",
   "metadata": {},
   "source": [
    "**Tải các thư viện cần thiết** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e11e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy torch scikit-learn matplotlib\n",
    "!pip install --extra-index-url https://fiinquant.github.io/fiinquantx/simple fiinquantx\n",
    "!pip install --upgrade --extra-index-url https://fiinquant.github.io/fiinquantx/simple fiinquantx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565db80b",
   "metadata": {},
   "source": [
    "**Block 1: tải dữ liệu lịch sử và realtime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5a2bf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số mã HOSE: 413\n",
      "Fetching data, it may take a while. Please wait...\n",
      "History ban đầu:   ticker         timestamp      open      high       low     close     volume  \\\n",
      "0    AAA  2023-01-03 00:00  6539.643  6866.145  6539.643  6866.145  1543984.0   \n",
      "1    AAA  2023-01-04 00:00  6866.145  7000.587  6827.733  6827.733  1302505.0   \n",
      "2    AAA  2023-01-05 00:00  6866.145  6904.557  6808.527  6885.351   980473.0   \n",
      "3    AAA  2023-01-06 00:00  6885.351  6990.984  6818.130  6856.542  1431699.0   \n",
      "4    AAA  2023-01-09 00:00  6914.160  6962.175  6760.512  6789.321  1121385.0   \n",
      "\n",
      "         bu        sd           fs           fn  \n",
      "0  938600.0  504700.0   40579000.0  899404000.0  \n",
      "1  462900.0  780600.0  151639000.0   36850000.0  \n",
      "2  487200.0  473700.0  343911000.0  -59103000.0  \n",
      "3  564300.0  828300.0  345999000.0 -294312000.0  \n",
      "4  414000.0  631800.0  514557000.0 -483197000.0  \n"
     ]
    }
   ],
   "source": [
    "# Block 1 — Login & Lấy dữ liệu tất cả HOSE/HNX/UPCOM\n",
    "import pandas as pd\n",
    "from FiinQuantX import FiinSession, BarDataUpdate\n",
    "# --- Login ---\n",
    "username = \"DSTC_18@fiinquant.vn\"\n",
    "password = \"Fiinquant0606\"\n",
    "\n",
    "client = FiinSession(\n",
    "    username=username,\n",
    "    password=password\n",
    ").login()\n",
    "\n",
    "# --- Lấy danh sách cổ phiếu từng sàn ---\n",
    "tickers_hose  = list(client.TickerList(ticker=\"VNINDEX\"))     # HOSE\n",
    "print(f\"Số mã HOSE: {len(tickers_hose)}\")\n",
    "\n",
    "# --- Lấy dữ liệu lịch sử toàn bộ ---\n",
    "event_history = client.Fetch_Trading_Data(\n",
    "    realtime=False,\n",
    "    tickers=tickers_hose,\n",
    "    fields=['open','high','low','close','volume','bu','sd','fs','fn'], \n",
    "    adjusted=True,\n",
    "    by=\"1d\",\n",
    "    from_date=\"2023-01-01\"   # Lấy dữ liệu từ 2023 tới nay\n",
    ")\n",
    "\n",
    "df_all = event_history.get_data()\n",
    "print(\"History ban đầu:\", df_all.head())\n",
    "\n",
    "# --- Callback realtime ---\n",
    "def onDataUpdate(data: BarDataUpdate):\n",
    "    global df_all\n",
    "    df_update = data.to_dataFrame()\n",
    "    df_all = pd.concat([df_all, df_update])\n",
    "    df_all = df_all.drop_duplicates()\n",
    "    print(\"Realtime update:\")\n",
    "    print(df_update.head())\n",
    "\n",
    "# --- Bật realtime nối tiếp dữ liệu ---\n",
    "event_realtime = client.Fetch_Trading_Data(\n",
    "    realtime=True,\n",
    "    tickers=tickers_hose,\n",
    "    fields=['open','high','low','close','volume','bu','sd','fs','fn'], \n",
    "    adjusted=True,\n",
    "    by=\"1d\",\n",
    "    period=1,\n",
    "    callback=onDataUpdate\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1122224",
   "metadata": {},
   "source": [
    "**Block 2: lấy dữ liệu FA, lọc các mã không hợp lệ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c93b463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Lỗi khi lấy FA cho FUETPVND: 'FUETPVND'\n",
      "Số mã HOSE ban đầu: 413\n",
      "Số mã có dữ liệu FA: 391\n",
      "FA Data sample:\n",
      "   organizationId ticker  year  quarter  \\\n",
      "0          894364    CCC  2023        4   \n",
      "1          894364    CCC  2024        1   \n",
      "2          894364    CCC  2024        2   \n",
      "3          894364    CCC  2024        3   \n",
      "4          894364    CCC  2024        4   \n",
      "\n",
      "                                              ratios ReportDate  \n",
      "0  {'SolvencyRatio': {'DebtToEquityRatio': 1.5102...        NaT  \n",
      "1  {'SolvencyRatio': {'DebtToEquityRatio': 0.7722...        NaT  \n",
      "2  {'SolvencyRatio': {'DebtToEquityRatio': 0.7357...        NaT  \n",
      "3  {'SolvencyRatio': {'DebtToEquityRatio': 0.7914...        NaT  \n",
      "4  {'SolvencyRatio': {'DebtToEquityRatio': 0.6437...        NaT  \n"
     ]
    }
   ],
   "source": [
    "# Block 2 — Lấy dữ liệu FA theo quý (HOSE only)\n",
    "\n",
    "def fetch_fa_quarterly(ticker, latest_year=2025, n_periods=32):\n",
    "    try:\n",
    "        fi_list = client.FundamentalAnalysis().get_ratios(\n",
    "            tickers=[ticker],\n",
    "            TimeFilter=\"Quarterly\",\n",
    "            LatestYear=latest_year,\n",
    "            NumberOfPeriod=n_periods,\n",
    "            Consolidated=True\n",
    "        )\n",
    "\n",
    "        # Nếu không có dữ liệu thì bỏ qua\n",
    "        if not fi_list or not isinstance(fi_list, list):\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        df = pd.DataFrame(fi_list)\n",
    "        if df.empty:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        df[\"ticker\"] = ticker\n",
    "        if \"ReportDate\" in df.columns:\n",
    "            df[\"ReportDate\"] = pd.to_datetime(df[\"ReportDate\"])\n",
    "        else:\n",
    "            # Nếu không có ReportDate thì tạo cột null để tránh lỗi concat\n",
    "            df[\"ReportDate\"] = pd.NaT\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Lỗi khi lấy FA cho {ticker}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "# --- Lọc danh sách: chỉ giữ những mã có dữ liệu FA ---\n",
    "fa_list = []\n",
    "valid_tickers = []\n",
    "\n",
    "for t in tickers_hose:   # lấy theo danh sách HOSE từ Block 1\n",
    "    df_fa = fetch_fa_quarterly(t, latest_year=2025, n_periods=32)\n",
    "    if not df_fa.empty:\n",
    "        fa_list.append(df_fa)\n",
    "        valid_tickers.append(t)\n",
    "\n",
    "# --- Gộp DataFrame ---\n",
    "if fa_list:\n",
    "    fa_data = pd.concat(fa_list, ignore_index=True)\n",
    "else:\n",
    "    fa_data = pd.DataFrame()\n",
    "\n",
    "print(f\"Số mã HOSE ban đầu: {len(tickers_hose)}\")\n",
    "print(f\"Số mã có dữ liệu FA: {len(valid_tickers)}\")\n",
    "print(\"FA Data sample:\")\n",
    "print(fa_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d9ef83",
   "metadata": {},
   "source": [
    "**Block 3: Chuẩn hóa FA và gộp dữ liệu với giá**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "831a3096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample merged:\n",
      "  ticker  timestamp      open      high       low     close     volume  \\\n",
      "0    AAA 2023-01-03  6539.643  6866.145  6539.643  6866.145  1543984.0   \n",
      "1    AAA 2023-01-04  6866.145  7000.587  6827.733  6827.733  1302505.0   \n",
      "2    AAA 2023-01-05  6866.145  6904.557  6808.527  6885.351   980473.0   \n",
      "3    AAA 2023-01-06  6885.351  6990.984  6818.130  6856.542  1431699.0   \n",
      "4    AAA 2023-01-09  6914.160  6962.175  6760.512  6789.321  1121385.0   \n",
      "\n",
      "         bu        sd           fs  ...  DebtToEquityRatio  EBITMargin  \\\n",
      "0  938600.0  504700.0   40579000.0  ...           0.507521   -0.049731   \n",
      "1  462900.0  780600.0  151639000.0  ...           0.507521   -0.049731   \n",
      "2  487200.0  473700.0  343911000.0  ...           0.507521   -0.049731   \n",
      "3  564300.0  828300.0  345999000.0  ...           0.507521   -0.049731   \n",
      "4  414000.0  631800.0  514557000.0  ...           0.507521   -0.049731   \n",
      "\n",
      "        ROA       ROE      ROIC    BasicEPS  PriceToBook  PriceToEarning  \\\n",
      "0  0.014669  0.029589  0.014784 -255.644791     0.737556       24.741322   \n",
      "1  0.014669  0.029589  0.014784 -255.644791     0.737556       24.741322   \n",
      "2  0.014669  0.029589  0.014784 -255.644791     0.737556       24.741322   \n",
      "3  0.014669  0.029589  0.014784 -255.644791     0.737556       24.741322   \n",
      "4  0.014669  0.029589  0.014784 -255.644791     0.737556       24.741322   \n",
      "\n",
      "   NetRevenueGrowthYoY  GrossProfitGrowthYoY  \n",
      "0             -0.18869             -0.910016  \n",
      "1             -0.18869             -0.910016  \n",
      "2             -0.18869             -0.910016  \n",
      "3             -0.18869             -0.910016  \n",
      "4             -0.18869             -0.910016  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "Số mã merge thành công: 391\n"
     ]
    }
   ],
   "source": [
    "# Block 3 — Chuẩn hoá FA + Merge với giá (HOSE only, dựa theo Block 2)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# --- Các chỉ số FA cần lấy ---\n",
    "fa_fields = [\n",
    "    \"DebtToEquityRatio\",\"EBITMargin\",\"ROA\",\"ROE\",\"ROIC\",\n",
    "    \"BasicEPS\",\"PriceToBook\",\"PriceToEarning\",\n",
    "    \"NetRevenueGrowthYoY\",\"GrossProfitGrowthYoY\"\n",
    "]\n",
    "\n",
    "# --- Hàm nổ ratios ---\n",
    "def explode_ratios(df, fa_fields):\n",
    "    records = []\n",
    "    for _, row in df.iterrows():\n",
    "        d = {\n",
    "            \"ticker\": row[\"ticker\"],\n",
    "            \"fa_year\": int(row[\"year\"]),\n",
    "            \"fa_quarter\": int(row[\"quarter\"])\n",
    "        }\n",
    "        ratios = row.get(\"ratios\", {})\n",
    "        if isinstance(ratios, dict):   # ✅ fix chỗ lỗi\n",
    "            for f in fa_fields:\n",
    "                val = None\n",
    "                for section in ratios.values():\n",
    "                    if isinstance(section, dict) and f in section:\n",
    "                        val = section[f]\n",
    "                d[f] = val\n",
    "        else:\n",
    "            # nếu ratios không phải dict thì gán NaN hết\n",
    "            for f in fa_fields:\n",
    "                d[f] = None\n",
    "        records.append(d)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# --- Chuẩn hoá FA ---\n",
    "fa_clean = explode_ratios(fa_data, fa_fields)\n",
    "\n",
    "# --- Chuẩn hoá giá ---\n",
    "df_price = df_all[df_all[\"ticker\"].isin(valid_tickers)].copy()\n",
    "df_price[\"timestamp\"] = pd.to_datetime(df_price[\"timestamp\"])\n",
    "df_price = df_price.sort_values([\"ticker\",\"timestamp\"])\n",
    "\n",
    "# tạo key (fa_year, fa_quarter) = quý trước\n",
    "pi = df_price[\"timestamp\"].dt.to_period(\"Q\")\n",
    "prev_pi = pi - 1\n",
    "df_price[\"fa_year\"] = prev_pi.dt.year.astype(int)\n",
    "df_price[\"fa_quarter\"] = prev_pi.dt.quarter.astype(int)\n",
    "\n",
    "# --- Xử lý FA: giữ duy nhất bản cuối cùng mỗi quý\n",
    "fa_clean = (\n",
    "    fa_clean.sort_values([\"ticker\",\"fa_year\",\"fa_quarter\"])\n",
    "            .drop_duplicates(subset=[\"ticker\",\"fa_year\",\"fa_quarter\"], keep=\"last\")\n",
    ")\n",
    "\n",
    "# --- Merge giá + FA ---\n",
    "df_merged = df_price.merge(\n",
    "    fa_clean,\n",
    "    on=[\"ticker\",\"fa_year\",\"fa_quarter\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# FFill theo thời gian trong từng ticker để lấp chỗ trống\n",
    "df_merged = df_merged.sort_values([\"ticker\",\"timestamp\"])\n",
    "df_merged[fa_fields] = df_merged.groupby(\"ticker\")[fa_fields].ffill()\n",
    "\n",
    "print(\"Sample merged:\")\n",
    "print(df_merged.head())\n",
    "print(\"Số mã merge thành công:\", df_merged[\"ticker\"].nunique())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08faae38",
   "metadata": {},
   "source": [
    "**Xóa biến df_all không cần thiết nữa để giảm dung lượng RAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73580df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del df_all\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331523dd",
   "metadata": {},
   "source": [
    "**Block 4: Tính các chỉ số TA dựa vào thư viện FiinQuant và ghép dữ liệu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b0de3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample with TA:\n",
      "  ticker  timestamp      open      high       low     close     volume  \\\n",
      "0    AAA 2023-01-03  6539.643  6866.145  6539.643  6866.145  1543984.0   \n",
      "1    AAA 2023-01-04  6866.145  7000.587  6827.733  6827.733  1302505.0   \n",
      "2    AAA 2023-01-05  6866.145  6904.557  6808.527  6885.351   980473.0   \n",
      "3    AAA 2023-01-06  6885.351  6990.984  6818.130  6856.542  1431699.0   \n",
      "4    AAA 2023-01-09  6914.160  6962.175  6760.512  6789.321  1121385.0   \n",
      "\n",
      "         bu        sd           fs  ...  ema_50  macd  macd_signal  macd_diff  \\\n",
      "0  938600.0  504700.0   40579000.0  ...     NaN   NaN          NaN        NaN   \n",
      "1  462900.0  780600.0  151639000.0  ...     NaN   NaN          NaN        NaN   \n",
      "2  487200.0  473700.0  343911000.0  ...     NaN   NaN          NaN        NaN   \n",
      "3  564300.0  828300.0  345999000.0  ...     NaN   NaN          NaN        NaN   \n",
      "4  414000.0  631800.0  514557000.0  ...     NaN   NaN          NaN        NaN   \n",
      "\n",
      "   rsi  bollinger_hband  bollinger_lband  atr        obv  vwap  \n",
      "0  NaN              NaN              NaN  NaN  1543984.0   NaN  \n",
      "1  NaN              NaN              NaN  NaN   241479.0   NaN  \n",
      "2  NaN              NaN              NaN  NaN  1221952.0   NaN  \n",
      "3  NaN              NaN              NaN  NaN  -209747.0   NaN  \n",
      "4  NaN              NaN              NaN  NaN -1331132.0   NaN  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "Shape sau khi thêm TA: (261234, 35)\n"
     ]
    }
   ],
   "source": [
    "# Block 4 — Tính các chỉ số TA (trên df_merged từ Block 3)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# --- Khởi tạo Indicator ---\n",
    "fi = client.FiinIndicator()\n",
    "\n",
    "# --- Hàm tính TA theo từng ticker ---\n",
    "def add_ta_indicators(df):\n",
    "    df = df.sort_values(\"timestamp\").copy()\n",
    "\n",
    "    # EMA\n",
    "    df['ema_5']  = fi.ema(df['close'], window=5)\n",
    "    df['ema_20'] = fi.ema(df['close'], window=20)\n",
    "    df['ema_50'] = fi.ema(df['close'], window=50)\n",
    "\n",
    "    # MACD\n",
    "    df['macd']        = fi.macd(df['close'], window_fast=12, window_slow=26)\n",
    "    df['macd_signal'] = fi.macd_signal(df['close'], window_fast=12, window_slow=26, window_sign=9)\n",
    "    df['macd_diff']   = fi.macd_diff(df['close'], window_fast=12, window_slow=26, window_sign=9)\n",
    "\n",
    "    # RSI\n",
    "    df['rsi'] = fi.rsi(df['close'], window=14)\n",
    "\n",
    "    # Bollinger Bands\n",
    "    df['bollinger_hband'] = fi.bollinger_hband(df['close'], window=20, window_dev=2)\n",
    "    df['bollinger_lband'] = fi.bollinger_lband(df['close'], window=20, window_dev=2)\n",
    "\n",
    "    # ATR\n",
    "    df['atr'] = fi.atr(df['high'], df['low'], df['close'], window=14)\n",
    "\n",
    "    # OBV\n",
    "    df['obv'] = fi.obv(df['close'], df['volume'])\n",
    "\n",
    "    # VWAP\n",
    "    df['vwap'] = fi.vwap(df['high'], df['low'], df['close'], df['volume'], window=14)\n",
    "\n",
    "    return df\n",
    "\n",
    "# --- Áp dụng cho toàn bộ df_merged ---\n",
    "df_with_ta = df_merged.groupby(\"ticker\", group_keys=False).apply(add_ta_indicators)\n",
    "\n",
    "print(\"Sample with TA:\")\n",
    "print(df_with_ta.head())\n",
    "print(\"Shape sau khi thêm TA:\", df_with_ta.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f235303e",
   "metadata": {},
   "source": [
    "**Xóa bớt biến df_merged không còn cần thiết để giảm dung lượng RAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26204a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del df_merged\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5614073e",
   "metadata": {},
   "source": [
    "**Block 5: Chuẩn hóa dữ liệu FA và TA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbd7f105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample features:\n",
      "  ticker  timestamp  DebtToEquityRatio  EBITMargin       ROA       ROE  \\\n",
      "0    AAA 2023-06-14           0.559115    0.978956  0.368731  0.415728   \n",
      "1    AAA 2023-06-15           0.559115    0.978956  0.368731  0.415728   \n",
      "2    AAA 2023-06-16           0.559115    0.978956  0.368731  0.415728   \n",
      "3    AAA 2023-06-19           0.559115    0.978956  0.368731  0.415728   \n",
      "4    AAA 2023-06-20           0.559115    0.978956  0.368731  0.415728   \n",
      "\n",
      "     ROIC  BasicEPS  PriceToBook  PriceToEarning  ...  ema_50_z    macd_z  \\\n",
      "0  0.7533  0.158046      0.37764        0.537353  ...  1.799046 -0.008320   \n",
      "1  0.7533  0.158046      0.37764        0.537353  ...  1.761009 -0.314808   \n",
      "2  0.7533  0.158046      0.37764        0.537353  ...  1.701399 -0.891565   \n",
      "3  0.7533  0.158046      0.37764        0.537353  ...  1.651219 -1.278916   \n",
      "4  0.7533  0.158046      0.37764        0.537353  ...  1.609327 -1.509982   \n",
      "\n",
      "   macd_signal_z  macd_diff_z     rsi_z  bollinger_hband_z  bollinger_lband_z  \\\n",
      "0       0.591579    -1.164222 -1.530688           1.363061           1.839777   \n",
      "1       0.399630    -1.467105 -1.541599           1.317089           1.758209   \n",
      "2       0.112479    -2.139400 -2.893380           1.289737           1.634182   \n",
      "3      -0.209795    -2.311526 -2.429426           1.248184           1.569059   \n",
      "4      -0.526222    -2.190019 -2.020537           1.199384           1.537532   \n",
      "\n",
      "      atr_z     obv_z    vwap_z  \n",
      "0  0.589827  1.405288  1.603355  \n",
      "1  0.534358  1.364100  1.554836  \n",
      "2  0.710743  0.982966  1.479150  \n",
      "3  0.593083  1.154836  1.414003  \n",
      "4  0.484151  1.326566  1.346550  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "Shape sau khi scaling & dropna: (186212, 24)\n"
     ]
    }
   ],
   "source": [
    "# Block 5 — Feature engineering & scaling\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# --- Danh sách cột FA & TA ---\n",
    "fa_features = [\n",
    "    \"DebtToEquityRatio\",\"EBITMargin\",\"ROA\",\"ROE\",\"ROIC\",\n",
    "    \"BasicEPS\",\"PriceToBook\",\"PriceToEarning\",\n",
    "    \"NetRevenueGrowthYoY\",\"GrossProfitGrowthYoY\"\n",
    "]\n",
    "\n",
    "ta_features = [\n",
    "    \"ema_5\",\"ema_20\",\"ema_50\",\"macd\",\"macd_signal\",\"macd_diff\",\n",
    "    \"rsi\",\"bollinger_hband\",\"bollinger_lband\",\"atr\",\"obv\",\"vwap\"\n",
    "]\n",
    "\n",
    "# --- Chuẩn hoá FA: cross-section min-max scaling theo ngày ---\n",
    "def scale_fa_minmax(df):\n",
    "    df_scaled = df.copy()\n",
    "    for f in fa_features:\n",
    "        vals = df[f].astype(float)\n",
    "        vmin, vmax = vals.min(), vals.max()\n",
    "        if np.isfinite(vmin) and np.isfinite(vmax) and vmax > vmin:\n",
    "            df_scaled[f] = (vals - vmin) / (vmax - vmin)\n",
    "        else:\n",
    "            df_scaled[f] = np.nan\n",
    "    return df_scaled\n",
    "\n",
    "df_scaled_fa = df_with_ta.groupby(\"timestamp\", group_keys=False).apply(scale_fa_minmax)\n",
    "\n",
    "# --- Chuẩn hoá TA: rolling z-score theo từng ticker ---\n",
    "def zscore_rolling(series, window=60):\n",
    "    return (series - series.rolling(window).mean()) / series.rolling(window).std()\n",
    "\n",
    "df_scaled = df_scaled_fa.groupby(\"ticker\", group_keys=False).apply(\n",
    "    lambda g: g.assign(**{f\"{col}_z\": zscore_rolling(g[col], 60) for col in ta_features})\n",
    ")\n",
    "\n",
    "# --- Drop các cột gốc TA, giữ bản z-score ---\n",
    "keep_cols = [\"ticker\",\"timestamp\"] + fa_features + [f\"{col}_z\" for col in ta_features]\n",
    "df_features = df_scaled[keep_cols].dropna().reset_index(drop=True)\n",
    "\n",
    "print(\"Sample features:\")\n",
    "print(df_features.head())\n",
    "print(\"Shape sau khi scaling & dropna:\", df_features.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44f5d94",
   "metadata": {},
   "source": [
    "**Xóa các biến df_with_ta, df_scaled, df_scaled_fa không cần thiết nữa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fee3d19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_with_ta, df_scaled, df_scaled_fa\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3245a6ca",
   "metadata": {},
   "source": [
    "**Block 6: Giảm chiều dữ liệu bằng t-SNE và phân cụm bằng DBSCAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "466d47e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 255, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster sample:\n",
      "  ticker  timestamp  cluster     tsne_x     tsne_y    month\n",
      "0    AAA 2023-06-14       -1  33.616352 -21.516567  2023-06\n",
      "1    AAA 2023-06-15       -1  33.574642 -21.709974  2023-06\n",
      "2    AAA 2023-06-16       -1  35.286522 -41.814465  2023-06\n",
      "3    AAA 2023-06-19       -1  34.876686 -41.506416  2023-06\n",
      "4    AAA 2023-06-20       -1  34.083431 -41.015423  2023-06\n",
      "Số cụm mỗi tháng:\n",
      "month\n",
      "2023-06     19\n",
      "2023-07     65\n",
      "2023-08     77\n",
      "2023-09     38\n",
      "2023-10     82\n",
      "2023-11     53\n",
      "2023-12     83\n",
      "2024-01     89\n",
      "2024-02     31\n",
      "2024-03     64\n",
      "2024-04     44\n",
      "2024-05     72\n",
      "2024-06     95\n",
      "2024-07     90\n",
      "2024-08     65\n",
      "2024-09     90\n",
      "2024-10    108\n",
      "2024-11     78\n",
      "2024-12     74\n",
      "2025-01     46\n",
      "2025-02     73\n",
      "2025-03     92\n",
      "2025-04     50\n",
      "2025-05     78\n",
      "2025-06     94\n",
      "2025-07    108\n",
      "2025-08     80\n",
      "2025-09     19\n",
      "Name: cluster, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Block 6 — Giảm chiều dữ liệu & phân cụm (t-SNE + DBSCAN)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# --- Chọn các cột features để phân cụm ---\n",
    "feature_cols = [\n",
    "    \"DebtToEquityRatio\",\"EBITMargin\",\"ROA\",\"ROE\",\"ROIC\",\n",
    "    \"BasicEPS\",\"PriceToBook\",\"PriceToEarning\",\n",
    "    \"NetRevenueGrowthYoY\",\"GrossProfitGrowthYoY\"\n",
    "] + [c for c in df_features.columns if c.endswith(\"_z\")]\n",
    "\n",
    "# --- Thêm cột tháng để snapshot ---\n",
    "df_features[\"month\"] = df_features[\"timestamp\"].dt.to_period(\"M\")\n",
    "\n",
    "cluster_results = []\n",
    "\n",
    "for (month, g) in df_features.groupby(\"month\"):\n",
    "    if len(g) < 10:   # quá ít cổ phiếu thì bỏ\n",
    "        continue\n",
    "\n",
    "    X = g[feature_cols].values\n",
    "\n",
    "    # --- t-SNE giảm chiều còn 2D ---\n",
    "    tsne = TSNE(n_components=2, perplexity=30, learning_rate=\"auto\", init=\"random\", random_state=42)\n",
    "    X_emb = tsne.fit_transform(X)\n",
    "\n",
    "    # --- DBSCAN phân cụm ---\n",
    "    db = DBSCAN(eps=0.5, min_samples=5).fit(X_emb)\n",
    "    labels = db.labels_\n",
    "\n",
    "    temp = g[[\"ticker\",\"timestamp\"]].copy()\n",
    "    temp[\"cluster\"] = labels\n",
    "    temp[\"tsne_x\"] = X_emb[:,0]\n",
    "    temp[\"tsne_y\"] = X_emb[:,1]\n",
    "    temp[\"month\"]  = str(month)\n",
    "\n",
    "    cluster_results.append(temp)\n",
    "\n",
    "df_clusters = pd.concat(cluster_results, ignore_index=True)\n",
    "\n",
    "print(\"Cluster sample:\")\n",
    "print(df_clusters.head())\n",
    "print(\"Số cụm mỗi tháng:\")\n",
    "print(df_clusters.groupby(\"month\")[\"cluster\"].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdde0916",
   "metadata": {},
   "source": [
    "**Block 7: Xây tensors (clusters mapping) và masks (active stocks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cfadfa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: tensor (503, 64, 17, 22), mask (503, 64, 17, 22) saved.\n",
      "Cluster 1: tensor (503, 64, 14, 22), mask (503, 64, 14, 22) saved.\n",
      "Cluster 2: tensor (503, 64, 15, 22), mask (503, 64, 15, 22) saved.\n",
      "Cluster 3: tensor (503, 64, 20, 22), mask (503, 64, 20, 22) saved.\n",
      "Cluster 4: tensor (503, 64, 24, 22), mask (503, 64, 24, 22) saved.\n",
      "Cluster 5: tensor (503, 64, 22, 22), mask (503, 64, 22, 22) saved.\n",
      "Cluster 6: tensor (503, 64, 20, 22), mask (503, 64, 20, 22) saved.\n",
      "Cluster 7: tensor (503, 64, 26, 22), mask (503, 64, 26, 22) saved.\n",
      "Cluster 8: tensor (503, 64, 21, 22), mask (503, 64, 21, 22) saved.\n",
      "Cluster 9: tensor (503, 64, 23, 22), mask (503, 64, 23, 22) saved.\n",
      "Cluster 10: tensor (503, 64, 21, 22), mask (503, 64, 21, 22) saved.\n",
      "Cluster 11: tensor (503, 64, 26, 22), mask (503, 64, 26, 22) saved.\n",
      "Cluster 12: tensor (503, 64, 29, 22), mask (503, 64, 29, 22) saved.\n",
      "Cluster 13: tensor (503, 64, 23, 22), mask (503, 64, 23, 22) saved.\n",
      "Cluster 14: tensor (503, 64, 28, 22), mask (503, 64, 28, 22) saved.\n",
      "Cluster 15: tensor (503, 64, 26, 22), mask (503, 64, 26, 22) saved.\n",
      "Cluster 16: tensor (503, 64, 27, 22), mask (503, 64, 27, 22) saved.\n",
      "Cluster 17: tensor (503, 64, 24, 22), mask (503, 64, 24, 22) saved.\n",
      "Cluster 18: tensor (503, 64, 23, 22), mask (503, 64, 23, 22) saved.\n",
      "Cluster 19: tensor (503, 64, 27, 22), mask (503, 64, 27, 22) saved.\n",
      "Cluster 20: tensor (503, 64, 28, 22), mask (503, 64, 28, 22) saved.\n",
      "Cluster 21: tensor (503, 64, 25, 22), mask (503, 64, 25, 22) saved.\n",
      "Cluster 22: tensor (503, 64, 24, 22), mask (503, 64, 24, 22) saved.\n",
      "Cluster 23: tensor (503, 64, 25, 22), mask (503, 64, 25, 22) saved.\n",
      "Cluster 24: tensor (503, 64, 25, 22), mask (503, 64, 25, 22) saved.\n",
      "Cluster 25: tensor (503, 64, 25, 22), mask (503, 64, 25, 22) saved.\n",
      "Cluster 26: tensor (503, 64, 26, 22), mask (503, 64, 26, 22) saved.\n",
      "Cluster 27: tensor (503, 64, 27, 22), mask (503, 64, 27, 22) saved.\n",
      "Cluster 28: tensor (503, 64, 27, 22), mask (503, 64, 27, 22) saved.\n",
      "Cluster 29: tensor (503, 64, 25, 22), mask (503, 64, 25, 22) saved.\n",
      "Cluster 30: tensor (503, 64, 24, 22), mask (503, 64, 24, 22) saved.\n",
      "Cluster 31: tensor (503, 64, 21, 22), mask (503, 64, 21, 22) saved.\n",
      "Cluster 32: tensor (503, 64, 22, 22), mask (503, 64, 22, 22) saved.\n",
      "Cluster 33: tensor (503, 64, 25, 22), mask (503, 64, 25, 22) saved.\n",
      "Cluster 34: tensor (503, 64, 25, 22), mask (503, 64, 25, 22) saved.\n",
      "Cluster 35: tensor (503, 64, 25, 22), mask (503, 64, 25, 22) saved.\n",
      "Cluster 36: tensor (503, 64, 24, 22), mask (503, 64, 24, 22) saved.\n",
      "Cluster 37: tensor (503, 64, 27, 22), mask (503, 64, 27, 22) saved.\n",
      "Cluster 38: tensor (503, 64, 23, 22), mask (503, 64, 23, 22) saved.\n",
      "Cluster 39: tensor (503, 64, 21, 22), mask (503, 64, 21, 22) saved.\n",
      "Cluster 40: tensor (503, 64, 25, 22), mask (503, 64, 25, 22) saved.\n",
      "Cluster 41: tensor (503, 64, 27, 22), mask (503, 64, 27, 22) saved.\n",
      "Cluster 42: tensor (503, 64, 23, 22), mask (503, 64, 23, 22) saved.\n",
      "Cluster 43: tensor (503, 64, 22, 22), mask (503, 64, 22, 22) saved.\n",
      "Cluster 44: tensor (503, 64, 25, 22), mask (503, 64, 25, 22) saved.\n",
      "Cluster 45: tensor (503, 64, 26, 22), mask (503, 64, 26, 22) saved.\n",
      "Cluster 46: tensor (503, 64, 23, 22), mask (503, 64, 23, 22) saved.\n",
      "Cluster 47: tensor (503, 64, 21, 22), mask (503, 64, 21, 22) saved.\n",
      "Cluster 48: tensor (503, 64, 19, 22), mask (503, 64, 19, 22) saved.\n",
      "Cluster 49: tensor (503, 64, 18, 22), mask (503, 64, 18, 22) saved.\n",
      "Cluster 50: tensor (503, 64, 21, 22), mask (503, 64, 21, 22) saved.\n",
      "Cluster 51: tensor (503, 64, 25, 22), mask (503, 64, 25, 22) saved.\n",
      "Cluster 52: tensor (503, 64, 21, 22), mask (503, 64, 21, 22) saved.\n",
      "Cluster 53: tensor (503, 64, 21, 22), mask (503, 64, 21, 22) saved.\n",
      "Cluster 54: tensor (503, 64, 21, 22), mask (503, 64, 21, 22) saved.\n",
      "Cluster 55: tensor (503, 64, 18, 22), mask (503, 64, 18, 22) saved.\n",
      "Cluster 56: tensor (503, 64, 20, 22), mask (503, 64, 20, 22) saved.\n",
      "Cluster 57: tensor (503, 64, 22, 22), mask (503, 64, 22, 22) saved.\n",
      "Cluster 58: tensor (503, 64, 21, 22), mask (503, 64, 21, 22) saved.\n",
      "Cluster 59: tensor (503, 64, 23, 22), mask (503, 64, 23, 22) saved.\n",
      "Cluster 60: tensor (503, 64, 18, 22), mask (503, 64, 18, 22) saved.\n",
      "Cluster 61: tensor (503, 64, 21, 22), mask (503, 64, 21, 22) saved.\n",
      "Cluster 62: tensor (503, 64, 18, 22), mask (503, 64, 18, 22) saved.\n",
      "Cluster 63: tensor (503, 64, 19, 22), mask (503, 64, 19, 22) saved.\n",
      "Cluster 64: tensor (503, 64, 16, 22), mask (503, 64, 16, 22) saved.\n",
      "Cluster 65: tensor (503, 64, 15, 22), mask (503, 64, 15, 22) saved.\n",
      "Cluster 66: tensor (503, 64, 17, 22), mask (503, 64, 17, 22) saved.\n",
      "Cluster 67: tensor (503, 64, 17, 22), mask (503, 64, 17, 22) saved.\n",
      "Cluster 68: tensor (503, 64, 18, 22), mask (503, 64, 18, 22) saved.\n",
      "Cluster 69: tensor (503, 64, 17, 22), mask (503, 64, 17, 22) saved.\n",
      "Cluster 70: tensor (503, 64, 20, 22), mask (503, 64, 20, 22) saved.\n",
      "Cluster 71: tensor (503, 64, 16, 22), mask (503, 64, 16, 22) saved.\n",
      "Cluster 72: tensor (503, 64, 17, 22), mask (503, 64, 17, 22) saved.\n",
      "Cluster 73: tensor (503, 64, 15, 22), mask (503, 64, 15, 22) saved.\n",
      "Cluster 74: tensor (503, 64, 14, 22), mask (503, 64, 14, 22) saved.\n",
      "Cluster 75: tensor (503, 64, 14, 22), mask (503, 64, 14, 22) saved.\n",
      "Cluster 76: tensor (503, 64, 12, 22), mask (503, 64, 12, 22) saved.\n",
      "Cluster 77: tensor (503, 64, 12, 22), mask (503, 64, 12, 22) saved.\n",
      "Cluster 78: tensor (503, 64, 10, 22), mask (503, 64, 10, 22) saved.\n",
      "Cluster 79: tensor (503, 64, 10, 22), mask (503, 64, 10, 22) saved.\n",
      "Cluster 80: tensor (503, 64, 9, 22), mask (503, 64, 9, 22) saved.\n",
      "Cluster 81: tensor (503, 64, 9, 22), mask (503, 64, 9, 22) saved.\n",
      "Cluster 82: tensor (503, 64, 12, 22), mask (503, 64, 12, 22) saved.\n",
      "Cluster 83: tensor (503, 64, 9, 22), mask (503, 64, 9, 22) saved.\n",
      "Cluster 84: tensor (503, 64, 7, 22), mask (503, 64, 7, 22) saved.\n",
      "Cluster 85: tensor (503, 64, 9, 22), mask (503, 64, 9, 22) saved.\n",
      "Cluster 86: tensor (503, 64, 7, 22), mask (503, 64, 7, 22) saved.\n",
      "Cluster 87: tensor (503, 64, 9, 22), mask (503, 64, 9, 22) saved.\n",
      "Cluster 88: tensor (503, 64, 8, 22), mask (503, 64, 8, 22) saved.\n",
      "Cluster 89: tensor (503, 64, 5, 22), mask (503, 64, 5, 22) saved.\n",
      "Cluster 90: tensor (503, 64, 6, 22), mask (503, 64, 6, 22) saved.\n",
      "Cluster 91: tensor (503, 64, 5, 22), mask (503, 64, 5, 22) saved.\n",
      "Cluster 92: tensor (503, 64, 5, 22), mask (503, 64, 5, 22) saved.\n",
      "Cluster 93: tensor (503, 64, 2, 22), mask (503, 64, 2, 22) saved.\n",
      "Cluster 94: tensor (503, 64, 2, 22), mask (503, 64, 2, 22) saved.\n",
      "Cluster 95: tensor (503, 64, 2, 22), mask (503, 64, 2, 22) saved.\n",
      "Cluster 96: tensor (503, 64, 2, 22), mask (503, 64, 2, 22) saved.\n",
      "Cluster 97: tensor (503, 64, 2, 22), mask (503, 64, 2, 22) saved.\n",
      "Cluster 98: tensor (503, 64, 2, 22), mask (503, 64, 2, 22) saved.\n",
      "Cluster 99: tensor (503, 64, 3, 22), mask (503, 64, 3, 22) saved.\n",
      "Cluster 100: tensor (503, 64, 1, 22), mask (503, 64, 1, 22) saved.\n",
      "Cluster 101: tensor (503, 64, 2, 22), mask (503, 64, 2, 22) saved.\n",
      "Cluster 102: tensor (503, 64, 2, 22), mask (503, 64, 2, 22) saved.\n",
      "Cluster 103: tensor (503, 64, 1, 22), mask (503, 64, 1, 22) saved.\n",
      "Cluster 104: tensor (503, 64, 2, 22), mask (503, 64, 2, 22) saved.\n",
      "Cluster 105: tensor (503, 64, 3, 22), mask (503, 64, 3, 22) saved.\n",
      "Cluster 106: tensor (503, 64, 1, 22), mask (503, 64, 1, 22) saved.\n",
      "✅ Done Block 7: tensors + masks saved for all clusters.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Block 7 — Tensors & Masks \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, gc, json\n",
    "\n",
    "LOOKBACK = 64   # window size\n",
    "DATA_DIR = \"./tensors/\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "feature_cols = [c for c in df_features.columns if c not in [\"ticker\",\"timestamp\",\"cluster\",\"month\"]]\n",
    "\n",
    "tensor_index = []\n",
    "\n",
    "for c_id, g in df_clusters.groupby(\"cluster\"):\n",
    "    if c_id == -1:   # noise bỏ qua\n",
    "        continue\n",
    "\n",
    "    tickers = sorted(g[\"ticker\"].unique())\n",
    "    g_feat = df_features[df_features[\"ticker\"].isin(tickers)].copy()\n",
    "\n",
    "    # Pivot: index = timestamp, columns = (ticker, feature)\n",
    "    pivoted = g_feat.pivot(index=\"timestamp\", columns=\"ticker\", values=feature_cols)\n",
    "    pivoted.columns = pd.MultiIndex.from_product([tickers, feature_cols])\n",
    "\n",
    "    # Mask\n",
    "    mask_df = ~pivoted.isna()\n",
    "    pivoted_filled = pivoted.ffill().bfill()\n",
    "\n",
    "    T, N, F = len(pivoted_filled.index), len(tickers), len(feature_cols)\n",
    "    X = pivoted_filled.values.reshape(T, N, F)\n",
    "    M = mask_df.values.reshape(T, N, F).astype(np.int8)\n",
    "\n",
    "    cluster_tensors, cluster_masks, cluster_dates = [], [], []\n",
    "    for i in range(LOOKBACK, T):\n",
    "        cluster_tensors.append(X[i-LOOKBACK:i])\n",
    "        cluster_masks.append(M[i-LOOKBACK:i])\n",
    "        cluster_dates.append(pivoted_filled.index[i])  # ngày cuối của window\n",
    "\n",
    "    if cluster_tensors:\n",
    "        X_arr = np.array(cluster_tensors, dtype=np.float16)  # tiết kiệm RAM\n",
    "        M_arr = np.array(cluster_masks, dtype=np.int8)\n",
    "\n",
    "        tensor_file = f\"cluster_{c_id}_tensor.npy\"\n",
    "        mask_file   = f\"cluster_{c_id}_mask.npy\"\n",
    "        np.save(os.path.join(DATA_DIR, tensor_file), X_arr)\n",
    "        np.save(os.path.join(DATA_DIR, mask_file), M_arr)\n",
    "\n",
    "        tensor_index.append({\n",
    "            \"cluster\": int(c_id),\n",
    "            \"tickers\": tickers,\n",
    "            \"dates\": [str(d) for d in cluster_dates],   # ngày T\n",
    "            \"dates_shifted\": [str(d+pd.Timedelta(days=1)) for d in cluster_dates],  # T+1 (cho reward)\n",
    "            \"tensor_file\": tensor_file,\n",
    "            \"mask_file\": mask_file\n",
    "        })\n",
    "\n",
    "        print(f\"Cluster {c_id}: tensor {X_arr.shape}, mask {M_arr.shape} saved.\")\n",
    "\n",
    "    del g_feat, pivoted, pivoted_filled, mask_df, X, M, cluster_tensors, cluster_masks\n",
    "    gc.collect()\n",
    "\n",
    "# Save metadata\n",
    "with open(os.path.join(DATA_DIR, \"tensor_index.json\"), \"w\") as f:\n",
    "    json.dump(tensor_index, f, indent=2)\n",
    "\n",
    "print(\"✅ Done Block 7: tensors + masks saved for all clusters.\")\n",
    "\n",
    "# Xoá df_features giảm RAM\n",
    "del df_features\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95417aff",
   "metadata": {},
   "source": [
    "**Block 7.5: Chuẩn bị dữ liệu backtest(loại bỏ các cột dữ liệu không cần thiết nữa)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bf1ef80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done Block 7.5: df_backtest sẵn sàng cho reward.\n",
      "Kích thước df_backtest: (261234, 3)\n",
      "Tickers unique: 391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Block 7.5 — Chuẩn bị dữ liệu backtest cho reward thật\n",
    "import gc\n",
    "\n",
    "# Chỉ giữ dữ liệu cần thiết để tính reward (close price)\n",
    "# df_price có từ Block 1 (OHLCV đầy đủ)\n",
    "df_backtest = df_price[[\"ticker\", \"timestamp\", \"close\"]].copy()\n",
    "\n",
    "# Ép timestamp về dạng datetime để đồng bộ\n",
    "df_backtest[\"timestamp\"] = pd.to_datetime(df_backtest[\"timestamp\"])\n",
    "\n",
    "print(\"✅ Done Block 7.5: df_backtest sẵn sàng cho reward.\")\n",
    "print(\"Kích thước df_backtest:\", df_backtest.shape)\n",
    "print(\"Tickers unique:\", df_backtest[\"ticker\"].nunique())\n",
    "\n",
    "# Xóa những biến không còn cần để tiết kiệm RAM\n",
    "del df_price\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c7aa4e",
   "metadata": {},
   "source": [
    "**Block 8: Huấn luyện A3C theo từng cụm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7090b945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 | X=(503, 64, 17, 22)\n",
      "  Epoch 1/3, Loss=-0.0168\n",
      "  Epoch 2/3, Loss=-0.2511\n",
      "  Epoch 3/3, Loss=-0.3643\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_0.pt\n",
      "Cluster 1 | X=(503, 64, 14, 22)\n",
      "  Epoch 1/3, Loss=-0.2780\n",
      "  Epoch 2/3, Loss=-0.2565\n",
      "  Epoch 3/3, Loss=-0.3481\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_1.pt\n",
      "Cluster 2 | X=(503, 64, 15, 22)\n",
      "  Epoch 1/3, Loss=0.1427\n",
      "  Epoch 2/3, Loss=-0.2206\n",
      "  Epoch 3/3, Loss=-0.3237\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_2.pt\n",
      "Cluster 3 | X=(503, 64, 20, 22)\n",
      "  Epoch 1/3, Loss=-0.4154\n",
      "  Epoch 2/3, Loss=-0.4415\n",
      "  Epoch 3/3, Loss=-0.4575\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_3.pt\n",
      "Cluster 4 | X=(503, 64, 24, 22)\n",
      "  Epoch 1/3, Loss=-0.4183\n",
      "  Epoch 2/3, Loss=-0.4866\n",
      "  Epoch 3/3, Loss=-0.5151\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_4.pt\n",
      "Cluster 5 | X=(503, 64, 22, 22)\n",
      "  Epoch 1/3, Loss=-0.1892\n",
      "  Epoch 2/3, Loss=-0.2718\n",
      "  Epoch 3/3, Loss=-0.3787\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_5.pt\n",
      "Cluster 6 | X=(503, 64, 20, 22)\n",
      "  Epoch 1/3, Loss=-0.5702\n",
      "  Epoch 2/3, Loss=-0.4656\n",
      "  Epoch 3/3, Loss=-0.4096\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_6.pt\n",
      "Cluster 7 | X=(503, 64, 26, 22)\n",
      "  Epoch 1/3, Loss=-0.1176\n",
      "  Epoch 2/3, Loss=-0.5466\n",
      "  Epoch 3/3, Loss=-0.5250\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_7.pt\n",
      "Cluster 8 | X=(503, 64, 21, 22)\n",
      "  Epoch 1/3, Loss=-0.6163\n",
      "  Epoch 2/3, Loss=-0.3876\n",
      "  Epoch 3/3, Loss=-0.4593\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_8.pt\n",
      "Cluster 9 | X=(503, 64, 23, 22)\n",
      "  Epoch 1/3, Loss=-0.6322\n",
      "  Epoch 2/3, Loss=-0.4723\n",
      "  Epoch 3/3, Loss=-0.5285\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_9.pt\n",
      "Cluster 10 | X=(503, 64, 21, 22)\n",
      "  Epoch 1/3, Loss=-0.3094\n",
      "  Epoch 2/3, Loss=-0.4486\n",
      "  Epoch 3/3, Loss=-0.4584\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_10.pt\n",
      "Cluster 11 | X=(503, 64, 26, 22)\n",
      "  Epoch 1/3, Loss=-0.3889\n",
      "  Epoch 2/3, Loss=-0.5076\n",
      "  Epoch 3/3, Loss=-0.5787\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_11.pt\n",
      "Cluster 12 | X=(503, 64, 29, 22)\n",
      "  Epoch 1/3, Loss=-0.5711\n",
      "  Epoch 2/3, Loss=-0.6023\n",
      "  Epoch 3/3, Loss=-0.6046\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_12.pt\n",
      "Cluster 13 | X=(503, 64, 23, 22)\n",
      "  Epoch 1/3, Loss=-1.2058\n",
      "  Epoch 2/3, Loss=-0.6081\n",
      "  Epoch 3/3, Loss=-0.4908\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_13.pt\n",
      "Cluster 14 | X=(503, 64, 28, 22)\n",
      "  Epoch 1/3, Loss=-0.8401\n",
      "  Epoch 2/3, Loss=-0.5718\n",
      "  Epoch 3/3, Loss=-0.6211\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_14.pt\n",
      "Cluster 15 | X=(503, 64, 26, 22)\n",
      "  Epoch 1/3, Loss=-0.4543\n",
      "  Epoch 2/3, Loss=-0.5589\n",
      "  Epoch 3/3, Loss=-0.5439\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_15.pt\n",
      "Cluster 16 | X=(503, 64, 27, 22)\n",
      "  Epoch 1/3, Loss=-0.9823\n",
      "  Epoch 2/3, Loss=-0.6044\n",
      "  Epoch 3/3, Loss=-0.5788\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_16.pt\n",
      "Cluster 17 | X=(503, 64, 24, 22)\n",
      "  Epoch 1/3, Loss=-1.0051\n",
      "  Epoch 2/3, Loss=-0.5135\n",
      "  Epoch 3/3, Loss=-0.5421\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_17.pt\n",
      "Cluster 18 | X=(503, 64, 23, 22)\n",
      "  Epoch 1/3, Loss=-0.4937\n",
      "  Epoch 2/3, Loss=-0.4614\n",
      "  Epoch 3/3, Loss=-0.4992\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_18.pt\n",
      "Cluster 19 | X=(503, 64, 27, 22)\n",
      "  Epoch 1/3, Loss=-0.0987\n",
      "  Epoch 2/3, Loss=-0.6309\n",
      "  Epoch 3/3, Loss=-0.5485\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_19.pt\n",
      "Cluster 20 | X=(503, 64, 28, 22)\n",
      "  Epoch 1/3, Loss=-0.6137\n",
      "  Epoch 2/3, Loss=-0.6675\n",
      "  Epoch 3/3, Loss=-0.5722\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_20.pt\n",
      "Cluster 21 | X=(503, 64, 25, 22)\n",
      "  Epoch 1/3, Loss=0.1360\n",
      "  Epoch 2/3, Loss=-0.5283\n",
      "  Epoch 3/3, Loss=-0.5153\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_21.pt\n",
      "Cluster 22 | X=(503, 64, 24, 22)\n",
      "  Epoch 1/3, Loss=-0.8217\n",
      "  Epoch 2/3, Loss=-0.5193\n",
      "  Epoch 3/3, Loss=-0.4941\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_22.pt\n",
      "Cluster 23 | X=(503, 64, 25, 22)\n",
      "  Epoch 1/3, Loss=-0.7918\n",
      "  Epoch 2/3, Loss=-0.5545\n",
      "  Epoch 3/3, Loss=-0.5423\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_23.pt\n",
      "Cluster 24 | X=(503, 64, 25, 22)\n",
      "  Epoch 1/3, Loss=-0.5386\n",
      "  Epoch 2/3, Loss=-0.5639\n",
      "  Epoch 3/3, Loss=-0.5272\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_24.pt\n",
      "Cluster 25 | X=(503, 64, 25, 22)\n",
      "  Epoch 1/3, Loss=-0.3238\n",
      "  Epoch 2/3, Loss=-0.5274\n",
      "  Epoch 3/3, Loss=-0.5558\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_25.pt\n",
      "Cluster 26 | X=(503, 64, 26, 22)\n",
      "  Epoch 1/3, Loss=-0.4669\n",
      "  Epoch 2/3, Loss=-0.5470\n",
      "  Epoch 3/3, Loss=-0.5378\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_26.pt\n",
      "Cluster 27 | X=(503, 64, 27, 22)\n",
      "  Epoch 1/3, Loss=-0.1554\n",
      "  Epoch 2/3, Loss=-0.5350\n",
      "  Epoch 3/3, Loss=-0.5535\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_27.pt\n",
      "Cluster 28 | X=(503, 64, 27, 22)\n",
      "  Epoch 1/3, Loss=-0.5548\n",
      "  Epoch 2/3, Loss=-0.5790\n",
      "  Epoch 3/3, Loss=-0.5841\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_28.pt\n",
      "Cluster 29 | X=(503, 64, 25, 22)\n",
      "  Epoch 1/3, Loss=-0.0875\n",
      "  Epoch 2/3, Loss=-0.5329\n",
      "  Epoch 3/3, Loss=-0.5330\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_29.pt\n",
      "Cluster 30 | X=(503, 64, 24, 22)\n",
      "  Epoch 1/3, Loss=-0.5318\n",
      "  Epoch 2/3, Loss=-0.4399\n",
      "  Epoch 3/3, Loss=-0.5645\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_30.pt\n",
      "Cluster 31 | X=(503, 64, 21, 22)\n",
      "  Epoch 1/3, Loss=-0.5456\n",
      "  Epoch 2/3, Loss=-0.4671\n",
      "  Epoch 3/3, Loss=-0.4800\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_31.pt\n",
      "Cluster 32 | X=(503, 64, 22, 22)\n",
      "  Epoch 1/3, Loss=-0.9633\n",
      "  Epoch 2/3, Loss=-0.6149\n",
      "  Epoch 3/3, Loss=-0.4780\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_32.pt\n",
      "Cluster 33 | X=(503, 64, 25, 22)\n",
      "  Epoch 1/3, Loss=-0.5830\n",
      "  Epoch 2/3, Loss=-0.5728\n",
      "  Epoch 3/3, Loss=-0.5276\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_33.pt\n",
      "Cluster 34 | X=(503, 64, 25, 22)\n",
      "  Epoch 1/3, Loss=0.1235\n",
      "  Epoch 2/3, Loss=-0.5195\n",
      "  Epoch 3/3, Loss=-0.5115\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_34.pt\n",
      "Cluster 35 | X=(503, 64, 25, 22)\n",
      "  Epoch 1/3, Loss=-0.8311\n",
      "  Epoch 2/3, Loss=-0.5618\n",
      "  Epoch 3/3, Loss=-0.5515\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_35.pt\n",
      "Cluster 36 | X=(503, 64, 24, 22)\n",
      "  Epoch 1/3, Loss=-0.5195\n",
      "  Epoch 2/3, Loss=-0.5155\n",
      "  Epoch 3/3, Loss=-0.5312\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_36.pt\n",
      "Cluster 37 | X=(503, 64, 27, 22)\n",
      "  Epoch 1/3, Loss=-0.6522\n",
      "  Epoch 2/3, Loss=-0.5234\n",
      "  Epoch 3/3, Loss=-0.6558\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_37.pt\n",
      "Cluster 38 | X=(503, 64, 23, 22)\n",
      "  Epoch 1/3, Loss=-0.2614\n",
      "  Epoch 2/3, Loss=-0.5516\n",
      "  Epoch 3/3, Loss=-0.4798\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_38.pt\n",
      "Cluster 39 | X=(503, 64, 21, 22)\n",
      "  Epoch 1/3, Loss=-0.3920\n",
      "  Epoch 2/3, Loss=-0.4774\n",
      "  Epoch 3/3, Loss=-0.4611\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_39.pt\n",
      "Cluster 40 | X=(503, 64, 25, 22)\n",
      "  Epoch 1/3, Loss=-0.5348\n",
      "  Epoch 2/3, Loss=-0.5232\n",
      "  Epoch 3/3, Loss=-0.5462\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_40.pt\n",
      "Cluster 41 | X=(503, 64, 27, 22)\n",
      "  Epoch 1/3, Loss=-0.6679\n",
      "  Epoch 2/3, Loss=-0.5589\n",
      "  Epoch 3/3, Loss=-0.5866\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_41.pt\n",
      "Cluster 42 | X=(503, 64, 23, 22)\n",
      "  Epoch 1/3, Loss=-0.8910\n",
      "  Epoch 2/3, Loss=-0.5382\n",
      "  Epoch 3/3, Loss=-0.5183\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_42.pt\n",
      "Cluster 43 | X=(503, 64, 22, 22)\n",
      "  Epoch 1/3, Loss=-0.3768\n",
      "  Epoch 2/3, Loss=-0.5918\n",
      "  Epoch 3/3, Loss=-0.1397\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_43.pt\n",
      "Cluster 44 | X=(503, 64, 25, 22)\n",
      "  Epoch 1/3, Loss=-0.6508\n",
      "  Epoch 2/3, Loss=-0.5380\n",
      "  Epoch 3/3, Loss=-0.5608\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_44.pt\n",
      "Cluster 45 | X=(503, 64, 26, 22)\n",
      "  Epoch 1/3, Loss=-0.5346\n",
      "  Epoch 2/3, Loss=-0.5557\n",
      "  Epoch 3/3, Loss=-0.5535\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_45.pt\n",
      "Cluster 46 | X=(503, 64, 23, 22)\n",
      "  Epoch 1/3, Loss=-0.5680\n",
      "  Epoch 2/3, Loss=-0.4529\n",
      "  Epoch 3/3, Loss=-0.5176\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_46.pt\n",
      "Cluster 47 | X=(503, 64, 21, 22)\n",
      "  Epoch 1/3, Loss=0.5205\n",
      "  Epoch 2/3, Loss=-0.4080\n",
      "  Epoch 3/3, Loss=-0.4249\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_47.pt\n",
      "Cluster 48 | X=(503, 64, 19, 22)\n",
      "  Epoch 1/3, Loss=-1.1990\n",
      "  Epoch 2/3, Loss=-0.4886\n",
      "  Epoch 3/3, Loss=-0.4009\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_48.pt\n",
      "Cluster 49 | X=(503, 64, 18, 22)\n",
      "  Epoch 1/3, Loss=-0.5069\n",
      "  Epoch 2/3, Loss=-0.3771\n",
      "  Epoch 3/3, Loss=-0.3458\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_49.pt\n",
      "Cluster 50 | X=(503, 64, 21, 22)\n",
      "  Epoch 1/3, Loss=-0.6529\n",
      "  Epoch 2/3, Loss=-0.4427\n",
      "  Epoch 3/3, Loss=-0.4618\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_50.pt\n",
      "Cluster 51 | X=(503, 64, 25, 22)\n",
      "  Epoch 1/3, Loss=-0.5516\n",
      "  Epoch 2/3, Loss=-0.5003\n",
      "  Epoch 3/3, Loss=-0.5664\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_51.pt\n",
      "Cluster 52 | X=(503, 64, 21, 22)\n",
      "  Epoch 1/3, Loss=-0.1699\n",
      "  Epoch 2/3, Loss=-0.4637\n",
      "  Epoch 3/3, Loss=-0.4205\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_52.pt\n",
      "Cluster 53 | X=(503, 64, 21, 22)\n",
      "  Epoch 1/3, Loss=0.0459\n",
      "  Epoch 2/3, Loss=-0.4290\n",
      "  Epoch 3/3, Loss=-0.4274\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_53.pt\n",
      "Cluster 54 | X=(503, 64, 21, 22)\n",
      "  Epoch 1/3, Loss=0.3939\n",
      "  Epoch 2/3, Loss=-0.3854\n",
      "  Epoch 3/3, Loss=-0.4042\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_54.pt\n",
      "Cluster 55 | X=(503, 64, 18, 22)\n",
      "  Epoch 1/3, Loss=-0.3116\n",
      "  Epoch 2/3, Loss=-0.3525\n",
      "  Epoch 3/3, Loss=-0.3601\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_55.pt\n",
      "Cluster 56 | X=(503, 64, 20, 22)\n",
      "  Epoch 1/3, Loss=-0.3390\n",
      "  Epoch 2/3, Loss=-0.2942\n",
      "  Epoch 3/3, Loss=-0.4765\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_56.pt\n",
      "Cluster 57 | X=(503, 64, 22, 22)\n",
      "  Epoch 1/3, Loss=-1.1559\n",
      "  Epoch 2/3, Loss=-0.5086\n",
      "  Epoch 3/3, Loss=-0.5139\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_57.pt\n",
      "Cluster 58 | X=(503, 64, 21, 22)\n",
      "  Epoch 1/3, Loss=-0.2134\n",
      "  Epoch 2/3, Loss=-0.4625\n",
      "  Epoch 3/3, Loss=-0.4477\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_58.pt\n",
      "Cluster 59 | X=(503, 64, 23, 22)\n",
      "  Epoch 1/3, Loss=-0.7099\n",
      "  Epoch 2/3, Loss=-0.5453\n",
      "  Epoch 3/3, Loss=-0.5070\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_59.pt\n",
      "Cluster 60 | X=(503, 64, 18, 22)\n",
      "  Epoch 1/3, Loss=-0.2337\n",
      "  Epoch 2/3, Loss=-0.3572\n",
      "  Epoch 3/3, Loss=-0.3744\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_60.pt\n",
      "Cluster 61 | X=(503, 64, 21, 22)\n",
      "  Epoch 1/3, Loss=-0.4620\n",
      "  Epoch 2/3, Loss=-0.3992\n",
      "  Epoch 3/3, Loss=-0.4642\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_61.pt\n",
      "Cluster 62 | X=(503, 64, 18, 22)\n",
      "  Epoch 1/3, Loss=-1.0715\n",
      "  Epoch 2/3, Loss=-0.4998\n",
      "  Epoch 3/3, Loss=-0.3162\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_62.pt\n",
      "Cluster 63 | X=(503, 64, 19, 22)\n",
      "  Epoch 1/3, Loss=0.1833\n",
      "  Epoch 2/3, Loss=-0.3684\n",
      "  Epoch 3/3, Loss=-0.3949\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_63.pt\n",
      "Cluster 64 | X=(503, 64, 16, 22)\n",
      "  Epoch 1/3, Loss=-0.1857\n",
      "  Epoch 2/3, Loss=-0.3204\n",
      "  Epoch 3/3, Loss=-0.3625\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_64.pt\n",
      "Cluster 65 | X=(503, 64, 15, 22)\n",
      "  Epoch 1/3, Loss=0.2035\n",
      "  Epoch 2/3, Loss=-0.2992\n",
      "  Epoch 3/3, Loss=-0.3437\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_65.pt\n",
      "Cluster 66 | X=(503, 64, 17, 22)\n",
      "  Epoch 1/3, Loss=-0.4186\n",
      "  Epoch 2/3, Loss=-0.3707\n",
      "  Epoch 3/3, Loss=-0.3829\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_66.pt\n",
      "Cluster 67 | X=(503, 64, 17, 22)\n",
      "  Epoch 1/3, Loss=-0.1366\n",
      "  Epoch 2/3, Loss=-0.2753\n",
      "  Epoch 3/3, Loss=-0.3514\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_67.pt\n",
      "Cluster 68 | X=(503, 64, 18, 22)\n",
      "  Epoch 1/3, Loss=-0.3485\n",
      "  Epoch 2/3, Loss=-0.3788\n",
      "  Epoch 3/3, Loss=-0.4230\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_68.pt\n",
      "Cluster 69 | X=(503, 64, 17, 22)\n",
      "  Epoch 1/3, Loss=-0.6856\n",
      "  Epoch 2/3, Loss=-0.4611\n",
      "  Epoch 3/3, Loss=-0.3804\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_69.pt\n",
      "Cluster 70 | X=(503, 64, 20, 22)\n",
      "  Epoch 1/3, Loss=-0.2668\n",
      "  Epoch 2/3, Loss=-0.3785\n",
      "  Epoch 3/3, Loss=-0.4421\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_70.pt\n",
      "Cluster 71 | X=(503, 64, 16, 22)\n",
      "  Epoch 1/3, Loss=-0.2021\n",
      "  Epoch 2/3, Loss=-0.3019\n",
      "  Epoch 3/3, Loss=-0.2960\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_71.pt\n",
      "Cluster 72 | X=(503, 64, 17, 22)\n",
      "  Epoch 1/3, Loss=-0.4386\n",
      "  Epoch 2/3, Loss=-0.4397\n",
      "  Epoch 3/3, Loss=-0.3389\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_72.pt\n",
      "Cluster 73 | X=(503, 64, 15, 22)\n",
      "  Epoch 1/3, Loss=-0.5219\n",
      "  Epoch 2/3, Loss=-0.2814\n",
      "  Epoch 3/3, Loss=-0.3798\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_73.pt\n",
      "Cluster 74 | X=(503, 64, 14, 22)\n",
      "  Epoch 1/3, Loss=0.0382\n",
      "  Epoch 2/3, Loss=-0.2417\n",
      "  Epoch 3/3, Loss=-0.3350\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_74.pt\n",
      "Cluster 75 | X=(503, 64, 14, 22)\n",
      "  Epoch 1/3, Loss=-0.3707\n",
      "  Epoch 2/3, Loss=-0.3303\n",
      "  Epoch 3/3, Loss=-0.3038\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_75.pt\n",
      "Cluster 76 | X=(503, 64, 12, 22)\n",
      "  Epoch 1/3, Loss=-0.2245\n",
      "  Epoch 2/3, Loss=-0.2743\n",
      "  Epoch 3/3, Loss=-0.2293\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_76.pt\n",
      "Cluster 77 | X=(503, 64, 12, 22)\n",
      "  Epoch 1/3, Loss=-0.7476\n",
      "  Epoch 2/3, Loss=-0.2501\n",
      "  Epoch 3/3, Loss=-0.2376\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_77.pt\n",
      "Cluster 78 | X=(503, 64, 10, 22)\n",
      "  Epoch 1/3, Loss=0.4805\n",
      "  Epoch 2/3, Loss=-0.1709\n",
      "  Epoch 3/3, Loss=-0.0846\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_78.pt\n",
      "Cluster 79 | X=(503, 64, 10, 22)\n",
      "  Epoch 1/3, Loss=-0.1746\n",
      "  Epoch 2/3, Loss=-0.2294\n",
      "  Epoch 3/3, Loss=-0.2111\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_79.pt\n",
      "Cluster 80 | X=(503, 64, 9, 22)\n",
      "  Epoch 1/3, Loss=-0.2343\n",
      "  Epoch 2/3, Loss=-0.2476\n",
      "  Epoch 3/3, Loss=-0.2925\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_80.pt\n",
      "Cluster 81 | X=(503, 64, 9, 22)\n",
      "  Epoch 1/3, Loss=0.1806\n",
      "  Epoch 2/3, Loss=-0.2604\n",
      "  Epoch 3/3, Loss=-0.1369\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_81.pt\n",
      "Cluster 82 | X=(503, 64, 12, 22)\n",
      "  Epoch 1/3, Loss=0.9125\n",
      "  Epoch 2/3, Loss=-0.4470\n",
      "  Epoch 3/3, Loss=-0.0596\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_82.pt\n",
      "Cluster 83 | X=(503, 64, 9, 22)\n",
      "  Epoch 1/3, Loss=-0.4410\n",
      "  Epoch 2/3, Loss=-0.1133\n",
      "  Epoch 3/3, Loss=-0.1851\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_83.pt\n",
      "Cluster 84 | X=(503, 64, 7, 22)\n",
      "  Epoch 1/3, Loss=-0.7852\n",
      "  Epoch 2/3, Loss=-0.0918\n",
      "  Epoch 3/3, Loss=-0.0793\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_84.pt\n",
      "Cluster 85 | X=(503, 64, 9, 22)\n",
      "  Epoch 1/3, Loss=-0.1901\n",
      "  Epoch 2/3, Loss=-0.2149\n",
      "  Epoch 3/3, Loss=-0.1059\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_85.pt\n",
      "Cluster 86 | X=(503, 64, 7, 22)\n",
      "  Epoch 1/3, Loss=-0.1687\n",
      "  Epoch 2/3, Loss=-0.1713\n",
      "  Epoch 3/3, Loss=-0.1471\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_86.pt\n",
      "Cluster 87 | X=(503, 64, 9, 22)\n",
      "  Epoch 1/3, Loss=-0.3489\n",
      "  Epoch 2/3, Loss=-0.1550\n",
      "  Epoch 3/3, Loss=-0.2720\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_87.pt\n",
      "Cluster 88 | X=(503, 64, 8, 22)\n",
      "  Epoch 1/3, Loss=-0.3037\n",
      "  Epoch 2/3, Loss=-0.0475\n",
      "  Epoch 3/3, Loss=-0.1597\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_88.pt\n",
      "Cluster 89 | X=(503, 64, 5, 22)\n",
      "  Epoch 1/3, Loss=-0.0486\n",
      "  Epoch 2/3, Loss=-0.0293\n",
      "  Epoch 3/3, Loss=-0.1830\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_89.pt\n",
      "Cluster 90 | X=(503, 64, 6, 22)\n",
      "  Epoch 1/3, Loss=0.0070\n",
      "  Epoch 2/3, Loss=-0.2935\n",
      "  Epoch 3/3, Loss=-0.0966\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_90.pt\n",
      "Cluster 91 | X=(503, 64, 5, 22)\n",
      "  Epoch 1/3, Loss=-0.2059\n",
      "  Epoch 2/3, Loss=-0.0534\n",
      "  Epoch 3/3, Loss=-0.1290\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_91.pt\n",
      "Cluster 92 | X=(503, 64, 5, 22)\n",
      "  Epoch 1/3, Loss=-0.6758\n",
      "  Epoch 2/3, Loss=-0.1620\n",
      "  Epoch 3/3, Loss=-0.2085\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_92.pt\n",
      "Cluster 93 | X=(503, 64, 2, 22)\n",
      "  Epoch 1/3, Loss=0.2425\n",
      "  Epoch 2/3, Loss=0.0247\n",
      "  Epoch 3/3, Loss=-0.0598\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_93.pt\n",
      "Cluster 94 | X=(503, 64, 2, 22)\n",
      "  Epoch 1/3, Loss=-0.1423\n",
      "  Epoch 2/3, Loss=0.0242\n",
      "  Epoch 3/3, Loss=-0.0363\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_94.pt\n",
      "Cluster 95 | X=(503, 64, 2, 22)\n",
      "  Epoch 1/3, Loss=0.1832\n",
      "  Epoch 2/3, Loss=-0.0348\n",
      "  Epoch 3/3, Loss=-0.1134\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_95.pt\n",
      "Cluster 96 | X=(503, 64, 2, 22)\n",
      "  Epoch 1/3, Loss=0.0007\n",
      "  Epoch 2/3, Loss=-0.0219\n",
      "  Epoch 3/3, Loss=-0.0859\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_96.pt\n",
      "Cluster 97 | X=(503, 64, 2, 22)\n",
      "  Epoch 1/3, Loss=-0.0978\n",
      "  Epoch 2/3, Loss=-0.0169\n",
      "  Epoch 3/3, Loss=-0.0041\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_97.pt\n",
      "Cluster 98 | X=(503, 64, 2, 22)\n",
      "  Epoch 1/3, Loss=-0.1284\n",
      "  Epoch 2/3, Loss=-0.1178\n",
      "  Epoch 3/3, Loss=-0.0858\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_98.pt\n",
      "Cluster 99 | X=(503, 64, 3, 22)\n",
      "  Epoch 1/3, Loss=-0.4131\n",
      "  Epoch 2/3, Loss=-0.0291\n",
      "  Epoch 3/3, Loss=-0.0009\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_99.pt\n",
      "Cluster 100 | X=(503, 64, 1, 22)\n",
      "  Epoch 1/3, Loss=0.1128\n",
      "  Epoch 2/3, Loss=0.1016\n",
      "  Epoch 3/3, Loss=0.0597\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_100.pt\n",
      "Cluster 101 | X=(503, 64, 2, 22)\n",
      "  Epoch 1/3, Loss=0.5142\n",
      "  Epoch 2/3, Loss=0.0659\n",
      "  Epoch 3/3, Loss=-0.1578\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_101.pt\n",
      "Cluster 102 | X=(503, 64, 2, 22)\n",
      "  Epoch 1/3, Loss=-0.0222\n",
      "  Epoch 2/3, Loss=-0.0749\n",
      "  Epoch 3/3, Loss=-0.0621\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_102.pt\n",
      "Cluster 103 | X=(503, 64, 1, 22)\n",
      "  Epoch 1/3, Loss=0.0592\n",
      "  Epoch 2/3, Loss=-0.0110\n",
      "  Epoch 3/3, Loss=-0.0638\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_103.pt\n",
      "Cluster 104 | X=(503, 64, 2, 22)\n",
      "  Epoch 1/3, Loss=0.2193\n",
      "  Epoch 2/3, Loss=-0.1436\n",
      "  Epoch 3/3, Loss=-0.1653\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_104.pt\n",
      "Cluster 105 | X=(503, 64, 3, 22)\n",
      "  Epoch 1/3, Loss=0.0777\n",
      "  Epoch 2/3, Loss=-0.1991\n",
      "  Epoch 3/3, Loss=-0.0089\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_105.pt\n",
      "Cluster 106 | X=(503, 64, 1, 22)\n",
      "  Epoch 1/3, Loss=0.1389\n",
      "  Epoch 2/3, Loss=-0.0444\n",
      "  Epoch 3/3, Loss=-0.1295\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_106.pt\n",
      "✅ Done Block 8: signals saved to ./signals/a3c_signals.csv, models in ./models/\n"
     ]
    }
   ],
   "source": [
    "# Block 8 — A3C multi-stock per-cluster \n",
    "\n",
    "import os, gc, json, csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "DATA_DIR = \"./tensors/\"\n",
    "SIG_DIR  = \"./signals/\"\n",
    "MODEL_DIR = \"./models/\"\n",
    "os.makedirs(SIG_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "SIG_FILE = os.path.join(SIG_DIR, \"a3c_signals.csv\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Reset signals file\n",
    "if os.path.exists(SIG_FILE):\n",
    "    os.remove(SIG_FILE)\n",
    "with open(SIG_FILE, \"w\", newline=\"\") as f:\n",
    "    csv.writer(f).writerow([\"date\",\"ticker\",\"signal\"])\n",
    "\n",
    "# Load metadata\n",
    "with open(os.path.join(DATA_DIR, \"tensor_index.json\"), \"r\") as f:\n",
    "    tensor_index = json.load(f)\n",
    "\n",
    "# --- Model ---\n",
    "class A3CNet(nn.Module):\n",
    "    def __init__(self, n_features, hidden=64):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=n_features, hidden_size=hidden, batch_first=True)\n",
    "        self.actor = nn.Linear(hidden, 3)   # short, flat, long\n",
    "        self.critic = nn.Linear(hidden, 1)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        h = out[:, -1, :]\n",
    "        return self.actor(h), self.critic(h)\n",
    "\n",
    "# --- Loss ---\n",
    "def a3c_loss(logits, values, actions, rewards, beta=0.01):\n",
    "    adv = rewards - values.squeeze(-1)\n",
    "    critic = adv.pow(2).mean()\n",
    "    logp = torch.log_softmax(logits, dim=-1)\n",
    "    actor = -(logp.gather(1, actions.unsqueeze(1)).squeeze(1) * adv.detach()).mean()\n",
    "    entropy = -(torch.softmax(logits, dim=-1) * logp).sum(-1).mean()\n",
    "    return actor + 0.5*critic - beta*entropy\n",
    "\n",
    "# --- Training & inference ---\n",
    "def process_cluster(meta, epochs=3, lr=1e-3, batch_size=256):\n",
    "    c_id, tickers, dates, dates_shifted = meta[\"cluster\"], meta[\"tickers\"], meta[\"dates\"], meta[\"dates_shifted\"]\n",
    "    X = np.load(os.path.join(DATA_DIR, meta[\"tensor_file\"]), mmap_mode=\"r\")\n",
    "    M = np.load(os.path.join(DATA_DIR, meta[\"mask_file\"]), mmap_mode=\"r\")\n",
    "    if X.size == 0:\n",
    "        return\n",
    "    B, T, N, F = X.shape\n",
    "    print(f\"Cluster {c_id} | X={X.shape}\")\n",
    "\n",
    "    # --- Lấy giá để tính reward ---\n",
    "    px = []\n",
    "    for tk in tickers:\n",
    "        s = df_backtest[df_backtest[\"ticker\"]==tk].set_index(\"timestamp\")[\"close\"]\n",
    "        s = s.reindex(dates_shifted).ffill().bfill().values  # dùng dates_shifted\n",
    "        px.append(s)\n",
    "    px = np.stack(px, axis=1)  # shape (B, N)\n",
    "    r = np.zeros_like(px, dtype=np.float32)\n",
    "    r[1:] = np.log(px[1:] / np.maximum(px[:-1], 1e-9))  # daily log-return\n",
    "\n",
    "    # --- Model + optimizer ---\n",
    "    model = A3CNet(F).to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Mini-batch generator\n",
    "    total = B*N\n",
    "    def iterator():\n",
    "        for start in range(0, total, batch_size):\n",
    "            end = min(total, start+batch_size)\n",
    "            xb, mb, rb, idx = [], [], [], []\n",
    "            for s in range(start,end):\n",
    "                b, n = divmod(s, N)\n",
    "                xb.append(X[b,:,n,:])\n",
    "                mb.append(M[b,:,n,:])\n",
    "                rb.append(r[b,n])\n",
    "                idx.append((b,n))\n",
    "            yield np.stack(xb), np.stack(mb), np.array(rb), idx\n",
    "\n",
    "    # --- Train ---\n",
    "    for ep in range(epochs):\n",
    "        loss_ep = 0\n",
    "        for xb, mb, rb, _ in iterator():\n",
    "            xb = torch.tensor(xb, dtype=torch.float32).to(device)\n",
    "            rb = torch.tensor(rb, dtype=torch.float32).to(device)\n",
    "            # mask vào input (loại bỏ chỗ NaN fill)\n",
    "            xb = xb * torch.tensor(mb, dtype=torch.float32).to(device)\n",
    "\n",
    "            logits, vals = model(xb)\n",
    "            dist = torch.distributions.Categorical(logits=logits)\n",
    "            act = dist.sample()\n",
    "            # reward theo action\n",
    "            reward = torch.where(act==2, rb, torch.where(act==0, -rb, torch.zeros_like(rb)))\n",
    "            loss = a3c_loss(logits, vals, act, reward)\n",
    "\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            loss_ep += loss.item()\n",
    "        print(f\"  Epoch {ep+1}/{epochs}, Loss={loss_ep:.4f}\")\n",
    "        gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "    # --- Save model ---\n",
    "    model_path = os.path.join(MODEL_DIR, f\"a3c_cluster_{c_id}.pt\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"  ✅ Saved model checkpoint: {model_path}\")\n",
    "\n",
    "    # --- Inference & save signals ---\n",
    "    with open(SIG_FILE,\"a\",newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        with torch.no_grad():\n",
    "            for xb, mb, _, idx in iterator():\n",
    "                xb = torch.tensor(xb, dtype=torch.float32).to(device)\n",
    "                xb = xb * torch.tensor(mb, dtype=torch.float32).to(device)\n",
    "                acts = torch.argmax(model(xb)[0], dim=-1).cpu().numpy() - 1  # (-1,0,1)\n",
    "                for k,(b,n) in enumerate(idx):\n",
    "                    w.writerow([dates[b], tickers[n], int(acts[k])])\n",
    "                del xb, acts\n",
    "                gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "    del X, M, px, r, model, opt\n",
    "    gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "# --- Run all clusters ---\n",
    "for meta in tensor_index:\n",
    "    process_cluster(meta)\n",
    "\n",
    "print(f\"✅ Done Block 8: signals saved to {SIG_FILE}, models in {MODEL_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7418f9a1",
   "metadata": {},
   "source": [
    "**Block 9: Suy luận từ mô hình A3C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f487374e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Inference] Cluster 0 | X=(503, 64, 17, 22)\n",
      "[Inference] Cluster 1 | X=(503, 64, 14, 22)\n",
      "[Inference] Cluster 2 | X=(503, 64, 15, 22)\n",
      "[Inference] Cluster 3 | X=(503, 64, 20, 22)\n",
      "[Inference] Cluster 4 | X=(503, 64, 24, 22)\n",
      "[Inference] Cluster 5 | X=(503, 64, 22, 22)\n",
      "[Inference] Cluster 6 | X=(503, 64, 20, 22)\n",
      "[Inference] Cluster 7 | X=(503, 64, 26, 22)\n",
      "[Inference] Cluster 8 | X=(503, 64, 21, 22)\n",
      "[Inference] Cluster 9 | X=(503, 64, 23, 22)\n",
      "[Inference] Cluster 10 | X=(503, 64, 21, 22)\n",
      "[Inference] Cluster 11 | X=(503, 64, 26, 22)\n",
      "[Inference] Cluster 12 | X=(503, 64, 29, 22)\n",
      "[Inference] Cluster 13 | X=(503, 64, 23, 22)\n",
      "[Inference] Cluster 14 | X=(503, 64, 28, 22)\n",
      "[Inference] Cluster 15 | X=(503, 64, 26, 22)\n",
      "[Inference] Cluster 16 | X=(503, 64, 27, 22)\n",
      "[Inference] Cluster 17 | X=(503, 64, 24, 22)\n",
      "[Inference] Cluster 18 | X=(503, 64, 23, 22)\n",
      "[Inference] Cluster 19 | X=(503, 64, 27, 22)\n",
      "[Inference] Cluster 20 | X=(503, 64, 28, 22)\n",
      "[Inference] Cluster 21 | X=(503, 64, 25, 22)\n",
      "[Inference] Cluster 22 | X=(503, 64, 24, 22)\n",
      "[Inference] Cluster 23 | X=(503, 64, 25, 22)\n",
      "[Inference] Cluster 24 | X=(503, 64, 25, 22)\n",
      "[Inference] Cluster 25 | X=(503, 64, 25, 22)\n",
      "[Inference] Cluster 26 | X=(503, 64, 26, 22)\n",
      "[Inference] Cluster 27 | X=(503, 64, 27, 22)\n",
      "[Inference] Cluster 28 | X=(503, 64, 27, 22)\n",
      "[Inference] Cluster 29 | X=(503, 64, 25, 22)\n",
      "[Inference] Cluster 30 | X=(503, 64, 24, 22)\n",
      "[Inference] Cluster 31 | X=(503, 64, 21, 22)\n",
      "[Inference] Cluster 32 | X=(503, 64, 22, 22)\n",
      "[Inference] Cluster 33 | X=(503, 64, 25, 22)\n",
      "[Inference] Cluster 34 | X=(503, 64, 25, 22)\n",
      "[Inference] Cluster 35 | X=(503, 64, 25, 22)\n",
      "[Inference] Cluster 36 | X=(503, 64, 24, 22)\n",
      "[Inference] Cluster 37 | X=(503, 64, 27, 22)\n",
      "[Inference] Cluster 38 | X=(503, 64, 23, 22)\n",
      "[Inference] Cluster 39 | X=(503, 64, 21, 22)\n",
      "[Inference] Cluster 40 | X=(503, 64, 25, 22)\n",
      "[Inference] Cluster 41 | X=(503, 64, 27, 22)\n",
      "[Inference] Cluster 42 | X=(503, 64, 23, 22)\n",
      "[Inference] Cluster 43 | X=(503, 64, 22, 22)\n",
      "[Inference] Cluster 44 | X=(503, 64, 25, 22)\n",
      "[Inference] Cluster 45 | X=(503, 64, 26, 22)\n",
      "[Inference] Cluster 46 | X=(503, 64, 23, 22)\n",
      "[Inference] Cluster 47 | X=(503, 64, 21, 22)\n",
      "[Inference] Cluster 48 | X=(503, 64, 19, 22)\n",
      "[Inference] Cluster 49 | X=(503, 64, 18, 22)\n",
      "[Inference] Cluster 50 | X=(503, 64, 21, 22)\n",
      "[Inference] Cluster 51 | X=(503, 64, 25, 22)\n",
      "[Inference] Cluster 52 | X=(503, 64, 21, 22)\n",
      "[Inference] Cluster 53 | X=(503, 64, 21, 22)\n",
      "[Inference] Cluster 54 | X=(503, 64, 21, 22)\n",
      "[Inference] Cluster 55 | X=(503, 64, 18, 22)\n",
      "[Inference] Cluster 56 | X=(503, 64, 20, 22)\n",
      "[Inference] Cluster 57 | X=(503, 64, 22, 22)\n",
      "[Inference] Cluster 58 | X=(503, 64, 21, 22)\n",
      "[Inference] Cluster 59 | X=(503, 64, 23, 22)\n",
      "[Inference] Cluster 60 | X=(503, 64, 18, 22)\n",
      "[Inference] Cluster 61 | X=(503, 64, 21, 22)\n",
      "[Inference] Cluster 62 | X=(503, 64, 18, 22)\n",
      "[Inference] Cluster 63 | X=(503, 64, 19, 22)\n",
      "[Inference] Cluster 64 | X=(503, 64, 16, 22)\n",
      "[Inference] Cluster 65 | X=(503, 64, 15, 22)\n",
      "[Inference] Cluster 66 | X=(503, 64, 17, 22)\n",
      "[Inference] Cluster 67 | X=(503, 64, 17, 22)\n",
      "[Inference] Cluster 68 | X=(503, 64, 18, 22)\n",
      "[Inference] Cluster 69 | X=(503, 64, 17, 22)\n",
      "[Inference] Cluster 70 | X=(503, 64, 20, 22)\n",
      "[Inference] Cluster 71 | X=(503, 64, 16, 22)\n",
      "[Inference] Cluster 72 | X=(503, 64, 17, 22)\n",
      "[Inference] Cluster 73 | X=(503, 64, 15, 22)\n",
      "[Inference] Cluster 74 | X=(503, 64, 14, 22)\n",
      "[Inference] Cluster 75 | X=(503, 64, 14, 22)\n",
      "[Inference] Cluster 76 | X=(503, 64, 12, 22)\n",
      "[Inference] Cluster 77 | X=(503, 64, 12, 22)\n",
      "[Inference] Cluster 78 | X=(503, 64, 10, 22)\n",
      "[Inference] Cluster 79 | X=(503, 64, 10, 22)\n",
      "[Inference] Cluster 80 | X=(503, 64, 9, 22)\n",
      "[Inference] Cluster 81 | X=(503, 64, 9, 22)\n",
      "[Inference] Cluster 82 | X=(503, 64, 12, 22)\n",
      "[Inference] Cluster 83 | X=(503, 64, 9, 22)\n",
      "[Inference] Cluster 84 | X=(503, 64, 7, 22)\n",
      "[Inference] Cluster 85 | X=(503, 64, 9, 22)\n",
      "[Inference] Cluster 86 | X=(503, 64, 7, 22)\n",
      "[Inference] Cluster 87 | X=(503, 64, 9, 22)\n",
      "[Inference] Cluster 88 | X=(503, 64, 8, 22)\n",
      "[Inference] Cluster 89 | X=(503, 64, 5, 22)\n",
      "[Inference] Cluster 90 | X=(503, 64, 6, 22)\n",
      "[Inference] Cluster 91 | X=(503, 64, 5, 22)\n",
      "[Inference] Cluster 92 | X=(503, 64, 5, 22)\n",
      "[Inference] Cluster 93 | X=(503, 64, 2, 22)\n",
      "[Inference] Cluster 94 | X=(503, 64, 2, 22)\n",
      "[Inference] Cluster 95 | X=(503, 64, 2, 22)\n",
      "[Inference] Cluster 96 | X=(503, 64, 2, 22)\n",
      "[Inference] Cluster 97 | X=(503, 64, 2, 22)\n",
      "[Inference] Cluster 98 | X=(503, 64, 2, 22)\n",
      "[Inference] Cluster 99 | X=(503, 64, 3, 22)\n",
      "[Inference] Cluster 100 | X=(503, 64, 1, 22)\n",
      "[Inference] Cluster 101 | X=(503, 64, 2, 22)\n",
      "[Inference] Cluster 102 | X=(503, 64, 2, 22)\n",
      "[Inference] Cluster 103 | X=(503, 64, 1, 22)\n",
      "[Inference] Cluster 104 | X=(503, 64, 2, 22)\n",
      "[Inference] Cluster 105 | X=(503, 64, 3, 22)\n",
      "[Inference] Cluster 106 | X=(503, 64, 1, 22)\n",
      "✅ Done Block 9: inference signals saved to ./signals/a3c_signals_infer.csv\n"
     ]
    }
   ],
   "source": [
    "# Block 9 — Inference từ checkpoint A3C\n",
    "\n",
    "import os, gc, json, csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "DATA_DIR = \"./tensors/\"\n",
    "MODEL_DIR = \"./models/\"\n",
    "SIG_DIR   = \"./signals/\"\n",
    "os.makedirs(SIG_DIR, exist_ok=True)\n",
    "\n",
    "SIG_FILE = os.path.join(SIG_DIR, \"a3c_signals_infer.csv\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Reset signals file\n",
    "if os.path.exists(SIG_FILE):\n",
    "    os.remove(SIG_FILE)\n",
    "with open(SIG_FILE, \"w\", newline=\"\") as f:\n",
    "    csv.writer(f).writerow([\"date\",\"ticker\",\"signal\"])\n",
    "\n",
    "# Load metadata\n",
    "with open(os.path.join(DATA_DIR, \"tensor_index.json\"), \"r\") as f:\n",
    "    tensor_index = json.load(f)\n",
    "\n",
    "# --- Model định nghĩa lại (giống Block 8) ---\n",
    "class A3CNet(nn.Module):\n",
    "    def __init__(self, n_features, hidden=64):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=n_features, hidden_size=hidden, batch_first=True)\n",
    "        self.actor = nn.Linear(hidden, 3)   # short, flat, long\n",
    "        self.critic = nn.Linear(hidden, 1)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        h = out[:, -1, :]\n",
    "        return self.actor(h), self.critic(h)\n",
    "\n",
    "# --- Inference function ---\n",
    "def infer_cluster(meta, batch_size=256):\n",
    "    c_id, tickers, dates, dates_shifted = meta[\"cluster\"], meta[\"tickers\"], meta[\"dates\"], meta[\"dates_shifted\"]\n",
    "    X = np.load(os.path.join(DATA_DIR, meta[\"tensor_file\"]), mmap_mode=\"r\")\n",
    "    M = np.load(os.path.join(DATA_DIR, meta[\"mask_file\"]), mmap_mode=\"r\")\n",
    "    if X.size == 0:\n",
    "        return\n",
    "    B, T, N, F = X.shape\n",
    "    print(f\"[Inference] Cluster {c_id} | X={X.shape}\")\n",
    "\n",
    "    # Load model checkpoint\n",
    "    model_path = os.path.join(MODEL_DIR, f\"a3c_cluster_{c_id}.pt\")\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️ Model checkpoint not found: {model_path}, skip\")\n",
    "        return\n",
    "    model = A3CNet(F).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    # Inference & save signals\n",
    "    total = B * N\n",
    "    with open(SIG_FILE, \"a\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        with torch.no_grad():\n",
    "            for start in range(0, total, batch_size):\n",
    "                end = min(total, start+batch_size)\n",
    "                xb, mb, idx = [], [], []\n",
    "                for s in range(start, end):\n",
    "                    b, n = divmod(s, N)\n",
    "                    xb.append(X[b, :, n, :])\n",
    "                    mb.append(M[b, :, n, :])\n",
    "                    idx.append((b, n))\n",
    "                xb = torch.tensor(np.stack(xb), dtype=torch.float32).to(device)\n",
    "                mb = torch.tensor(np.stack(mb), dtype=torch.float32).to(device)\n",
    "\n",
    "                # Áp dụng mask\n",
    "                xb = xb * mb\n",
    "\n",
    "                acts = torch.argmax(model(xb)[0], dim=-1).cpu().numpy() - 1  # (-1,0,1)\n",
    "                for k,(b,n) in enumerate(idx):\n",
    "                    # dùng dates[b] (ngày cuối window), nhưng reward tính T+1 (dates_shifted)\n",
    "                    w.writerow([dates[b], tickers[n], int(acts[k])])\n",
    "                del xb, mb, acts\n",
    "                gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "    del X, M, model\n",
    "    gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "# --- Run inference all clusters ---\n",
    "for meta in tensor_index:\n",
    "    infer_cluster(meta)\n",
    "\n",
    "print(f\"✅ Done Block 9: inference signals saved to {SIG_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df4f8af",
   "metadata": {},
   "source": [
    "**Block 10 : Huấn luyện Cluster DDPG (chỉ với trường hợp vị thế long)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a04525a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DDPG] Epoch 1/20 | Critic 0.0076 | Actor 23.2607\n",
      "[DDPG] Epoch 2/20 | Critic 0.0139 | Actor 15.1680\n",
      "[DDPG] Epoch 3/20 | Critic 0.0233 | Actor 9.6906\n",
      "[DDPG] Epoch 4/20 | Critic 0.0348 | Actor 4.7725\n",
      "[DDPG] Epoch 5/20 | Critic 0.0318 | Actor 3.0788\n",
      "[DDPG] Epoch 6/20 | Critic 0.0298 | Actor 2.1893\n",
      "[DDPG] Epoch 7/20 | Critic 0.0308 | Actor 1.1258\n",
      "[DDPG] Epoch 8/20 | Critic 0.0298 | Actor 0.2072\n",
      "[DDPG] Epoch 9/20 | Critic 0.0312 | Actor -1.3339\n",
      "[DDPG] Epoch 10/20 | Critic 0.0369 | Actor -4.6054\n",
      "[DDPG] Epoch 11/20 | Critic 0.0370 | Actor -6.4414\n",
      "[DDPG] Epoch 12/20 | Critic 0.0381 | Actor -6.9208\n",
      "[DDPG] Epoch 13/20 | Critic 0.0351 | Actor -7.4684\n",
      "[DDPG] Epoch 14/20 | Critic 0.0267 | Actor -8.2097\n",
      "[DDPG] Epoch 15/20 | Critic 0.0237 | Actor -8.5045\n",
      "[DDPG] Epoch 16/20 | Critic 0.0372 | Actor -8.8276\n",
      "[DDPG] Epoch 17/20 | Critic 0.0344 | Actor -10.0914\n",
      "[DDPG] Epoch 18/20 | Critic 0.0258 | Actor -9.1938\n",
      "[DDPG] Epoch 19/20 | Critic 0.0199 | Actor -9.1797\n",
      "[DDPG] Epoch 20/20 | Critic 0.0178 | Actor -9.3583\n",
      "Fetching VNINDEX for benchmark (buy & hold)...\n",
      "Fetching data, it may take a while. Please wait...\n",
      "✅ Done Block 10 (long-only, lag, turnover, cluster-DDPG, RAM-optimized).\n"
     ]
    }
   ],
   "source": [
    "# Block 10 — Cluster DDPG + Execution Lag + Turnover Cost \n",
    "\n",
    "import os, gc, json, csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from FiinQuantX import FiinSession\n",
    "\n",
    "# ===== Paths =====\n",
    "DATA_DIR   = \"./tensors/\"\n",
    "SIG_DIR    = \"./signals/\"\n",
    "OUTPUT_DIR = \"./backtest_ddpg/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ===== Hyper-params & config =====\n",
    "INIT_CAPITAL   = 10_000\n",
    "BENCHMARK_TKR  = \"VNINDEX\"\n",
    "EXECUTION_LAG  = 2         # tín hiệu T -> return T+2\n",
    "COST_BPS       = 30        # phí theo turnover 0.30% = 30bps\n",
    "STATE_LKBK     = 10         # số ngày lịch sử dùng làm state\n",
    "MIN_NAMES_PER_CLUSTER = 2  # tối thiểu số mã active trong 1 cụm\n",
    "SEED = 42\n",
    "\n",
    "# DDPG \n",
    "EPOCHS       = 20\n",
    "BATCH_SIZE   = 64\n",
    "LR_ACTOR     = 1e-4\n",
    "LR_CRITIC    = 5e-4\n",
    "GAMMA        = 0.95\n",
    "TAU          = 1e-2\n",
    "NOISE_STD    = 0.05   # nhiễu nhẹ trên logits\n",
    "HIDDEN       = 128\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "# ===== Load artifacts từ các block trước =====\n",
    "# (1) A3C signals\n",
    "signals = pd.read_csv(os.path.join(SIG_DIR, \"a3c_signals_infer.csv\"))\n",
    "signals[\"date\"] = pd.to_datetime(signals[\"date\"])\n",
    "\n",
    "# (2) Giá để tính return\n",
    "df_px = df_backtest.rename(columns={\"timestamp\": \"date\"}).copy()\n",
    "df_px[\"date\"] = pd.to_datetime(df_px[\"date\"])\n",
    "px_wide = df_px.pivot(index=\"date\", columns=\"ticker\", values=\"close\").sort_index()\n",
    "ret_wide = px_wide.pct_change().fillna(0.0)\n",
    "\n",
    "# (3) Map ticker -> cluster\n",
    "with open(os.path.join(DATA_DIR, \"tensor_index.json\"), \"r\") as f:\n",
    "    tensor_index = json.load(f)\n",
    "ticker2cluster = {}\n",
    "for meta in tensor_index:\n",
    "    for tk in meta[\"tickers\"]:\n",
    "        # nếu 1 mã gặp nhiều cụm theo thời gian, giữ cụm đầu tiên để đơn giản\n",
    "        ticker2cluster.setdefault(tk, meta[\"cluster\"])\n",
    "ticker2cluster = pd.Series(ticker2cluster)\n",
    "\n",
    "# ===== Train/Test split =====\n",
    "TRAIN_START = pd.Timestamp(\"2023-01-01\")\n",
    "TRAIN_END   = pd.Timestamp(\"2024-12-31\")\n",
    "TEST_START  = pd.Timestamp(\"2025-01-01\")\n",
    "TEST_END    = ret_wide.index.max()\n",
    "\n",
    "# ===== Chuẩn bị signal với execution lag =====\n",
    "sig_wide_raw = signals.pivot_table(index=\"date\", columns=\"ticker\", values=\"signal\", aggfunc=\"last\").sort_index()\n",
    "idx_all = ret_wide.index.union(sig_wide_raw.index)\n",
    "ret_wide = ret_wide.reindex(idx_all).fillna(0.0)\n",
    "sig_wide = sig_wide_raw.reindex(idx_all).fillna(0.0)\n",
    "sig_wide_lag = sig_wide.shift(EXECUTION_LAG)  # <- execution lag\n",
    "\n",
    "# chỉ giữ tickers có trong map cụm & có return\n",
    "tickers = [t for t in ret_wide.columns if t in ticker2cluster.index]\n",
    "ret_wide = ret_wide[tickers].astype(\"float32\")\n",
    "sig_wide_lag = sig_wide_lag[tickers].astype(\"float32\")\n",
    "cluster_of = ticker2cluster.loc[tickers]\n",
    "\n",
    "# ===== Danh sách cụm và thành viên =====\n",
    "clusters = sorted(cluster_of.unique().tolist())\n",
    "cluster_members = {c: cluster_of[cluster_of == c].index.tolist() for c in clusters}\n",
    "C = len(clusters)\n",
    "\n",
    "# ===== Helpers =====\n",
    "def build_state_arrays(ret_w, sig_lag, start, end, K=STATE_LKBK):\n",
    "    \"\"\"\n",
    "    Xây state ở cấp cụm (long-only):\n",
    "      - activity[c,t] = tỷ lệ mã trong cụm c có signal>0 tại ngày t\n",
    "      - cluster_ret[c,t] = mean return của các mã active (signal>0) trong cụm c tại ngày t\n",
    "    Trả ra:\n",
    "      S_mat: (T, 2*C*K)  -> [activity(K ngày), cluster_ret(K ngày)]\n",
    "      R_mat: (T, C)      -> return cụm tại ngày t (dùng để tính reward)\n",
    "      dates: index tương ứng\n",
    "      ACTIVE_masks: dict[c] -> DataFrame mask active của cụm c trên khoảng thời gian này\n",
    "    \"\"\"\n",
    "    R = ret_w.loc[start:end]\n",
    "    S = sig_lag.loc[start:end]\n",
    "    dates = R.index\n",
    "\n",
    "    # tính activity và return cụm từng ngày, theo cụm\n",
    "    act_cols, ret_cols = [], []\n",
    "    ACTIVE_masks = {}\n",
    "\n",
    "    for c in clusters:\n",
    "        tks = cluster_members[c]\n",
    "        if not tks:\n",
    "            # tạo cột 0 nếu cụm rỗng (hiếm)\n",
    "            act_c = pd.Series(0.0, index=dates, name=c)\n",
    "            ret_c = pd.Series(0.0, index=dates, name=c)\n",
    "            ACTIVE_masks[c] = pd.DataFrame(0.0, index=dates, columns=tks)\n",
    "        else:\n",
    "            S_c = S[tks]\n",
    "            R_c = R[tks]\n",
    "\n",
    "            active_mask = (S_c > 0).astype(\"float32\")  # long-only\n",
    "            ACTIVE_masks[c] = active_mask\n",
    "\n",
    "            denom = active_mask.sum(axis=1).replace(0, np.nan)\n",
    "            w = active_mask.div(denom, axis=0)  # chia đều trong các mã active\n",
    "            w = w.fillna(0.0)\n",
    "\n",
    "            act_c = (active_mask.mean(axis=1)).astype(\"float32\")  # % mã active\n",
    "            ret_c = ((R_c * w).sum(axis=1)).astype(\"float32\")     # mean ret của mã active\n",
    "\n",
    "        act_cols.append(act_c.rename(c))\n",
    "        ret_cols.append(ret_c.rename(c))\n",
    "\n",
    "    act_df = pd.concat(act_cols, axis=1).astype(\"float32\")\n",
    "    cret_df = pd.concat(ret_cols, axis=1).astype(\"float32\")\n",
    "\n",
    "    # dựng state = concat K ngày gần nhất cho activity & cluster_ret\n",
    "    def stack_lookback(df, K):\n",
    "        mats = []\n",
    "        for k in range(K):\n",
    "            mats.append(df.shift(k).fillna(0.0))\n",
    "        return np.concatenate([m.values[:, :, None] for m in mats], axis=2)  # (T, C, K)\n",
    "\n",
    "    A3 = stack_lookback(act_df, K)    # (T,C,K)\n",
    "    R3 = stack_lookback(cret_df, K)   # (T,C,K)\n",
    "\n",
    "    # Loại bỏ những ngày đầu chưa đủ lookback\n",
    "    valid = np.arange(A3.shape[0]) >= (K - 1)\n",
    "    A3 = A3[valid]   # (T',C,K)\n",
    "    R3_look = R3[valid]\n",
    "    dates2 = dates[valid]\n",
    "\n",
    "    # Flatten state: (T', 2*C*K)\n",
    "    S_mat = np.concatenate([A3.reshape(len(dates2), -1), R3_look.reshape(len(dates2), -1)], axis=1).astype(\"float32\")\n",
    "    # Reward dùng return cụm (không lookback): lấy cret_df tại ngày tương ứng\n",
    "    R_mat = cret_df.loc[dates2].values.astype(\"float32\")\n",
    "\n",
    "    # đồng bộ ACTIVE_masks về dates2\n",
    "    ACTIVE_masks = {c: ACTIVE_masks[c].loc[dates2] for c in clusters}\n",
    "    return S_mat, R_mat, dates2, ACTIVE_masks\n",
    "\n",
    "# ===== Chuẩn bị Train & Test =====\n",
    "S_train, R_train, d_train, ACTIVE_train = build_state_arrays(ret_wide, sig_wide_lag, TRAIN_START, TRAIN_END, K=STATE_LKBK)\n",
    "S_test,  R_test,  d_test,  ACTIVE_test  = build_state_arrays(ret_wide, sig_wide_lag, TEST_START,  TEST_END,  K=STATE_LKBK)\n",
    "\n",
    "# ===== DDPG (long-only simplex) =====\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, s_dim, a_dim, hidden=HIDDEN):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(s_dim, hidden), nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden), nn.ReLU(),\n",
    "            nn.Linear(hidden, a_dim)  # logits\n",
    "        )\n",
    "    def forward(self, s):\n",
    "        return torch.softmax(self.net(s), dim=-1)  # long-only, sum=1\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, s_dim, a_dim, hidden=HIDDEN):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(s_dim + a_dim, hidden), nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden), nn.ReLU(),\n",
    "            nn.Linear(hidden, 1)\n",
    "        )\n",
    "    def forward(self, s, a):\n",
    "        return self.net(torch.cat([s, a], dim=-1))\n",
    "\n",
    "class Buffer:\n",
    "    def __init__(self, maxlen=20000):\n",
    "        self.maxlen = maxlen; self.buf=[]\n",
    "    def push(self, s,a,r,s2):\n",
    "        if len(self.buf)>=self.maxlen: self.buf.pop(0)\n",
    "        self.buf.append((s,a,r,s2))\n",
    "    def sample(self, bs):\n",
    "        n=min(bs,len(self.buf))\n",
    "        idx=np.random.choice(len(self.buf), n, replace=False)\n",
    "        s,a,r,s2 = zip(*[self.buf[i] for i in idx])\n",
    "        return (np.array(s, np.float32), np.array(a, np.float32),\n",
    "                np.array(r, np.float32).reshape(-1,1), np.array(s2, np.float32))\n",
    "\n",
    "def step_soft_update(src, tgt, tau):\n",
    "    with torch.no_grad():\n",
    "        for p, tp in zip(src.parameters(), tgt.parameters()):\n",
    "            tp.data.mul_(1-tau); tp.data.add_(tau*p.data)\n",
    "\n",
    "def port_reward_longonly(w_c, r_c, prev_w_c=None):\n",
    "    gross = float(np.dot(w_c, r_c))\n",
    "    fee = 0.0\n",
    "    # phí ở cấp cụm đã được tính ở cấp mã trong mô phỏng cuối, nên ở training giữ đơn giản để ổn định\n",
    "    return gross - fee\n",
    "\n",
    "s_dim = S_train.shape[1]; a_dim = C\n",
    "actor = Actor(s_dim, a_dim).to(device)\n",
    "critic = Critic(s_dim, a_dim).to(device)\n",
    "t_actor = Actor(s_dim, a_dim).to(device); t_actor.load_state_dict(actor.state_dict())\n",
    "t_critic= Critic(s_dim, a_dim).to(device); t_critic.load_state_dict(critic.state_dict())\n",
    "optA = optim.Adam(actor.parameters(), lr=LR_ACTOR)\n",
    "optC = optim.Adam(critic.parameters(), lr=LR_CRITIC)\n",
    "mse = nn.MSELoss()\n",
    "buf = Buffer()\n",
    "\n",
    "# ---- Train  ----\n",
    "S_tr = S_train; R_tr = R_train\n",
    "prev_w = None\n",
    "for ep in range(EPOCHS):\n",
    "    c_loss=a_loss=0.0\n",
    "    prev_w = None\n",
    "    for t in range(len(S_tr)-1):\n",
    "        s  = torch.from_numpy(S_tr[t]).to(device).unsqueeze(0)\n",
    "        s2 = torch.from_numpy(S_tr[t+1]).to(device).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            w = actor(s).cpu().numpy()[0]\n",
    "        # exploration trong simplex\n",
    "        logits = np.log(w + 1e-9) + np.random.normal(0, NOISE_STD, size=a_dim)\n",
    "        w_e = np.exp(logits); w_e = (w_e / w_e.sum()).astype(\"float32\")\n",
    "\n",
    "        r = port_reward_longonly(w_e, R_tr[t], prev_w)\n",
    "        prev_w = w_e.copy()\n",
    "        buf.push(S_tr[t], w_e, r, S_tr[t+1])\n",
    "\n",
    "        if len(buf.buf) >= BATCH_SIZE:\n",
    "            sb, ab, rb, s2b = buf.sample(BATCH_SIZE)\n",
    "            sb  = torch.from_numpy(sb).to(device)\n",
    "            ab  = torch.from_numpy(ab).to(device)\n",
    "            rb  = torch.from_numpy(rb).to(device)\n",
    "            s2b = torch.from_numpy(s2b).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                a2 = t_actor(s2b)\n",
    "                q2 = t_critic(s2b, a2)\n",
    "                y  = rb + GAMMA * q2\n",
    "\n",
    "            q  = critic(sb, ab)\n",
    "            lc = mse(q, y)\n",
    "            optC.zero_grad(); lc.backward(); optC.step()\n",
    "\n",
    "            ap = actor(sb)\n",
    "            la = -critic(sb, ap).mean()\n",
    "            optA.zero_grad(); la.backward(); optA.step()\n",
    "\n",
    "            step_soft_update(actor, t_actor, TAU)\n",
    "            step_soft_update(critic, t_critic, TAU)\n",
    "\n",
    "            c_loss += float(lc.item()); a_loss += float(la.item())\n",
    "    print(f\"[DDPG] Epoch {ep+1}/{EPOCHS} | Critic {c_loss:.4f} | Actor {a_loss:.4f}\")\n",
    "    gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "# ===== Backtest (Test) — long-only với phí theo turnover ở cấp mã =====\n",
    "dates = d_test\n",
    "capital = INIT_CAPITAL\n",
    "portfolio_value = pd.Series(index=dates, dtype=\"float64\")\n",
    "portfolio_value.iloc[0] = capital\n",
    "\n",
    "# stream save cluster weights để không tốn RAM\n",
    "cw_path = os.path.join(OUTPUT_DIR, \"cluster_weights_test.csv\")\n",
    "with open(cw_path, \"w\", newline=\"\") as f:\n",
    "    cw = csv.writer(f); cw.writerow([\"date\"] + [f\"cluster_{c}\" for c in clusters])\n",
    "\n",
    "prev_w_ticker = pd.Series(0.0, index=tickers, dtype=\"float32\")\n",
    "\n",
    "for i, dt in enumerate(dates):\n",
    "    # dùng state của ngày trước (action lag 1 step để chắc chắn không leak)\n",
    "    s_dt = dates[i-1] if i>0 else dates[i]\n",
    "    s = torch.from_numpy(S_test[i-1].astype(\"float32\") if i>0 else S_test[i].astype(\"float32\")).to(device).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        w_c = actor(s).cpu().numpy()[0].astype(\"float32\")\n",
    "    w_c = np.clip(w_c, 0, 1); ssum = w_c.sum(); w_c = w_c/ssum if ssum>0 else np.ones_like(w_c)/len(w_c)\n",
    "\n",
    "    # phân bổ xuống mã: trong mỗi cụm, chia đều cho mã active (signal>0)\n",
    "    w_ticker = pd.Series(0.0, index=tickers, dtype=\"float32\")\n",
    "    for j, c in enumerate(clusters):\n",
    "        members = cluster_members[c]\n",
    "        if not members: continue\n",
    "        act_row = ACTIVE_test[c].iloc[i]  # mask của ngày dt\n",
    "        valid = [tk for tk in members if (tk in act_row.index and act_row[tk] > 0)]\n",
    "        if len(valid) >= MIN_NAMES_PER_CLUSTER:\n",
    "            share = w_c[j] / len(valid)\n",
    "            w_ticker.loc[valid] += share\n",
    "\n",
    "    # nếu không cụm nào active -> phân bổ đều toàn thị trường (đảm bảo sum=1)\n",
    "    ssum = float(w_ticker.sum())\n",
    "    if ssum <= 1e-12:\n",
    "        w_ticker[:] = 1.0 / len(w_ticker)\n",
    "    else:\n",
    "        w_ticker /= ssum\n",
    "\n",
    "    # lưu cluster weights (stream)\n",
    "    with open(cw_path, \"a\", newline=\"\") as f:\n",
    "        cw = csv.writer(f); cw.writerow([dt.strftime(\"%Y-%m-%d\")] + [float(x) for x in w_c])\n",
    "\n",
    "    # lợi nhuận ngày dt & phí turnover\n",
    "    r_vec = ret_wide.loc[dt, w_ticker.index].values.astype(\"float32\")\n",
    "    turnover = float(np.sum(np.abs(w_ticker.values - prev_w_ticker.values)))\n",
    "    fee = (COST_BPS/1e4) * turnover\n",
    "\n",
    "    r_net = float(np.dot(w_ticker.values, r_vec)) - fee\n",
    "    capital = capital * (1.0 + r_net)\n",
    "    portfolio_value.iloc[i] = capital\n",
    "\n",
    "    prev_w_ticker = w_ticker\n",
    "    if (i % 50) == 0:\n",
    "        gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "# ===== Benchmark (buy & hold VNINDEX) =====\n",
    "print(\"Fetching VNINDEX for benchmark (buy & hold)...\")\n",
    "client = FiinSession(username=\"DSTC_18@fiinquant.vn\", password=\"Fiinquant0606\").login()\n",
    "bench = client.Fetch_Trading_Data(\n",
    "    realtime=False, tickers=BENCHMARK_TKR, fields=['close'],\n",
    "    adjusted=True, by=\"1d\", from_date=str(dates.min().date())\n",
    ").get_data()\n",
    "bench[\"date\"] = pd.to_datetime(bench[\"timestamp\"])\n",
    "bench = bench.set_index(\"date\")[\"close\"].sort_index().reindex(dates).ffill().bfill()\n",
    "bench_ret = bench.pct_change().fillna(0.0)\n",
    "benchmark_value = (1 + bench_ret).cumprod() * INIT_CAPITAL\n",
    "\n",
    "# ===== Save outputs (gọn) =====\n",
    "portfolio_value.to_frame(\"portfolio_value\").to_csv(os.path.join(OUTPUT_DIR, \"portfolio_value_test.csv\"))\n",
    "benchmark_value.to_frame(\"benchmark_value\").to_csv(os.path.join(OUTPUT_DIR, \"benchmark_value_test.csv\"))\n",
    "\n",
    "print(\"✅ Done Block 10 (long-only, lag, turnover, cluster-DDPG, RAM-optimized).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49e0e1c",
   "metadata": {},
   "source": [
    "**BLOCK 10.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c66cfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved ticker weights to ./backtest_ddpg/weights_by_ticker.csv\n",
      "✅ Saved daily returns\n",
      "✅ Saved trades log\n",
      "🎯 Done Block 10.5 — All DDPG inference artifacts saved.\n"
     ]
    }
   ],
   "source": [
    "# Block 10.5 — Save full results (DDPG inference artifacts)\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ===== Đường dẫn =====\n",
    "OUTPUT_DIR = \"./backtest_ddpg/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# 1. Lưu giá trị danh mục & benchmark (đã có trong Block 10)\n",
    "# -> portfolio_value.csv, benchmark_value.csv đã được lưu\n",
    "\n",
    "# 2. Lưu allocation theo từng ticker (tỷ trọng vốn mỗi ngày)\n",
    "weights_by_ticker_path = os.path.join(OUTPUT_DIR, \"weights_by_ticker.csv\")\n",
    "weights_df = pd.DataFrame(index=dates, columns=tickers, dtype=\"float32\")\n",
    "\n",
    "prev_w_ticker = pd.Series(0.0, index=tickers, dtype=\"float32\")\n",
    "capital = INIT_CAPITAL\n",
    "\n",
    "for i, dt in enumerate(dates):\n",
    "    # dùng state của ngày trước (action lag 1 step để chắc chắn không leak)\n",
    "    s_dt = dates[i-1] if i>0 else dates[i]\n",
    "    s = torch.from_numpy(S_test[i-1].astype(\"float32\") if i>0 else S_test[i].astype(\"float32\")).to(device).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        w_c = actor(s).cpu().numpy()[0].astype(\"float32\")\n",
    "    w_c = np.clip(w_c, 0, 1)\n",
    "    ssum = w_c.sum()\n",
    "    w_c = w_c/ssum if ssum>0 else np.ones_like(w_c)/len(w_c)\n",
    "\n",
    "    # phân bổ xuống ticker\n",
    "    w_ticker = pd.Series(0.0, index=tickers, dtype=\"float32\")\n",
    "    for j, c in enumerate(clusters):\n",
    "        members = cluster_members[c]\n",
    "        if not members: continue\n",
    "        act_row = ACTIVE_test[c].iloc[i]\n",
    "        valid = [tk for tk in members if (tk in act_row.index and act_row[tk] > 0)]\n",
    "        if len(valid) >= MIN_NAMES_PER_CLUSTER:\n",
    "            share = w_c[j] / len(valid)\n",
    "            w_ticker.loc[valid] += share\n",
    "\n",
    "    ssum = float(w_ticker.sum())\n",
    "    if ssum <= 1e-12:\n",
    "        w_ticker[:] = 1.0 / len(w_ticker)\n",
    "    else:\n",
    "        w_ticker /= ssum\n",
    "\n",
    "    # Lưu allocation\n",
    "    weights_df.loc[dt] = w_ticker\n",
    "\n",
    "# Ghi file\n",
    "weights_df.to_csv(weights_by_ticker_path)\n",
    "print(f\"✅ Saved ticker weights to {weights_by_ticker_path}\")\n",
    "\n",
    "# 3. Lưu daily returns (log lợi nhuận hàng ngày)\n",
    "returns = weights_df.shift(1).fillna(0.0).mul(ret_wide.loc[weights_df.index].values).sum(axis=1)\n",
    "returns.name = \"daily_return\"\n",
    "returns.to_csv(os.path.join(OUTPUT_DIR, \"returns.csv\"))\n",
    "print(\"✅ Saved daily returns\")\n",
    "\n",
    "# 4. Lưu log giao dịch (turnover)\n",
    "turnover_log = (weights_df.diff().abs().sum(axis=1))\n",
    "turnover_log.name = \"turnover\"\n",
    "turnover_log.to_csv(os.path.join(OUTPUT_DIR, \"trades_log.csv\"))\n",
    "print(\"✅ Saved trades log\")\n",
    "\n",
    "print(\"🎯 Done Block 10.5 — All DDPG inference artifacts saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc5b470",
   "metadata": {},
   "source": [
    "**Block 11: Thống kê kết quả và vẽ biểu đồ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7922908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:87: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11408\\2247239484.py:94: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  monthly = returns.resample(\"M\").agg([\"sum\",\"count\",lambda x:(x>0).mean()])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Kết quả Test:\n",
      "Ngày bắt đầu                        2025-01-15\n",
      "Ngày kết thúc                       2025-09-19\n",
      "Giá trị cuối                      11317.497532\n",
      "ROI (%)                              13.678408\n",
      "Biến động (năm, %)                   23.843905\n",
      "Sharpe                                0.929647\n",
      "Sortino                               1.452968\n",
      "MaxDrawdown (%)                     -14.744853\n",
      "Tỷ lệ phiên thắng (%)                52.095808\n",
      "Số ngày                                    167\n",
      "Giá trị cuối (VNINDEX)            13417.301687\n",
      "ROI VNINDEX (%)                      34.173017\n",
      "Chênh lệch so với VNINDEX (pp)      -20.494609\n",
      "dtype: object\n",
      "\n",
      "📊 Stress Test (Trump thông báo đánh thuế 46% hàng hóa Việt Nam):\n",
      "Ngày bắt đầu                        2025-03-26\n",
      "Ngày kết thúc                       2025-04-15\n",
      "Giá trị cuối                      10687.417347\n",
      "ROI (%)                              -3.041787\n",
      "Biến động (năm, %)                   46.197109\n",
      "Sharpe                               -0.989089\n",
      "Sortino                              -1.626574\n",
      "MaxDrawdown (%)                     -12.033519\n",
      "Tỷ lệ phiên thắng (%)                42.857143\n",
      "Số ngày                                     14\n",
      "Giá trị cuối (VNINDEX)             9932.129625\n",
      "ROI VNINDEX (%)                       -7.41277\n",
      "Chênh lệch so với VNINDEX (pp)        4.370983\n",
      "dtype: object\n",
      "\n",
      "✅ Block 11 hoàn tất. Stats lưu tại: ./backtest_ddpg/stats_test.csv, Charts in ./backtest_ddpg/\n"
     ]
    }
   ],
   "source": [
    "# Block 11 — Hiệu suất & Stress Test (Trump đánh thuế 46%)\n",
    "import os, numpy as np, pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "OUTPUT_DIR = \"./backtest_ddpg/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "STATS_FILE = os.path.join(OUTPUT_DIR, \"stats_test.csv\")\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def max_drawdown(series: pd.Series) -> float:\n",
    "    peak = series.cummax()\n",
    "    dd = (series / peak) - 1.0\n",
    "    return float(dd.min())\n",
    "\n",
    "def compute_stats(port_val: pd.Series, bench_val: pd.Series | None = None):\n",
    "    port_ret = port_val.pct_change().fillna(0.0)\n",
    "    stats = {\n",
    "        \"Ngày bắt đầu\": port_val.index.min().strftime(\"%Y-%m-%d\"),\n",
    "        \"Ngày kết thúc\": port_val.index.max().strftime(\"%Y-%m-%d\"),\n",
    "        \"Giá trị cuối\": float(port_val.iloc[-1]),\n",
    "        \"ROI (%)\": float((port_val.iloc[-1] / port_val.iloc[0] - 1.0) * 100),\n",
    "        \"Biến động (năm, %)\": float(port_ret.std() * np.sqrt(252) * 100),\n",
    "        \"Sharpe\": float((port_ret.mean() / port_ret.std()) * np.sqrt(252)) if port_ret.std() > 0 else 0,\n",
    "        \"Sortino\": float((port_ret.mean() / port_ret[port_ret < 0].std()) * np.sqrt(252)) if port_ret[port_ret < 0].std() > 0 else 0,\n",
    "        \"MaxDrawdown (%)\": float(max_drawdown(port_val) * 100),\n",
    "        \"Tỷ lệ phiên thắng (%)\": float((port_ret > 0).mean() * 100),\n",
    "        \"Số ngày\": int(len(port_ret))\n",
    "    }\n",
    "    if bench_val is not None and len(bench_val) > 1:\n",
    "        stats.update({\n",
    "            \"Giá trị cuối (VNINDEX)\": float(bench_val.iloc[-1]),\n",
    "            \"ROI VNINDEX (%)\": float((bench_val.iloc[-1] / bench_val.iloc[0] - 1.0) * 100),\n",
    "            \"Chênh lệch so với VNINDEX (pp)\": stats[\"ROI (%)\"] - ((bench_val.iloc[-1] / bench_val.iloc[0] - 1.0) * 100)\n",
    "        })\n",
    "    return stats\n",
    "\n",
    "def plot_equity(port_val, bench_val, title, path):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(port_val, label=\"Chiến lược\", linewidth=1.6)\n",
    "    if bench_val is not None:\n",
    "        plt.plot(bench_val, label=\"VNINDEX (Buy&Hold)\", linewidth=1.2)\n",
    "    plt.title(title); plt.legend(); plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(path, dpi=150); plt.close()\n",
    "\n",
    "def plot_hist(port_ret, title, path, bench_ret=None):\n",
    "    plt.figure(figsize=(9,5))\n",
    "    plt.hist(port_ret.dropna(), bins=50, alpha=0.6, label=\"Chiến lược\")\n",
    "    if bench_ret is not None:\n",
    "        plt.hist(bench_ret.dropna(), bins=50, alpha=0.6, label=\"VNINDEX\")\n",
    "    plt.title(title); plt.xlabel(\"Daily Return\"); plt.ylabel(\"Tần suất\")\n",
    "    plt.legend(); plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(path, dpi=150); plt.close()\n",
    "\n",
    "# ---------- Load kết quả ----------\n",
    "port_val = pd.read_csv(os.path.join(OUTPUT_DIR, \"portfolio_value_test.csv\"), index_col=0, parse_dates=True).iloc[:,0].sort_index()\n",
    "bench_val = pd.read_csv(os.path.join(OUTPUT_DIR, \"benchmark_value_test.csv\"), index_col=0, parse_dates=True).iloc[:,0].sort_index().reindex(port_val.index).ffill().bfill()\n",
    "returns = port_val.pct_change().fillna(0.0)\n",
    "bench_ret = bench_val.pct_change().fillna(0.0)\n",
    "\n",
    "# ---------- Stats (Test tổng thể) ----------\n",
    "stats_test = compute_stats(port_val, bench_val)\n",
    "\n",
    "# Equity + Histogram toàn kỳ\n",
    "plot_equity(port_val, bench_val, \"Equity Curve (Test)\", os.path.join(OUTPUT_DIR, \"equity_test.png\"))\n",
    "plot_hist(returns, \"Histogram lợi nhuận ngày (Test)\", os.path.join(OUTPUT_DIR, \"hist_test.png\"), bench_ret)\n",
    "\n",
    "# Drawdown toàn kỳ\n",
    "cum_ret = (1+returns).cumprod(); dd = cum_ret/cum_ret.cummax()-1\n",
    "plt.figure(figsize=(10,4)); plt.plot(dd, color=\"red\"); plt.title(\"Drawdown toàn kỳ\"); plt.grid(True,alpha=0.3)\n",
    "plt.savefig(os.path.join(OUTPUT_DIR,\"drawdown_test.png\")); plt.close()\n",
    "\n",
    "# Rolling Sharpe & Beta toàn kỳ\n",
    "window=60\n",
    "roll_sharpe = returns.rolling(window).mean()/returns.rolling(window).std()\n",
    "plt.figure(figsize=(10,4)); plt.plot(roll_sharpe,label=\"Rolling Sharpe (60d)\")\n",
    "plt.axhline(0,color=\"grey\",ls=\"--\"); plt.legend(); plt.grid(True,alpha=0.3)\n",
    "plt.title(\"Rolling Sharpe (toàn kỳ)\"); plt.savefig(os.path.join(OUTPUT_DIR,\"rolling_sharpe.png\")); plt.close()\n",
    "\n",
    "betas=[]\n",
    "for i in range(len(returns)-window):\n",
    "    y=returns.iloc[i:i+window]; x=bench_ret.iloc[i:i+window]\n",
    "    if x.std()==0: betas.append(np.nan); continue\n",
    "    X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
    "roll_beta=pd.Series(betas,index=returns.index[window:])\n",
    "plt.figure(figsize=(10,4)); plt.plot(roll_beta,label=\"Rolling Beta (60d)\")\n",
    "plt.axhline(1,color=\"grey\",ls=\"--\"); plt.legend(); plt.grid(True,alpha=0.3)\n",
    "plt.title(\"Rolling Beta (toàn kỳ)\"); plt.savefig(os.path.join(OUTPUT_DIR,\"rolling_beta.png\")); plt.close()\n",
    "\n",
    "# ---------- Heatmap Monthly Return + số giao dịch + winrate ----------\n",
    "monthly = returns.resample(\"M\").agg([\"sum\",\"count\",lambda x:(x>0).mean()])\n",
    "monthly.columns=[\"Return\",\"Trades\",\"WinRate\"]\n",
    "pivot=monthly.pivot_table(values=\"Return\",index=monthly.index.year,columns=monthly.index.month)\n",
    "plt.figure(figsize=(12,6)); sns.heatmap(pivot,annot=True,fmt=\".2%\",cmap=\"RdYlGn\",center=0)\n",
    "plt.title(\"Heatmap lợi nhuận hàng tháng\"); plt.savefig(os.path.join(OUTPUT_DIR,\"heatmap_monthly.png\")); plt.close()\n",
    "monthly.to_csv(os.path.join(OUTPUT_DIR,\"monthly_stats.csv\"))\n",
    "\n",
    "# ---------- Stress Test ----------\n",
    "stress_start, stress_end = pd.Timestamp(\"2025-03-26\"), pd.Timestamp(\"2025-04-15\")\n",
    "stress_name = \"Trump thông báo đánh thuế 46% hàng hóa Việt Nam\"\n",
    "sub_port, sub_bench = port_val.loc[stress_start:stress_end], bench_val.loc[stress_start:stress_end]\n",
    "sub_ret=sub_port.pct_change().fillna(0.0)\n",
    "stats_stress={}\n",
    "if len(sub_port)>1:\n",
    "    stats_stress=compute_stats(sub_port,sub_bench)\n",
    "    plot_equity(sub_port,sub_bench,f\"Equity ({stress_name})\",os.path.join(OUTPUT_DIR,\"equity_stress.png\"))\n",
    "    plot_hist(sub_ret,f\"Histogram ({stress_name})\",os.path.join(OUTPUT_DIR,\"hist_stress.png\"))\n",
    "    # Drawdown so sánh benchmark\n",
    "    cum_p=(1+sub_ret).cumprod(); dd_p=cum_p/cum_p.cummax()-1\n",
    "    cum_b=(1+sub_bench.pct_change().fillna(0.0)).cumprod(); dd_b=cum_b/cum_b.cummax()-1\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(dd_p,label=\"Chiến lược\",color=\"red\"); plt.plot(dd_b,label=\"VNINDEX\",color=\"blue\")\n",
    "    plt.title(f\"Drawdown ({stress_name})\"); plt.legend(); plt.grid(True,alpha=0.3)\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR,\"drawdown_stress.png\")); plt.close()\n",
    "    # Rolling Sharpe\n",
    "    if len(sub_ret)>20:\n",
    "        rs=sub_ret.rolling(10).mean()/sub_ret.rolling(10).std()\n",
    "        plt.figure(figsize=(10,4)); plt.plot(rs,label=\"Rolling Sharpe (10d)\")\n",
    "        plt.axhline(0,color=\"grey\",ls=\"--\"); plt.legend(); plt.grid(True,alpha=0.3)\n",
    "        plt.title(f\"Rolling Sharpe ({stress_name})\"); plt.savefig(os.path.join(OUTPUT_DIR,\"rolling_sharpe_stress.png\")); plt.close()\n",
    "    # Rolling Beta\n",
    "    if len(sub_ret)>20:\n",
    "        beta_vals=[]; window=10; bench_r=sub_bench.pct_change().fillna(0.0)\n",
    "        for i in range(len(sub_ret)-window):\n",
    "            y=sub_ret.iloc[i:i+window]; x=bench_r.iloc[i:i+window]\n",
    "            X=sm.add_constant(x); model=sm.OLS(y,X).fit(); beta_vals.append(model.params[1])\n",
    "        rolling_beta=pd.Series(beta_vals,index=sub_ret.index[window:])\n",
    "        plt.figure(figsize=(10,4)); plt.plot(rolling_beta,label=\"Rolling Beta (10d)\")\n",
    "        plt.axhline(1,color=\"grey\",ls=\"--\"); plt.legend(); plt.grid(True,alpha=0.3)\n",
    "        plt.title(f\"Rolling Beta ({stress_name})\"); plt.savefig(os.path.join(OUTPUT_DIR,\"rolling_beta_stress.png\")); plt.close()\n",
    "\n",
    "# ---------- Top Holdings & Performance ----------\n",
    "weights_path = os.path.join(OUTPUT_DIR, \"ticker_weights_test.csv\")\n",
    "df_backtest_path = \"./backtest_ddpg/df_backtest.csv\"\n",
    "\n",
    "if os.path.exists(weights_path):\n",
    "    weights = pd.read_csv(weights_path, index_col=0, parse_dates=True)\n",
    "    mean_w=weights.mean().sort_values(ascending=False).head(10)\n",
    "    plt.figure(figsize=(10,6)); mean_w.plot(kind=\"bar\"); plt.title(\"Top 10 cổ phiếu phân bổ vốn cao nhất\"); plt.ylabel(\"Tỷ trọng\")\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR,\"top10_weights.png\")); plt.close()\n",
    "\n",
    "if os.path.exists(df_backtest_path):\n",
    "    df_backtest = pd.read_csv(df_backtest_path, parse_dates=[\"timestamp\"])\n",
    "    df_backtest = df_backtest.groupby([\"timestamp\",\"ticker\"],as_index=False).agg({\"close\":\"last\"})\n",
    "    px = df_backtest.pivot(index=\"timestamp\", columns=\"ticker\", values=\"close\").sort_index()\n",
    "    ret_wide = px.pct_change().fillna(0.0)\n",
    "    cum_ret_tk=(1+ret_wide).cumprod().iloc[-1]-1\n",
    "    top_gain=cum_ret_tk.sort_values(ascending=False).head(10)\n",
    "    top_loss=cum_ret_tk.sort_values().head(10)\n",
    "    plt.figure(figsize=(10,6)); top_gain.plot(kind=\"bar\",color=\"green\"); plt.title(\"Top 10 cổ phiếu lãi nhiều nhất\"); plt.savefig(os.path.join(OUTPUT_DIR,\"top10_gain.png\")); plt.close()\n",
    "    plt.figure(figsize=(10,6)); top_loss.plot(kind=\"bar\",color=\"red\"); plt.title(\"Top 10 cổ phiếu lỗ nhiều nhất\"); plt.savefig(os.path.join(OUTPUT_DIR,\"top10_loss.png\")); plt.close()\n",
    "\n",
    "# ---------- Save Stats ----------\n",
    "all_stats={\"Test\":stats_test}\n",
    "if stats_stress: all_stats[\"Stress Test\"]=stats_stress\n",
    "pd.DataFrame(all_stats).T.to_csv(STATS_FILE)\n",
    "\n",
    "print(\"📊 Kết quả Test:\"); print(pd.Series(stats_test))\n",
    "if stats_stress: print(f\"\\n📊 Stress Test ({stress_name}):\"); print(pd.Series(stats_stress))\n",
    "print(f\"\\n✅ Block 11 hoàn tất. Stats lưu tại: {STATS_FILE}, Charts in {OUTPUT_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
