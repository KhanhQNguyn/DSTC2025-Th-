{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d4d6cad",
   "metadata": {},
   "source": [
    "**HƯỚNG DẪN CHẠY**\n",
    "\n",
    "*Nhóm chạy code theo thứ tự từng cell từ trên xuống xuống dưới*\n",
    "\n",
    "**Một số điểm lưu ý:**\n",
    "\n",
    "- *Thời gian chạy các block đa số lâu (Khoảng 10 phút riêng block 6 khoảng 25 phút)*\n",
    "\n",
    "- *Các block 8,9,10,11 có lưu kết quả file csv* \n",
    "\n",
    "- **Các file csv kết quả nhóm có upload lên github**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2bbe97",
   "metadata": {},
   "source": [
    "**Tải các thư viện cần thiết** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e11e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy torch scikit-learn matplotlib\n",
    "!pip install --extra-index-url https://fiinquant.github.io/fiinquantx/simple fiinquantx\n",
    "!pip install --upgrade --extra-index-url https://fiinquant.github.io/fiinquantx/simple fiinquantx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565db80b",
   "metadata": {},
   "source": [
    "**Block 1: tải dữ liệu lịch sử và realtime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5a2bf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số mã HOSE: 413\n",
      "Fetching data, it may take a while. Please wait...\n",
      "History ban đầu:   ticker         timestamp      open      high       low     close     volume  \\\n",
      "0    AAA  2023-01-03 00:00  6539.643  6866.145  6539.643  6866.145  1543984.0   \n",
      "1    AAA  2023-01-04 00:00  6866.145  7000.587  6827.733  6827.733  1302505.0   \n",
      "2    AAA  2023-01-05 00:00  6866.145  6904.557  6808.527  6885.351   980473.0   \n",
      "3    AAA  2023-01-06 00:00  6885.351  6990.984  6818.130  6856.542  1431699.0   \n",
      "4    AAA  2023-01-09 00:00  6914.160  6962.175  6760.512  6789.321  1121385.0   \n",
      "\n",
      "         bu        sd           fs           fn  \n",
      "0  938600.0  504700.0   40579000.0  899404000.0  \n",
      "1  462900.0  780600.0  151639000.0   36850000.0  \n",
      "2  487200.0  473700.0  343911000.0  -59103000.0  \n",
      "3  564300.0  828300.0  345999000.0 -294312000.0  \n",
      "4  414000.0  631800.0  514557000.0 -483197000.0  \n"
     ]
    }
   ],
   "source": [
    "# Block 1 — Login & Lấy dữ liệu tất cả HOSE/HNX/UPCOM\n",
    "import pandas as pd\n",
    "from FiinQuantX import FiinSession, BarDataUpdate\n",
    "# --- Login ---\n",
    "username = \"DSTC_18@fiinquant.vn\"\n",
    "password = \"Fiinquant0606\"\n",
    "\n",
    "client = FiinSession(\n",
    "    username=username,\n",
    "    password=password\n",
    ").login()\n",
    "\n",
    "# --- Lấy danh sách cổ phiếu từng sàn ---\n",
    "tickers_hose  = list(client.TickerList(ticker=\"VNINDEX\"))     # HOSE\n",
    "print(f\"Số mã HOSE: {len(tickers_hose)}\")\n",
    "\n",
    "# --- Lấy dữ liệu lịch sử toàn bộ ---\n",
    "event_history = client.Fetch_Trading_Data(\n",
    "    realtime=False,\n",
    "    tickers=tickers_hose,\n",
    "    fields=['open','high','low','close','volume','bu','sd','fs','fn'], \n",
    "    adjusted=True,\n",
    "    by=\"1d\",\n",
    "    from_date=\"2023-01-01\"   # Lấy dữ liệu từ 2023 tới nay\n",
    ")\n",
    "\n",
    "df_all = event_history.get_data()\n",
    "print(\"History ban đầu:\", df_all.head())\n",
    "\n",
    "# --- Callback realtime ---\n",
    "def onDataUpdate(data: BarDataUpdate):\n",
    "    global df_all\n",
    "    df_update = data.to_dataFrame()\n",
    "    df_all = pd.concat([df_all, df_update])\n",
    "    df_all = df_all.drop_duplicates()\n",
    "    print(\"Realtime update:\")\n",
    "    print(df_update.head())\n",
    "\n",
    "# --- Bật realtime nối tiếp dữ liệu ---\n",
    "event_realtime = client.Fetch_Trading_Data(\n",
    "    realtime=True,\n",
    "    tickers=tickers_hose,\n",
    "    fields=['open','high','low','close','volume','bu','sd','fs','fn'], \n",
    "    adjusted=True,\n",
    "    by=\"1d\",\n",
    "    period=1,\n",
    "    callback=onDataUpdate\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1122224",
   "metadata": {},
   "source": [
    "**Block 2: lấy dữ liệu FA, lọc các mã không hợp lệ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c93b463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số mã VNINDEX tổng: 413\n",
      "Resume: đã phát hiện 3 ticker đã xử lý trong 'vnindex_fa_quarterly_vnstock.csv'.\n",
      "Skip CCC (đã có trong processed/master/invalid).\n",
      "Skip SBG (đã có trong processed/master/invalid).\n",
      "[FUCTVGF3] ❌ Mã không hợp lệ — BỎ QUA (không retry). Message: Mã chứng khoán không hợp lệ. Chỉ cổ phiếu mới có thông tin.\n",
      "[FUEIP100] ❌ Mã không hợp lệ — BỎ QUA (không retry). Message: Mã chứng khoán không hợp lệ. Chỉ cổ phiếu mới có thông tin.\n",
      "[GMH] ✓ Lấy xong và lưu (rows=18).\n",
      "[FUEKIV30] ❌ Mã không hợp lệ — BỎ QUA (không retry). Message: Mã chứng khoán không hợp lệ. Chỉ cổ phiếu mới có thông tin.\n",
      "[NO1] ✓ Lấy xong và lưu (rows=17).\n",
      "[FUCTVGF4] ❌ Mã không hợp lệ — BỎ QUA (không retry). Message: Mã chứng khoán không hợp lệ. Chỉ cổ phiếu mới có thông tin.\n",
      "[RYG] ✓ Lấy xong và lưu (rows=7).\n",
      "[FUEDCMID] ❌ Mã không hợp lệ — BỎ QUA (không retry). Message: Mã chứng khoán không hợp lệ. Chỉ cổ phiếu mới có thông tin.\n",
      "[FUEKIVFS] ❌ Mã không hợp lệ — BỎ QUA (không retry). Message: Mã chứng khoán không hợp lệ. Chỉ cổ phiếu mới có thông tin.\n",
      "[FUEMAVND] ❌ Mã không hợp lệ — BỎ QUA (không retry). Message: Mã chứng khoán không hợp lệ. Chỉ cổ phiếu mới có thông tin.\n",
      "[FUEFCV50] ❌ Mã không hợp lệ — BỎ QUA (không retry). Message: Mã chứng khoán không hợp lệ. Chỉ cổ phiếu mới có thông tin.\n",
      "[FUEBFVND] ❌ Mã không hợp lệ — BỎ QUA (không retry). Message: Mã chứng khoán không hợp lệ. Chỉ cổ phiếu mới có thông tin.\n",
      "[FUCTVGF5] ❌ Mã không hợp lệ — BỎ QUA (không retry). Message: Mã chứng khoán không hợp lệ. Chỉ cổ phiếu mới có thông tin.\n",
      "[FUEKIVND] ❌ Mã không hợp lệ — BỎ QUA (không retry). Message: Mã chứng khoán không hợp lệ. Chỉ cổ phiếu mới có thông tin.\n",
      "[FUEABVND] ❌ Mã không hợp lệ — BỎ QUA (không retry). Message: Mã chứng khoán không hợp lệ. Chỉ cổ phiếu mới có thông tin.\n",
      "[FUETCC50] ❌ Mã không hợp lệ — BỎ QUA (không retry). Message: Mã chứng khoán không hợp lệ. Chỉ cổ phiếu mới có thông tin.\n",
      "[FUETPVND] ❌ Mã không hợp lệ — BỎ QUA (không retry). Message: Mã chứng khoán không hợp lệ. Chỉ cổ phiếu mới có thông tin.\n",
      "[AAA] ✓ Lấy xong và lưu (rows=50).\n",
      "[AAM] ✓ Lấy xong và lưu (rows=50).\n",
      "[AAT] ✓ Lấy xong và lưu (rows=28).\n",
      "[ABR] ✓ Lấy xong và lưu (rows=23).\n",
      "[ABS] ✓ Lấy xong và lưu (rows=26).\n",
      "[ABT] ✓ Lấy xong và lưu (rows=50).\n",
      "[ACB] ✓ Lấy xong và lưu (rows=51).\n",
      "[ACC] ✓ Lấy xong và lưu (rows=50).\n",
      "[ACL] ✓ Lấy xong và lưu (rows=50).\n",
      "[ADP] ✓ Lấy xong và lưu (rows=35).\n",
      "[AGR] ✓ Lấy xong và lưu (rows=50).\n",
      "[AGG] ✓ Lấy xong và lưu (rows=25).\n",
      "[ACG] ✓ Lấy xong và lưu (rows=29).\n",
      "[ANV] ✓ Lấy xong và lưu (rows=52).\n",
      "[APG] ✓ Lấy xong và lưu (rows=50).\n",
      "[APH] ✓ Lấy xong và lưu (rows=22).\n",
      "[HII] ✓ Lấy xong và lưu (rows=34).\n",
      "[ASG] ✓ Lấy xong và lưu (rows=28).\n",
      "[ASM] ✓ Lấy xong và lưu (rows=50).\n",
      "[ASP] ✓ Lấy xong và lưu (rows=50).\n",
      "[BAF] ✓ Lấy xong và lưu (rows=17).\n",
      "[BBC] ✓ Lấy xong và lưu (rows=50).\n",
      "[BCE] ✓ Lấy xong và lưu (rows=50).\n",
      "[BCG] ✓ Lấy xong và lưu (rows=39).\n",
      "[BFC] ✓ Lấy xong và lưu (rows=43).\n",
      "[BHN] ✓ Lấy xong và lưu (rows=37).\n",
      "[BIC] ✓ Lấy xong và lưu (rows=50).\n",
      "[BID] ✓ Lấy xong và lưu (rows=50).\n",
      "[BCM] ✓ Lấy xong và lưu (rows=30).\n",
      "[DBD] ✓ Lấy xong và lưu (rows=42).\n",
      "[BWE] ✓ Lấy xong và lưu (rows=35).\n",
      "[BKG] ✓ Lấy xong và lưu (rows=21).\n",
      "[BMC] ✓ Lấy xong và lưu (rows=50).\n",
      "[BMI] ✓ Lấy xong và lưu (rows=50).\n",
      "[BMP] ✓ Lấy xong và lưu (rows=50).\n",
      "[BRC] ✓ Lấy xong và lưu (rows=50).\n",
      "[BSI] ✓ Lấy xong và lưu (rows=50).\n",
      "[BSR] ✓ Lấy xong và lưu (rows=31).\n",
      "[BTP] ✓ Lấy xong và lưu (rows=50).\n",
      "[BTT] ✓ Lấy xong và lưu (rows=50).\n",
      "[BVH] ✓ Lấy xong và lưu (rows=50).\n",
      "[TNH] ✓ Lấy xong và lưu (rows=22).\n",
      "[C32] ✓ Lấy xong và lưu (rows=50).\n",
      "[C47] ✓ Lấy xong và lưu (rows=50).\n",
      "[CCI] ✓ Lấy xong và lưu (rows=50).\n",
      "[CCL] ✓ Lấy xong và lưu (rows=50).\n",
      "[CDC] ✓ Lấy xong và lưu (rows=52).\n",
      "[CRE] ✓ Lấy xong và lưu (rows=30).\n",
      "[STK] ✓ Lấy xong và lưu (rows=43).\n",
      "[CHP] ✓ Lấy xong và lưu (rows=50).\n",
      "[CIG] ✓ Lấy xong và lưu (rows=50).\n",
      "[CII] ✓ Lấy xong và lưu (rows=50).\n",
      "[CKG] ⚠️ Rate limit detected (attempt 1/6). Đợi 502.2s rồi thử lại. Message: Failed to fetch data: 502 - Bad Gateway\n",
      "[CKG] ✓ Lấy xong và lưu (rows=38).\n",
      "[CLC] ✓ Lấy xong và lưu (rows=50).\n",
      "[ADG] ✓ Lấy xong và lưu (rows=20).\n",
      "[CLL] ✓ Lấy xong và lưu (rows=50).\n",
      "[CLW] ✓ Lấy xong và lưu (rows=50).\n",
      "[CMG] ✓ Lấy xong và lưu (rows=50).\n",
      "[CMV] ✓ Lấy xong và lưu (rows=50).\n",
      "[CMX] ✓ Lấy xong và lưu (rows=50).\n",
      "[CNG] ✓ Lấy xong và lưu (rows=50).\n",
      "[COM] ✓ Lấy xong và lưu (rows=50).\n",
      "[CRC] ✓ Lấy xong và lưu (rows=34).\n",
      "[CSM] ✓ Lấy xong và lưu (rows=50).\n",
      "[CSV] ✓ Lấy xong và lưu (rows=44).\n",
      "[CTD] ✓ Lấy xong và lưu (rows=50).\n",
      "[CTF] ✓ Lấy xong và lưu (rows=35).\n",
      "[CTG] ✓ Lấy xong và lưu (rows=53).\n",
      "[CTI] ✓ Lấy xong và lưu (rows=50).\n",
      "[ICT] ✓ Lấy xong và lưu (rows=31).\n",
      "[CTR] ✓ Lấy xong và lưu (rows=50).\n",
      "[CTS] ✓ Lấy xong và lưu (rows=50).\n",
      "[CVT] ✓ Lấy xong và lưu (rows=50).\n",
      "[D2D] ✓ Lấy xong và lưu (rows=50).\n",
      "[DAH] ✓ Lấy xong và lưu (rows=37).\n",
      "[ADS] ✓ Lấy xong và lưu (rows=38).\n",
      "[DPG] ✓ Lấy xong và lưu (rows=31).\n",
      "[DBC] ✓ Lấy xong và lưu (rows=51).\n",
      "[DBT] ✓ Lấy xong và lưu (rows=50).\n",
      "[DC4] ✓ Lấy xong và lưu (rows=50).\n",
      "[DCL] ✓ Lấy xong và lưu (rows=50).\n",
      "[DCM] ✓ Lấy xong và lưu (rows=42).\n",
      "[DGC] ✓ Lấy xong và lưu (rows=47).\n",
      "[DGW] ✓ Lấy xong và lưu (rows=42).\n",
      "[DHA] ✓ Lấy xong và lưu (rows=50).\n",
      "[DHC] ✓ Lấy xong và lưu (rows=50).\n",
      "[DHG] ✓ Lấy xong và lưu (rows=50).\n",
      "[DHM] ✓ Lấy xong và lưu (rows=50).\n",
      "[TTE] ✓ Lấy xong và lưu (rows=30).\n",
      "[DIG] ✓ Lấy xong và lưu (rows=50).\n",
      "[DLG] ✓ Lấy xong và lưu (rows=50).\n",
      "[DMC] ✓ Lấy xong và lưu (rows=52).\n",
      "[DSC] ✓ Lấy xong và lưu (rows=50).\n",
      "[DSE] ✓ Lấy xong và lưu (rows=52).\n",
      "[DPM] ✓ Lấy xong và lưu (rows=50).\n",
      "[DPR] ✓ Lấy xong và lưu (rows=50).\n",
      "[DQC] ✓ Lấy xong và lưu (rows=50).\n",
      "[DRC] ✓ Lấy xong và lưu (rows=50).\n",
      "[DRH] ✓ Lấy xong và lưu (rows=50).\n",
      "[DRL] ✓ Lấy xong và lưu (rows=50).\n",
      "[DSN] ✓ Lấy xong và lưu (rows=50).\n",
      "[DTA] ✓ Lấy xong và lưu (rows=50).\n",
      "[DTL] ✓ Lấy xong và lưu (rows=50).\n",
      "[DTT] ✓ Lấy xong và lưu (rows=50).\n",
      "[DVP] ✓ Lấy xong và lưu (rows=50).\n",
      "[DXG] ✓ Lấy xong và lưu (rows=50).\n",
      "[DXS] ✓ Lấy xong và lưu (rows=18).\n",
      "[DXV] ✓ Lấy xong và lưu (rows=50).\n",
      "[FUESSV50] ❌ Mã không hợp lệ — BỎ QUA (không retry). Message: Mã chứng khoán không hợp lệ. Chỉ cổ phiếu mới có thông tin.\n",
      "[E1VFVN30] ❌ Mã không hợp lệ — BỎ QUA (không retry). Message: Mã chứng khoán không hợp lệ. Chỉ cổ phiếu mới có thông tin.\n",
      "[EIB] ✓ Lấy xong và lưu (rows=50).\n",
      "[ELC] ✓ Lấy xong và lưu (rows=50).\n",
      "[FUESSVFL] ❌ Mã không hợp lệ — BỎ QUA (không retry). Message: Mã chứng khoán không hợp lệ. Chỉ cổ phiếu mới có thông tin.\n",
      "[EVE] ✓ Lấy xong và lưu (rows=50).\n",
      "[EVG] ✓ Lấy xong và lưu (rows=35).\n",
      "[EVF] ✓ Lấy xong và lưu (rows=46).\n",
      "[FCM] ✓ Lấy xong và lưu (rows=50).\n",
      "[FCN] ✓ Lấy xong và lưu (rows=50).\n",
      "[FDC] ✓ Lấy xong và lưu (rows=50).\n",
      "[FIR] ✓ Lấy xong và lưu (rows=31).\n",
      "[FIT] ✓ Lấy xong và lưu (rows=50).\n",
      "[FMC] ✓ Lấy xong và lưu (rows=50).\n",
      "[FPT] ✓ Lấy xong và lưu (rows=52).\n",
      "[FRT] ✓ Lấy xong và lưu (rows=33).\n",
      "[FTS] ✓ Lấy xong và lưu (rows=50).\n",
      "[FUEMAV30] ❌ Mã không hợp lệ — BỎ QUA (không retry). Message: Mã chứng khoán không hợp lệ. Chỉ cổ phiếu mới có thông tin.\n",
      "[FUESSV30] ❌ Mã không hợp lệ — BỎ QUA (không retry). Message: Mã chứng khoán không hợp lệ. Chỉ cổ phiếu mới có thông tin.\n",
      "[FUEVFVND] ❌ Mã không hợp lệ — BỎ QUA (không retry). Message: Mã chứng khoán không hợp lệ. Chỉ cổ phiếu mới có thông tin.\n",
      "[FUEVN100] ❌ Mã không hợp lệ — BỎ QUA (không retry). Message: Mã chứng khoán không hợp lệ. Chỉ cổ phiếu mới có thông tin.\n",
      "[GAS] ✓ Lấy xong và lưu (rows=50).\n",
      "[GDT] ✓ Lấy xong và lưu (rows=50).\n",
      "[GEX] ✓ Lấy xong và lưu (rows=50).\n",
      "[GEE] ✓ Lấy xong và lưu (rows=15).\n",
      "[PGV] ✓ Lấy xong và lưu (rows=34).\n",
      "[GIL] ✓ Lấy xong và lưu (rows=50).\n",
      "[GEG] ✓ Lấy xong và lưu (rows=42).\n",
      "[GMD] ✓ Lấy xong và lưu (rows=50).\n",
      "[GSP] ✓ Lấy xong và lưu (rows=50).\n",
      "[GTA] ✓ Lấy xong và lưu (rows=50).\n",
      "[HAG] ✓ Lấy xong và lưu (rows=54).\n",
      "[HAH] ✓ Lấy xong và lưu (rows=44).\n",
      "[HPX] ✓ Lấy xong và lưu (rows=30).\n",
      "[HID] ✓ Lấy xong và lưu (rows=39).\n",
      "[HHV] ✓ Lấy xong và lưu (rows=23).\n",
      "[HAP] ✓ Lấy xong và lưu (rows=50).\n",
      "[HAR] ✓ Lấy xong và lưu (rows=50).\n",
      "[HAS] ✓ Lấy xong và lưu (rows=50).\n",
      "[HAX] ✓ Lấy xong và lưu (rows=51).\n",
      "[HCD] ✓ Lấy xong và lưu (rows=38).\n",
      "[HCM] ✓ Lấy xong và lưu (rows=52).\n",
      "[HDB] ✓ Lấy xong và lưu (rows=45).\n",
      "[HDC] ✓ Lấy xong và lưu (rows=50).\n",
      "[HDG] ✓ Lấy xong và lưu (rows=52).\n",
      "[HHP] ✓ Lấy xong và lưu (rows=28).\n",
      "[HHS] ✓ Lấy xong và lưu (rows=50).\n",
      "[TCH] ✓ Lấy xong và lưu (rows=39).\n",
      "[HSL] ✓ Lấy xong và lưu (rows=31).\n",
      "[HMC] ✓ Lấy xong và lưu (rows=50).\n",
      "[HNA] ✓ Lấy xong và lưu (rows=39).\n",
      "[HPG] ✓ Lấy xong và lưu (rows=50).\n",
      "[HQC] ✓ Lấy xong và lưu (rows=50).\n",
      "[HRC] ✓ Lấy xong và lưu (rows=50).\n",
      "[HSG] ✓ Lấy xong và lưu (rows=50).\n",
      "[HT1] ✓ Lấy xong và lưu (rows=50).\n",
      "[HTG] ✓ Lấy xong và lưu (rows=42).\n",
      "[HTI] ✓ Lấy xong và lưu (rows=50).\n",
      "[HTN] ✓ Lấy xong và lưu (rows=30).\n",
      "[HTL] ✓ Lấy xong và lưu (rows=50).\n",
      "[HTV] ✓ Lấy xong và lưu (rows=49).\n",
      "[HU1] ✓ Lấy xong và lưu (rows=50).\n",
      "[HVH] ✓ Lấy xong và lưu (rows=30).\n",
      "[HVX] ✓ Lấy xong và lưu (rows=50).\n",
      "[ILB] ✓ Lấy xong và lưu (rows=42).\n",
      "[IDI] ✓ Lấy xong và lưu (rows=50).\n",
      "[IJC] ✓ Lấy xong và lưu (rows=50).\n",
      "[IMP] ✓ Lấy xong và lưu (rows=50).\n",
      "[ITC] ✓ Lấy xong và lưu (rows=50).\n",
      "[ITD] ✓ Lấy xong và lưu (rows=50).\n",
      "[JVC] ✓ Lấy xong và lưu (rows=50).\n",
      "[KBC] ✓ Lấy xong và lưu (rows=50).\n",
      "[KDC] ✓ Lấy xong và lưu (rows=50).\n",
      "[KDH] ✓ Lấy xong và lưu (rows=50).\n",
      "[KHG] ✓ Lấy xong và lưu (rows=18).\n",
      "[KHP] ✓ Lấy xong và lưu (rows=50).\n",
      "[KMR] ✓ Lấy xong và lưu (rows=50).\n",
      "[KOS] ✓ Lấy xong và lưu (rows=32).\n",
      "[KSB] ✓ Lấy xong và lưu (rows=50).\n",
      "[L10] ✓ Lấy xong và lưu (rows=50).\n",
      "[LAF] ✓ Lấy xong và lưu (rows=50).\n",
      "[LBM] ✓ Lấy xong và lưu (rows=51).\n",
      "[LCG] ✓ Lấy xong và lưu (rows=51).\n",
      "[LDG] ✓ Lấy xong và lưu (rows=42).\n",
      "[LGC] ✓ Lấy xong và lưu (rows=50).\n",
      "[LGL] ✓ Lấy xong và lưu (rows=50).\n",
      "[LHG] ✓ Lấy xong và lưu (rows=50).\n",
      "[LIX] ✓ Lấy xong và lưu (rows=50).\n",
      "[LM8] ✓ Lấy xong và lưu (rows=50).\n",
      "[LSS] ✓ Lấy xong và lưu (rows=50).\n",
      "[LPB] ✓ Lấy xong và lưu (rows=47).\n",
      "[MBB] ✓ Lấy xong và lưu (rows=56).\n",
      "[MCM] ✓ Lấy xong và lưu (rows=22).\n",
      "[MCP] ✓ Lấy xong và lưu (rows=50).\n",
      "[MDG] ✓ Lấy xong và lưu (rows=50).\n",
      "[MHC] ✓ Lấy xong và lưu (rows=50).\n",
      "[MIG] ✓ Lấy xong và lưu (rows=42).\n",
      "[MSB] ✓ Lấy xong và lưu (rows=39).\n",
      "[MSN] ✓ Lấy xong và lưu (rows=51).\n",
      "[MWG] ✓ Lấy xong và lưu (rows=46).\n",
      "[NAB] ✓ Lấy xong và lưu (rows=50).\n",
      "[NAF] ✓ Lấy xong và lưu (rows=41).\n",
      "[NAV] ✓ Lấy xong và lưu (rows=50).\n",
      "[NBB] ✓ Lấy xong và lưu (rows=50).\n",
      "[NCT] ✓ Lấy xong và lưu (rows=45).\n",
      "[NHA] ✓ Lấy xong và lưu (rows=50).\n",
      "[NHH] ✓ Lấy xong và lưu (rows=26).\n",
      "[VHM] ✓ Lấy xong và lưu (rows=36).\n",
      "[NHT] ✓ Lấy xong và lưu (rows=27).\n",
      "[NKG] ✓ Lấy xong và lưu (rows=50).\n",
      "[NLG] ✓ Lấy xong và lưu (rows=50).\n",
      "[NNC] ✓ Lấy xong và lưu (rows=50).\n",
      "[NVL] ✓ Lấy xong và lưu (rows=38).\n",
      "[NSC] ✓ Lấy xong và lưu (rows=50).\n",
      "[NT2] ✓ Lấy xong và lưu (rows=50).\n",
      "[NTL] ✓ Lấy xong và lưu (rows=50).\n",
      "[NVT] ✓ Lấy xong và lưu (rows=50).\n",
      "[OCB] ✓ Lấy xong và lưu (rows=46).\n",
      "[OGC] ✓ Lấy xong và lưu (rows=50).\n",
      "[OPC] ✓ Lấy xong và lưu (rows=50).\n",
      "[ORS] ✓ Lấy xong và lưu (rows=50).\n",
      "[PAC] ✓ Lấy xong và lưu (rows=50).\n",
      "[PAN] ✓ Lấy xong và lưu (rows=50).\n",
      "[PC1] ✓ Lấy xong và lưu (rows=49).\n",
      "[PDN] ✓ Lấy xong và lưu (rows=50).\n",
      "[PDR] ✓ Lấy xong và lưu (rows=50).\n",
      "[PET] ✓ Lấy xong và lưu (rows=50).\n",
      "[PLX] ✓ Lấy xong và lưu (rows=47).\n",
      "[PGC] ✓ Lấy xong và lưu (rows=50).\n",
      "[PGD] ✓ Lấy xong và lưu (rows=50).\n",
      "[PGI] ✓ Lấy xong và lưu (rows=50).\n",
      "[PLP] ✓ Lấy xong và lưu (rows=33).\n",
      "[PHC] ✓ Lấy xong và lưu (rows=50).\n",
      "[PHR] ✓ Lấy xong và lưu (rows=50).\n",
      "[PIT] ✓ Lấy xong và lưu (rows=50).\n",
      "[PJT] ✓ Lấy xong và lưu (rows=50).\n",
      "[PMG] ✓ Lấy xong và lưu (rows=32).\n",
      "[PNC] ✓ Lấy xong và lưu (rows=50).\n",
      "[PNJ] ✓ Lấy xong và lưu (rows=50).\n",
      "[PPC] ✓ Lấy xong và lưu (rows=50).\n",
      "[PTB] ✓ Lấy xong và lưu (rows=50).\n",
      "[PTC] ✓ Lấy xong và lưu (rows=50).\n",
      "[PTL] ✓ Lấy xong và lưu (rows=50).\n",
      "[DAT] ✓ Lấy xong và lưu (rows=40).\n",
      "[PVD] ✓ Lấy xong và lưu (rows=50).\n",
      "[POW] ✓ Lấy xong và lưu (rows=34).\n",
      "[PVT] ✓ Lấy xong và lưu (rows=51).\n",
      "[PVP] ✓ Lấy xong và lưu (rows=49).\n",
      "[QCG] ✓ Lấy xong và lưu (rows=50).\n",
      "[QNP] ✓ Lấy xong và lưu (rows=34).\n",
      "[RAL] ✓ Lấy xong và lưu (rows=50).\n",
      "[REE] ✓ Lấy xong và lưu (rows=50).\n",
      "[SGN] ✓ Lấy xong và lưu (rows=42).\n",
      "[SAM] ✓ Lấy xong và lưu (rows=50).\n",
      "[SAV] ✓ Lấy xong và lưu (rows=50).\n",
      "[SBA] ✓ Lấy xong và lưu (rows=50).\n",
      "[SAB] ✓ Lấy xong và lưu (rows=48).\n",
      "[SBT] ✓ Lấy xong và lưu (rows=50).\n",
      "[SC5] ✓ Lấy xong và lưu (rows=50).\n",
      "[SCR] ✓ Lấy xong và lưu (rows=50).\n",
      "[SCS] ✓ Lấy xong và lưu (rows=43).\n",
      "[SSB] ✓ Lấy xong và lưu (rows=39).\n",
      "[SFC] ✓ Lấy xong và lưu (rows=50).\n",
      "[SFG] ✓ Lấy xong và lưu (rows=49).\n",
      "[SFI] ✓ Lấy xong và lưu (rows=50).\n",
      "[SGR] ✓ Lấy xong và lưu (rows=38).\n",
      "[SGT] ✓ Lấy xong và lưu (rows=47).\n",
      "[SIP] ✓ Lấy xong và lưu (rows=26).\n",
      "[SHA] ✓ Lấy xong và lưu (rows=50).\n",
      "[SHB] ✓ Lấy xong và lưu (rows=50).\n",
      "[MSH] ✓ Lấy xong và lưu (rows=38).\n",
      "[SHI] ✓ Lấy xong và lưu (rows=50).\n",
      "[SHP] ✓ Lấy xong và lưu (rows=50).\n",
      "[SBV] ✓ Lấy xong và lưu (rows=35).\n",
      "[SZC] ✓ Lấy xong và lưu (rows=50).\n",
      "[SJD] ✓ Lấy xong và lưu (rows=50).\n",
      "[SJS] ✓ Lấy xong và lưu (rows=51).\n",
      "[SKG] ✓ Lấy xong và lưu (rows=48).\n",
      "[SMA] ✓ Lấy xong và lưu (rows=50).\n",
      "[SMB] ✓ Lấy xong và lưu (rows=49).\n",
      "[SMC] ✓ Lấy xong và lưu (rows=50).\n",
      "[SPM] ✓ Lấy xong và lưu (rows=50).\n",
      "[SRC] ✓ Lấy xong và lưu (rows=50).\n",
      "[SRF] ✓ Lấy xong và lưu (rows=50).\n",
      "[S4A] ✓ Lấy xong và lưu (rows=42).\n",
      "[SSC] ✓ Lấy xong và lưu (rows=50).\n",
      "[SSI] ✓ Lấy xong và lưu (rows=50).\n",
      "[ST8] ✓ Lấy xong và lưu (rows=50).\n",
      "[STB] ✓ Lấy xong và lưu (rows=50).\n",
      "[STG] ✓ Lấy xong và lưu (rows=50).\n",
      "[SVC] ✓ Lấy xong và lưu (rows=50).\n",
      "[SVD] ✓ Lấy xong và lưu (rows=21).\n",
      "[SVI] ✓ Lấy xong và lưu (rows=50).\n",
      "[SVT] ✓ Lấy xong và lưu (rows=50).\n",
      "[SZL] ✓ Lấy xong và lưu (rows=50).\n",
      "[AST] ✓ Lấy xong và lưu (rows=33).\n",
      "[TAL] ✓ Lấy xong và lưu (rows=8).\n",
      "[TBC] ✓ Lấy xong và lưu (rows=50).\n",
      "[TCB] ✓ Lấy xong và lưu (rows=50).\n",
      "[TCL] ✓ Lấy xong và lưu (rows=49).\n",
      "[TCM] ✓ Lấy xong và lưu (rows=50).\n",
      "[TCO] ✓ Lấy xong và lưu (rows=50).\n",
      "[TCR] ✓ Lấy xong và lưu (rows=50).\n",
      "[FUCVREIT] ❌ Mã không hợp lệ — BỎ QUA (không retry). Message: Mã chứng khoán không hợp lệ. Chỉ cổ phiếu mới có thông tin.\n",
      "[TCI] ✓ Lấy xong và lưu (rows=50).\n",
      "[TCT] ✓ Lấy xong và lưu (rows=50).\n",
      "[TDC] ✓ Lấy xong và lưu (rows=50).\n",
      "[TDG] ✓ Lấy xong và lưu (rows=35).\n",
      "[TDH] ✓ Lấy xong và lưu (rows=50).\n",
      "[TDM] ✓ Lấy xong và lưu (rows=38).\n",
      "[TDP] ✓ Lấy xong và lưu (rows=30).\n",
      "[TDW] ✓ Lấy xong và lưu (rows=50).\n",
      "[TEG] ✓ Lấy xong và lưu (rows=39).\n",
      "[THG] ✓ Lấy xong và lưu (rows=50).\n",
      "[TIP] ✓ Lấy xong và lưu (rows=50).\n",
      "[TIX] ✓ Lấy xong và lưu (rows=50).\n",
      "[TLD] ✓ Lấy xong và lưu (rows=32).\n",
      "[TLG] ✓ Lấy xong và lưu (rows=50).\n",
      "[TLH] ✓ Lấy xong và lưu (rows=50).\n",
      "[TMP] ✓ Lấy xong và lưu (rows=50).\n",
      "[TMS] ✓ Lấy xong và lưu (rows=50).\n",
      "[TMT] ✓ Lấy xong và lưu (rows=50).\n",
      "[TN1] ✓ Lấy xong và lưu (rows=29).\n",
      "[TNC] ✓ Lấy xong và lưu (rows=50).\n",
      "[TNI] ✓ Lấy xong và lưu (rows=38).\n",
      "[TNT] ✓ Lấy xong và lưu (rows=50).\n",
      "[TPB] ✓ Lấy xong và lưu (rows=42).\n",
      "[TPC] ✓ Lấy xong và lưu (rows=50).\n",
      "[TRA] ✓ Lấy xong và lưu (rows=50).\n",
      "[TCD] ✓ Lấy xong và lưu (rows=35).\n",
      "[TRC] ✓ Lấy xong và lưu (rows=51).\n",
      "[TVB] ✓ Lấy xong và lưu (rows=50).\n",
      "[TSC] ✓ Lấy xong và lưu (rows=50).\n",
      "[TTA] ✓ Lấy xong và lưu (rows=21).\n",
      "[TTF] ✓ Lấy xong và lưu (rows=50).\n",
      "[HUB] ✓ Lấy xong và lưu (rows=37).\n",
      "[TV2] ✓ Lấy xong và lưu (rows=50).\n",
      "[TVS] ✓ Lấy xong và lưu (rows=50).\n",
      "[TYA] ✓ Lấy xong và lưu (rows=50).\n",
      "[UIC] ✓ Lấy xong và lưu (rows=50).\n",
      "[VAB] ✓ Lấy xong và lưu (rows=41).\n",
      "[VAF] ✓ Lấy xong và lưu (rows=48).\n",
      "[VCA] ✓ Lấy xong và lưu (rows=50).\n",
      "[VCB] ✓ Lấy xong và lưu (rows=50).\n",
      "[VCF] ✓ Lấy xong và lưu (rows=50).\n",
      "[VCG] ✓ Lấy xong và lưu (rows=52).\n",
      "[VCI] ✓ Lấy xong và lưu (rows=50).\n",
      "[VDS] ✓ Lấy xong và lưu (rows=50).\n",
      "[VFG] ✓ Lấy xong và lưu (rows=50).\n",
      "[VGC] ✓ Lấy xong và lưu (rows=42).\n",
      "[VHC] ✓ Lấy xong và lưu (rows=50).\n",
      "[VIB] ✓ Lấy xong và lưu (rows=50).\n",
      "[VIC] ✓ Lấy xong và lưu (rows=51).\n",
      "[TVT] ✓ Lấy xong và lưu (rows=45).\n",
      "[VID] ✓ Lấy xong và lưu (rows=50).\n",
      "[VDP] ✓ Lấy xong và lưu (rows=35).\n",
      "[VJC] ✓ Lấy xong và lưu (rows=35).\n",
      "[VIP] ✓ Lấy xong và lưu (rows=50).\n",
      "[VPS] ✓ Lấy xong và lưu (rows=42).\n",
      "[VIX] ✓ Lấy xong và lưu (rows=58).\n",
      "[VMD] ✓ Lấy xong và lưu (rows=49).\n",
      "[HVN] ✓ Lấy xong và lưu (rows=42).\n",
      "[VND] ✓ Lấy xong và lưu (rows=51).\n",
      "[VNE] ✓ Lấy xong và lưu (rows=50).\n",
      "[VNG] ✓ Lấy xong và lưu (rows=50).\n",
      "[VNL] ✓ Lấy xong và lưu (rows=50).\n",
      "[VNM] ✓ Lấy xong và lưu (rows=50).\n",
      "[VPD] ✓ Lấy xong và lưu (rows=43).\n",
      "[GVR] ✓ Lấy xong và lưu (rows=28).\n",
      "[VNS] ✓ Lấy xong và lưu (rows=50).\n",
      "[VOS] ✓ Lấy xong và lưu (rows=50).\n",
      "[VPB] ✓ Lấy xong và lưu (rows=50).\n",
      "[VPG] ✓ Lấy xong và lưu (rows=33).\n",
      "[VPH] ✓ Lấy xong và lưu (rows=50).\n",
      "[VPL] ✓ Lấy xong và lưu (rows=22).\n",
      "[VPI] ✓ Lấy xong và lưu (rows=32).\n",
      "[VRC] ✓ Lấy xong và lưu (rows=50).\n",
      "[VRE] ✓ Lấy xong và lưu (rows=33).\n",
      "[VSC] ✓ Lấy xong và lưu (rows=50).\n",
      "[VSH] ✓ Lấy xong và lưu (rows=50).\n",
      "[VSI] ✓ Lấy xong và lưu (rows=50).\n",
      "[VTB] ✓ Lấy xong và lưu (rows=51).\n",
      "[VTO] ✓ Lấy xong và lưu (rows=50).\n",
      "[VTP] ✓ Lấy xong và lưu (rows=37).\n",
      "[YBM] ✓ Lấy xong và lưu (rows=30).\n",
      "[YEG] ✓ Lấy xong và lưu (rows=31).\n",
      "=== Hoàn tất Block 2 (vnstock) ===\n",
      "Tổng tickers xử lý thành công: 389\n",
      "Tổng tickers bị đánh dấu INVALID và bỏ qua: 22\n",
      "Tổng tickers thất bại (retry hết nhưng không invalid): 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Meta</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Chỉ tiêu cơ cấu nguồn vốn</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Chỉ tiêu hiệu quả hoạt động</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"9\" halign=\"left\">Chỉ tiêu định giá</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>yearReport</th>\n",
       "      <th>lengthReport</th>\n",
       "      <th>(ST+LT borrowings)/Equity</th>\n",
       "      <th>Debt/Equity</th>\n",
       "      <th>Fixed Asset-To-Equity</th>\n",
       "      <th>Owners' Equity/Charter Capital</th>\n",
       "      <th>Asset Turnover</th>\n",
       "      <th>Fixed Asset Turnover</th>\n",
       "      <th>Days Sales Outstanding</th>\n",
       "      <th>...</th>\n",
       "      <th>Market Capital (Bn. VND)</th>\n",
       "      <th>Outstanding Share (Mil. Shares)</th>\n",
       "      <th>P/E</th>\n",
       "      <th>P/B</th>\n",
       "      <th>P/S</th>\n",
       "      <th>P/Cash Flow</th>\n",
       "      <th>EPS (VND)</th>\n",
       "      <th>BVPS (VND)</th>\n",
       "      <th>EV/EBITDA</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GMH</td>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051588</td>\n",
       "      <td>0.124650</td>\n",
       "      <td>1.090538</td>\n",
       "      <td>0.562538</td>\n",
       "      <td>4.422492</td>\n",
       "      <td>63.351078</td>\n",
       "      <td>...</td>\n",
       "      <td>1.452000e+11</td>\n",
       "      <td>16500000.0</td>\n",
       "      <td>11.480752</td>\n",
       "      <td>0.806941</td>\n",
       "      <td>1.362896</td>\n",
       "      <td>3.795689</td>\n",
       "      <td>356.816813</td>\n",
       "      <td>10905.381178</td>\n",
       "      <td>11.204889</td>\n",
       "      <td>GMH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GMH</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022473</td>\n",
       "      <td>0.051838</td>\n",
       "      <td>0.130708</td>\n",
       "      <td>1.089856</td>\n",
       "      <td>0.495824</td>\n",
       "      <td>3.693597</td>\n",
       "      <td>71.229634</td>\n",
       "      <td>...</td>\n",
       "      <td>1.311750e+11</td>\n",
       "      <td>16500000.0</td>\n",
       "      <td>16.681350</td>\n",
       "      <td>0.729454</td>\n",
       "      <td>1.406508</td>\n",
       "      <td>3.940808</td>\n",
       "      <td>121.619694</td>\n",
       "      <td>10898.564366</td>\n",
       "      <td>20.561323</td>\n",
       "      <td>GMH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GMH</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038005</td>\n",
       "      <td>0.138373</td>\n",
       "      <td>1.077694</td>\n",
       "      <td>0.461186</td>\n",
       "      <td>3.248087</td>\n",
       "      <td>69.708499</td>\n",
       "      <td>...</td>\n",
       "      <td>1.229250e+11</td>\n",
       "      <td>16500000.0</td>\n",
       "      <td>20.639945</td>\n",
       "      <td>0.691291</td>\n",
       "      <td>1.395969</td>\n",
       "      <td>10.732768</td>\n",
       "      <td>120.501797</td>\n",
       "      <td>10776.944672</td>\n",
       "      <td>19.378872</td>\n",
       "      <td>GMH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GMH</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>0.038418</td>\n",
       "      <td>0.106987</td>\n",
       "      <td>0.146877</td>\n",
       "      <td>1.065434</td>\n",
       "      <td>0.456444</td>\n",
       "      <td>3.178684</td>\n",
       "      <td>66.693418</td>\n",
       "      <td>...</td>\n",
       "      <td>1.313400e+11</td>\n",
       "      <td>16500000.0</td>\n",
       "      <td>21.487381</td>\n",
       "      <td>0.747113</td>\n",
       "      <td>1.491061</td>\n",
       "      <td>7.664694</td>\n",
       "      <td>167.561987</td>\n",
       "      <td>10654.338632</td>\n",
       "      <td>31.526449</td>\n",
       "      <td>GMH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GMH</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>0.015499</td>\n",
       "      <td>0.063503</td>\n",
       "      <td>0.156407</td>\n",
       "      <td>1.048888</td>\n",
       "      <td>0.438959</td>\n",
       "      <td>2.972644</td>\n",
       "      <td>64.985075</td>\n",
       "      <td>...</td>\n",
       "      <td>1.366200e+11</td>\n",
       "      <td>16500000.0</td>\n",
       "      <td>19.196756</td>\n",
       "      <td>0.789407</td>\n",
       "      <td>1.585955</td>\n",
       "      <td>11.360902</td>\n",
       "      <td>66.896642</td>\n",
       "      <td>10488.880887</td>\n",
       "      <td>18.004344</td>\n",
       "      <td>GMH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GMH</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009567</td>\n",
       "      <td>0.032987</td>\n",
       "      <td>0.150374</td>\n",
       "      <td>1.142198</td>\n",
       "      <td>0.473768</td>\n",
       "      <td>3.133843</td>\n",
       "      <td>60.882722</td>\n",
       "      <td>...</td>\n",
       "      <td>1.485000e+11</td>\n",
       "      <td>16500000.0</td>\n",
       "      <td>16.702805</td>\n",
       "      <td>0.787954</td>\n",
       "      <td>1.568495</td>\n",
       "      <td>14.300980</td>\n",
       "      <td>5.990141</td>\n",
       "      <td>11421.984245</td>\n",
       "      <td>15.236970</td>\n",
       "      <td>GMH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GMH</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047413</td>\n",
       "      <td>0.157043</td>\n",
       "      <td>1.142922</td>\n",
       "      <td>0.572311</td>\n",
       "      <td>3.624814</td>\n",
       "      <td>53.195105</td>\n",
       "      <td>...</td>\n",
       "      <td>1.658250e+11</td>\n",
       "      <td>16500000.0</td>\n",
       "      <td>12.102004</td>\n",
       "      <td>0.880344</td>\n",
       "      <td>1.460188</td>\n",
       "      <td>-104.265001</td>\n",
       "      <td>130.001223</td>\n",
       "      <td>11415.994104</td>\n",
       "      <td>12.309960</td>\n",
       "      <td>GMH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GMH</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>0.040551</td>\n",
       "      <td>0.115587</td>\n",
       "      <td>0.165952</td>\n",
       "      <td>1.128155</td>\n",
       "      <td>0.637397</td>\n",
       "      <td>4.058792</td>\n",
       "      <td>50.114334</td>\n",
       "      <td>...</td>\n",
       "      <td>1.600500e+11</td>\n",
       "      <td>16500000.0</td>\n",
       "      <td>9.127335</td>\n",
       "      <td>0.859811</td>\n",
       "      <td>1.234861</td>\n",
       "      <td>59.962717</td>\n",
       "      <td>228.434875</td>\n",
       "      <td>11281.546389</td>\n",
       "      <td>9.337824</td>\n",
       "      <td>GMH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GMH</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088011</td>\n",
       "      <td>0.175449</td>\n",
       "      <td>1.105311</td>\n",
       "      <td>0.682272</td>\n",
       "      <td>4.248544</td>\n",
       "      <td>47.441126</td>\n",
       "      <td>...</td>\n",
       "      <td>1.592250e+11</td>\n",
       "      <td>16500000.0</td>\n",
       "      <td>8.101948</td>\n",
       "      <td>0.873057</td>\n",
       "      <td>1.143669</td>\n",
       "      <td>24.127825</td>\n",
       "      <td>174.405400</td>\n",
       "      <td>11053.111514</td>\n",
       "      <td>9.445047</td>\n",
       "      <td>GMH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GMH</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043288</td>\n",
       "      <td>0.101775</td>\n",
       "      <td>0.169373</td>\n",
       "      <td>1.137871</td>\n",
       "      <td>0.724659</td>\n",
       "      <td>4.420403</td>\n",
       "      <td>40.665490</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666500e+11</td>\n",
       "      <td>16500000.0</td>\n",
       "      <td>6.932984</td>\n",
       "      <td>0.887623</td>\n",
       "      <td>1.121519</td>\n",
       "      <td>12.311260</td>\n",
       "      <td>293.153010</td>\n",
       "      <td>11378.706114</td>\n",
       "      <td>7.042915</td>\n",
       "      <td>GMH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Meta                         Chỉ tiêu cơ cấu nguồn vốn              \\\n",
       "  ticker yearReport lengthReport (ST+LT borrowings)/Equity Debt/Equity   \n",
       "0    GMH       2025            2                  0.000000    0.051588   \n",
       "1    GMH       2025            1                  0.022473    0.051838   \n",
       "2    GMH       2024            4                  0.000000    0.038005   \n",
       "3    GMH       2024            3                  0.038418    0.106987   \n",
       "4    GMH       2024            2                  0.015499    0.063503   \n",
       "5    GMH       2024            1                  0.009567    0.032987   \n",
       "6    GMH       2023            4                  0.000000    0.047413   \n",
       "7    GMH       2023            3                  0.040551    0.115587   \n",
       "8    GMH       2023            2                  0.000000    0.088011   \n",
       "9    GMH       2023            1                  0.043288    0.101775   \n",
       "\n",
       "                                                        \\\n",
       "  Fixed Asset-To-Equity Owners' Equity/Charter Capital   \n",
       "0              0.124650                       1.090538   \n",
       "1              0.130708                       1.089856   \n",
       "2              0.138373                       1.077694   \n",
       "3              0.146877                       1.065434   \n",
       "4              0.156407                       1.048888   \n",
       "5              0.150374                       1.142198   \n",
       "6              0.157043                       1.142922   \n",
       "7              0.165952                       1.128155   \n",
       "8              0.175449                       1.105311   \n",
       "9              0.169373                       1.137871   \n",
       "\n",
       "  Chỉ tiêu hiệu quả hoạt động                                              \\\n",
       "               Asset Turnover Fixed Asset Turnover Days Sales Outstanding   \n",
       "0                    0.562538             4.422492              63.351078   \n",
       "1                    0.495824             3.693597              71.229634   \n",
       "2                    0.461186             3.248087              69.708499   \n",
       "3                    0.456444             3.178684              66.693418   \n",
       "4                    0.438959             2.972644              64.985075   \n",
       "5                    0.473768             3.133843              60.882722   \n",
       "6                    0.572311             3.624814              53.195105   \n",
       "7                    0.637397             4.058792              50.114334   \n",
       "8                    0.682272             4.248544              47.441126   \n",
       "9                    0.724659             4.420403              40.665490   \n",
       "\n",
       "   ...        Chỉ tiêu định giá                                             \\\n",
       "   ... Market Capital (Bn. VND) Outstanding Share (Mil. Shares)        P/E   \n",
       "0  ...             1.452000e+11                      16500000.0  11.480752   \n",
       "1  ...             1.311750e+11                      16500000.0  16.681350   \n",
       "2  ...             1.229250e+11                      16500000.0  20.639945   \n",
       "3  ...             1.313400e+11                      16500000.0  21.487381   \n",
       "4  ...             1.366200e+11                      16500000.0  19.196756   \n",
       "5  ...             1.485000e+11                      16500000.0  16.702805   \n",
       "6  ...             1.658250e+11                      16500000.0  12.102004   \n",
       "7  ...             1.600500e+11                      16500000.0   9.127335   \n",
       "8  ...             1.592250e+11                      16500000.0   8.101948   \n",
       "9  ...             1.666500e+11                      16500000.0   6.932984   \n",
       "\n",
       "                                                                       ticker  \n",
       "        P/B       P/S P/Cash Flow   EPS (VND)    BVPS (VND)  EV/EBITDA         \n",
       "0  0.806941  1.362896    3.795689  356.816813  10905.381178  11.204889    GMH  \n",
       "1  0.729454  1.406508    3.940808  121.619694  10898.564366  20.561323    GMH  \n",
       "2  0.691291  1.395969   10.732768  120.501797  10776.944672  19.378872    GMH  \n",
       "3  0.747113  1.491061    7.664694  167.561987  10654.338632  31.526449    GMH  \n",
       "4  0.789407  1.585955   11.360902   66.896642  10488.880887  18.004344    GMH  \n",
       "5  0.787954  1.568495   14.300980    5.990141  11421.984245  15.236970    GMH  \n",
       "6  0.880344  1.460188 -104.265001  130.001223  11415.994104  12.309960    GMH  \n",
       "7  0.859811  1.234861   59.962717  228.434875  11281.546389   9.337824    GMH  \n",
       "8  0.873057  1.143669   24.127825  174.405400  11053.111514   9.445047    GMH  \n",
       "9  0.887623  1.121519   12.311260  293.153010  11378.706114   7.042915    GMH  \n",
       "\n",
       "[10 rows x 38 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Block 2 — Lấy dữ liệu FA theo quý (VNINDEX) với retry + backoff, skip ticker không hợp lệ và lưu incremental\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from vnstock import Finance\n",
    "\n",
    "# --- Dùng tickers_hose từ Block 1 nếu có, nếu không lấy lại từ client ---\n",
    "try:\n",
    "    tickers_vnindex = tickers_hose\n",
    "except NameError:\n",
    "    tickers_vnindex = list(client.TickerList(ticker=\"VNINDEX\"))\n",
    "\n",
    "print(f\"Số mã VNINDEX tổng: {len(tickers_vnindex)}\")\n",
    "\n",
    "# --- Output files ---\n",
    "master_file = \"vnindex_fa_quarterly_vnstock.csv\"\n",
    "per_ticker_dir = \"vnindex_fa_by_ticker\"\n",
    "invalid_file = \"vnindex_invalid_tickers.txt\"\n",
    "os.makedirs(per_ticker_dir, exist_ok=True)\n",
    "\n",
    "# --- Retry / backoff parameters ---\n",
    "MAX_RETRIES = 6\n",
    "BASE_DELAY = 5\n",
    "BACKOFF_BASE = 2.0\n",
    "JITTER = 1.0\n",
    "RATE_LIMIT_PATTERNS = [\n",
    "    r\"rate limit exceeded\",\n",
    "    r\"you have sent too many requests\",\n",
    "    r\"too many requests\",\n",
    "    r\"rate limit\",\n",
    "    r\"vci.*rate\",\n",
    "]\n",
    "INVALID_TICKER_PATTERNS = [\n",
    "    r\"mã chứng khoán không hợp lệ\",\n",
    "    r\"chỉ cổ phiếu mới có thông tin\",\n",
    "    r\"không phải mã cổ phiếu\",\n",
    "    r\"invalid symbol\",\n",
    "    r\"symbol is invalid\",\n",
    "]\n",
    "\n",
    "def parse_wait_seconds_from_msg(msg):\n",
    "    if not msg:\n",
    "        return None\n",
    "    m = re.search(r\"after\\s+(\\d+)\\s*seconds?\", msg, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "    m2 = re.search(r\"after\\s+(\\d+)\\s*s\\b\", msg, flags=re.IGNORECASE)\n",
    "    if m2:\n",
    "        return int(m2.group(1))\n",
    "    m3 = re.search(r\"(\\d+)\", msg)\n",
    "    if m3:\n",
    "        return int(m3.group(1))\n",
    "    return None\n",
    "\n",
    "# --- Resume: đọc danh sách tickers đã xử lý trong master file nếu có ---\n",
    "processed = set()\n",
    "if os.path.exists(master_file):\n",
    "    try:\n",
    "        df_exist = pd.read_csv(master_file, usecols=['ticker'])\n",
    "        processed.update(df_exist['ticker'].astype(str).unique().tolist())\n",
    "        print(f\"Resume: đã phát hiện {len(processed)} ticker đã xử lý trong '{master_file}'.\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# --- Resume: đọc danh sách ticker invalid đã lưu trước đó ---\n",
    "invalid_set = set()\n",
    "if os.path.exists(invalid_file):\n",
    "    try:\n",
    "        with open(invalid_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                s = line.strip()\n",
    "                if s:\n",
    "                    invalid_set.add(s)\n",
    "        processed.update(invalid_set)  # coi invalid như đã xử lý để skip lần sau\n",
    "        print(f\"Resume: {len(invalid_set)} ticker đã được đánh dấu INVALID và sẽ bị bỏ qua.\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# --- Thu thập dữ liệu ---\n",
    "fa_list = []\n",
    "successful = []\n",
    "skipped_invalid = []\n",
    "failed = []\n",
    "\n",
    "for t in tickers_vnindex:\n",
    "    if t in processed:\n",
    "        print(f\"Skip {t} (đã có trong processed/master/invalid).\")\n",
    "        continue\n",
    "\n",
    "    attempt = 0\n",
    "    success = False\n",
    "    last_exception_msg = None\n",
    "\n",
    "    while attempt < MAX_RETRIES and not success:\n",
    "        attempt += 1\n",
    "        try:\n",
    "            finance = Finance(symbol=t, source='VCI')\n",
    "            df = finance.ratio(period='quarterly')\n",
    "            df = pd.DataFrame(df) if df is not None else pd.DataFrame()\n",
    "\n",
    "            if df.empty:\n",
    "                print(f\"[{t}] ⚠️ Không có dữ liệu FA (vnstock). Bỏ qua (không lưu).\")\n",
    "                # không ghi master nếu trống; đánh dấu là đã thử (không add vào processed để có thể thử lại sau nếu muốn)\n",
    "                success = True\n",
    "                break\n",
    "\n",
    "            # Đảm bảo có cột ticker\n",
    "            if 'ticker' not in df.columns:\n",
    "                df['ticker'] = t\n",
    "            else:\n",
    "                df['ticker'] = df['ticker'].fillna(t)\n",
    "\n",
    "            # Nếu có ReportDate (meta) thì drop đi\n",
    "            if 'ReportDate' in df.columns:\n",
    "                df = df.drop(columns=['ReportDate'])\n",
    "\n",
    "            # Coerce numeric cho các cột (nếu có thể)\n",
    "            for c in df.columns:\n",
    "                if c != 'ticker':\n",
    "                    df[c] = pd.to_numeric(df[c], errors='ignore')\n",
    "\n",
    "            # --- Lưu per-ticker CSV ---\n",
    "            per_file = os.path.join(per_ticker_dir, f\"{t}_fa.csv\")\n",
    "            df.to_csv(per_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "            # --- Append vào master CSV ---\n",
    "            write_header = not os.path.exists(master_file)\n",
    "            df.to_csv(master_file, mode='a', header=write_header, index=False, encoding='utf-8-sig')\n",
    "\n",
    "            print(f\"[{t}] ✓ Lấy xong và lưu (rows={len(df)}).\")\n",
    "            fa_list.append(df)\n",
    "            successful.append(t)\n",
    "            processed.add(t)  # mark processed so resume will skip next time\n",
    "            success = True\n",
    "\n",
    "            # nhẹ nhàng sleep giữa requests\n",
    "            time.sleep(BASE_DELAY + random.uniform(0, JITTER))\n",
    "\n",
    "        except Exception as e:\n",
    "            msg = str(e)\n",
    "            last_exception_msg = msg\n",
    "            lower_msg = msg.lower()\n",
    "\n",
    "            # --- Nếu lỗi do ticker không hợp lệ -> bỏ luôn, không retry ---\n",
    "            is_invalid = any(re.search(pat, lower_msg) for pat in INVALID_TICKER_PATTERNS)\n",
    "            if is_invalid:\n",
    "                print(f\"[{t}] ❌ Mã không hợp lệ — BỎ QUA (không retry). Message: {msg}\")\n",
    "                skipped_invalid.append(t)\n",
    "                processed.add(t)\n",
    "                # lưu vào file invalid để lần sau không thử lại\n",
    "                try:\n",
    "                    with open(invalid_file, \"a\", encoding=\"utf-8\") as f:\n",
    "                        f.write(t + \"\\n\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "                break\n",
    "\n",
    "            # --- Nếu nghi ngờ rate-limit hoặc server báo wait time ---\n",
    "            is_rate_limit = any(pat in lower_msg for pat in RATE_LIMIT_PATTERNS)\n",
    "            parsed_wait = parse_wait_seconds_from_msg(msg)\n",
    "\n",
    "            if is_rate_limit or parsed_wait:\n",
    "                wait_sec = parsed_wait if parsed_wait and parsed_wait > 0 else (BACKOFF_BASE ** attempt)\n",
    "                wait_sec = wait_sec + random.uniform(0, JITTER)\n",
    "                print(f\"[{t}] ⚠️ Rate limit detected (attempt {attempt}/{MAX_RETRIES}). \"\n",
    "                      f\"Đợi {wait_sec:.1f}s rồi thử lại. Message: {msg}\")\n",
    "                time.sleep(wait_sec)\n",
    "                continue\n",
    "            else:\n",
    "                backoff = (BACKOFF_BASE ** attempt) + random.uniform(0, JITTER)\n",
    "                print(f\"[{t}] ⚠️ Lỗi khi fetch (attempt {attempt}/{MAX_RETRIES}): {msg}. \"\n",
    "                      f\"Đợi {backoff:.1f}s rồi thử lại.\")\n",
    "                time.sleep(backoff)\n",
    "                continue\n",
    "\n",
    "    # nếu vòng retry kết thúc mà không success và không thuộc invalid -> mark failed\n",
    "    if not success and t not in skipped_invalid:\n",
    "        print(f\"[{t}] ❌ Không lấy được dữ liệu sau {MAX_RETRIES} lần. Bỏ qua ticker này. Lỗi cuối: {last_exception_msg}\")\n",
    "        failed.append(t)\n",
    "\n",
    "# --- Kết quả tổng kết ---\n",
    "print(\"=== Hoàn tất Block 2 (vnstock) ===\")\n",
    "print(f\"Tổng tickers xử lý thành công: {len(successful)}\")\n",
    "print(f\"Tổng tickers bị đánh dấu INVALID và bỏ qua: {len(skipped_invalid)}\")\n",
    "print(f\"Tổng tickers thất bại (retry hết nhưng không invalid): {len(failed)}\")\n",
    "\n",
    "if fa_list:\n",
    "    sample_df = pd.concat(fa_list, ignore_index=True, sort=False).head(10)\n",
    "    display(sample_df)\n",
    "else:\n",
    "    print(\"❗ Không có dữ liệu FA thu được cho các ticker đã chạy.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d9ef83",
   "metadata": {},
   "source": [
    "**Block 3: Chuẩn hóa FA và gộp dữ liệu với giá**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "831a3096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đọc dữ liệu FA từ 391 ticker, tổng 17586 dòng\n",
      "✅ Đã lưu dữ liệu merged giá + FA vào: vnindex_price_fa_merged.csv\n",
      "Sample merged:\n",
      "  ticker  timestamp      open      high       low     close     volume  \\\n",
      "0    AAA 2023-01-03  6539.643  6866.145  6539.643  6866.145  1543984.0   \n",
      "1    AAA 2023-01-04  6866.145  7000.587  6827.733  6827.733  1302505.0   \n",
      "2    AAA 2023-01-05  6866.145  6904.557  6808.527  6885.351   980473.0   \n",
      "3    AAA 2023-01-06  6885.351  6990.984  6818.130  6856.542  1431699.0   \n",
      "4    AAA 2023-01-09  6914.160  6962.175  6760.512  6789.321  1121385.0   \n",
      "\n",
      "         bu        sd           fs           fn  fa_year  fa_quarter  \\\n",
      "0  938600.0  504700.0   40579000.0  899404000.0     2022           4   \n",
      "1  462900.0  780600.0  151639000.0   36850000.0     2022           4   \n",
      "2  487200.0  473700.0  343911000.0  -59103000.0     2022           4   \n",
      "3  564300.0  828300.0  345999000.0 -294312000.0     2022           4   \n",
      "4  414000.0  631800.0  514557000.0 -483197000.0     2022           4   \n",
      "\n",
      "   Debt/Equity  Net Profit Margin (%)        P/E       P/B  \n",
      "0     0.749394              -0.028688  21.391591  0.637137  \n",
      "1     0.749394              -0.028688  21.391591  0.637137  \n",
      "2     0.749394              -0.028688  21.391591  0.637137  \n",
      "3     0.749394              -0.028688  21.391591  0.637137  \n",
      "4     0.749394              -0.028688  21.391591  0.637137  \n",
      "Số mã merge thành công: 391\n"
     ]
    }
   ],
   "source": [
    "# Block 3 — Chuẩn hoá FA (từ file per-ticker có 2 dòng header) + Merge với giá và lưu CSV\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# --- Các cột FA cần lấy ---\n",
    "fa_fields = [\"Debt/Equity\", \"Net Profit Margin (%)\", \"P/E\", \"P/B\"]\n",
    "need_cols = [\"ticker\",\"yearReport\",\"lengthReport\"] + fa_fields\n",
    "\n",
    "# --- Đọc toàn bộ FA từ thư mục ---\n",
    "folder = \"vnindex_fa_by_ticker\"\n",
    "fa_list = []\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.endswith(\"_fa.csv\"):\n",
    "        path = os.path.join(folder, file)\n",
    "        try:\n",
    "            # ⚡ Bỏ dòng header đầu (Meta...), lấy dòng thứ 2 làm header\n",
    "            df = pd.read_csv(path, header=1)\n",
    "\n",
    "            # Đảm bảo đủ cột cần thiết\n",
    "            for col in need_cols:\n",
    "                if col not in df.columns:\n",
    "                    df[col] = pd.NA\n",
    "\n",
    "            df = df[need_cols]\n",
    "            fa_list.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Lỗi đọc {file}: {e}\")\n",
    "\n",
    "# --- Gộp toàn bộ FA ---\n",
    "fa_data = pd.concat(fa_list, ignore_index=True)\n",
    "print(f\"Đọc dữ liệu FA từ {len(fa_list)} ticker, tổng {len(fa_data)} dòng\")\n",
    "\n",
    "# --- Chuẩn hoá giá (df_all từ Block 1) ---\n",
    "df_price = df_all[df_all[\"ticker\"].isin(fa_data[\"ticker\"].unique())].copy()\n",
    "df_price[\"timestamp\"] = pd.to_datetime(df_price[\"timestamp\"])\n",
    "df_price = df_price.sort_values([\"ticker\",\"timestamp\"])\n",
    "\n",
    "# tạo key (fa_year, fa_quarter) = quý trước để tránh data leak\n",
    "pi = df_price[\"timestamp\"].dt.to_period(\"Q\")\n",
    "prev_pi = pi - 1\n",
    "df_price[\"fa_year\"] = prev_pi.dt.year.astype(int)\n",
    "df_price[\"fa_quarter\"] = prev_pi.dt.quarter.astype(int)\n",
    "\n",
    "# --- Chuẩn hoá FA ---\n",
    "fa_clean = fa_data.rename(columns={\n",
    "    \"yearReport\": \"fa_year\",\n",
    "    \"lengthReport\": \"fa_quarter\"\n",
    "})\n",
    "# ép kiểu int cho chắc\n",
    "fa_clean[\"fa_year\"] = fa_clean[\"fa_year\"].astype(\"Int64\")\n",
    "fa_clean[\"fa_quarter\"] = fa_clean[\"fa_quarter\"].astype(\"Int64\")\n",
    "\n",
    "fa_clean = (\n",
    "    fa_clean.sort_values([\"ticker\",\"fa_year\",\"fa_quarter\"])\n",
    "            .drop_duplicates(subset=[\"ticker\",\"fa_year\",\"fa_quarter\"], keep=\"last\")\n",
    ")\n",
    "\n",
    "# --- Merge giá + FA ---\n",
    "df_merged = df_price.merge(\n",
    "    fa_clean,\n",
    "    on=[\"ticker\",\"fa_year\",\"fa_quarter\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# FFill để lấp chỗ trống\n",
    "df_merged = df_merged.sort_values([\"ticker\",\"timestamp\"])\n",
    "df_merged[fa_fields] = df_merged.groupby(\"ticker\")[fa_fields].ffill()\n",
    "\n",
    "# --- Lưu ra CSV ---\n",
    "output_file = \"vnindex_price_fa_merged.csv\"\n",
    "df_merged.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"✅ Đã lưu dữ liệu merged giá + FA vào: {output_file}\")\n",
    "\n",
    "# --- Preview ---\n",
    "print(\"Sample merged:\")\n",
    "print(df_merged.head())\n",
    "print(\"Số mã merge thành công:\", df_merged['ticker'].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08faae38",
   "metadata": {},
   "source": [
    "**Xóa biến df_all không cần thiết nữa để giảm dung lượng RAM**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331523dd",
   "metadata": {},
   "source": [
    "**Block 4: Tính các chỉ số TA dựa vào thư viện FiinQuant và ghép dữ liệu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d43b3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã lưu dữ liệu có TA (từng mã, KHÔNG regime) vào: vnindex_price_fa_ta.csv\n",
      "Sample with TA:\n",
      "  ticker  timestamp     close  ema_20  ema_50  macd  rsi\n",
      "0    AAA 2023-01-03  6866.145     NaN     NaN   NaN  NaN\n",
      "1    AAA 2023-01-04  6827.733     NaN     NaN   NaN  NaN\n",
      "2    AAA 2023-01-05  6885.351     NaN     NaN   NaN  NaN\n",
      "3    AAA 2023-01-06  6856.542     NaN     NaN   NaN  NaN\n",
      "4    AAA 2023-01-09  6789.321     NaN     NaN   NaN  NaN\n",
      "Shape sau khi thêm TA: (264721, 29)\n"
     ]
    }
   ],
   "source": [
    "# Block 4 — Tính các chỉ số TA cho từng mã (KHÔNG có regime)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Load dữ liệu merge từ Block 3 ---\n",
    "df_merged = pd.read_csv(\"vnindex_price_fa_merged.csv\", parse_dates=[\"timestamp\"])\n",
    "\n",
    "# --- Khởi tạo Indicator ---\n",
    "fi = client.FiinIndicator()\n",
    "\n",
    "# --- Hàm tính TA cho từng ticker ---\n",
    "def add_ta_indicators(df):\n",
    "    df = df.sort_values(\"timestamp\").copy().reset_index(drop=True)\n",
    "\n",
    "    # EMA\n",
    "    df['ema_5']  = fi.ema(df['close'], window=5)\n",
    "    df['ema_20'] = fi.ema(df['close'], window=20)\n",
    "    df['ema_50'] = fi.ema(df['close'], window=50)\n",
    "\n",
    "    # MACD\n",
    "    df['macd']        = fi.macd(df['close'], window_fast=12, window_slow=26)\n",
    "    df['macd_signal'] = fi.macd_signal(df['close'], window_fast=12, window_slow=26, window_sign=9)\n",
    "    df['macd_diff']   = fi.macd_diff(df['close'], window_fast=12, window_slow=26, window_sign=9)\n",
    "\n",
    "    # RSI\n",
    "    df['rsi'] = fi.rsi(df['close'], window=14)\n",
    "\n",
    "    # Bollinger Bands\n",
    "    df['bollinger_hband'] = fi.bollinger_hband(df['close'], window=20, window_dev=2)\n",
    "    df['bollinger_lband'] = fi.bollinger_lband(df['close'], window=20, window_dev=2)\n",
    "\n",
    "    # ATR\n",
    "    df['atr'] = fi.atr(df['high'], df['low'], df['close'], window=14)\n",
    "\n",
    "    # OBV\n",
    "    df['obv'] = fi.obv(df['close'], df['volume'])\n",
    "\n",
    "    # VWAP\n",
    "    df['vwap'] = fi.vwap(df['high'], df['low'], df['close'], df['volume'], window=14)\n",
    "\n",
    "    return df\n",
    "\n",
    "# --- Áp dụng TA cho toàn bộ df_merged ---\n",
    "df_with_ta = df_merged.groupby(\"ticker\", group_keys=False).apply(add_ta_indicators)\n",
    "\n",
    "# --- Lưu ra CSV (không còn regime nữa) ---\n",
    "output_file = \"vnindex_price_fa_ta.csv\"\n",
    "df_with_ta.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"✅ Đã lưu dữ liệu có TA (từng mã, KHÔNG regime) vào: {output_file}\")\n",
    "\n",
    "# --- Preview ---\n",
    "print(\"Sample with TA:\")\n",
    "print(df_with_ta[['ticker','timestamp','close','ema_20','ema_50','macd','rsi']].head())\n",
    "print(\"Shape sau khi thêm TA:\", df_with_ta.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f235303e",
   "metadata": {},
   "source": [
    "**Xóa bớt biến df_merged không còn cần thiết để giảm dung lượng RAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26204a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1802"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del df_merged\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5614073e",
   "metadata": {},
   "source": [
    "**Block 5: Chuẩn hóa dữ liệu FA và TA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59579dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample features:\n",
      "  ticker  timestamp  Debt/Equity  Net Profit Margin (%)       P/E       P/B  \\\n",
      "0    AAA 2023-06-14     0.302753               0.976223  0.581524  0.119378   \n",
      "1    AAM 2023-06-14     0.274571               0.976478  0.567593  0.081723   \n",
      "2    AAT 2023-06-14     0.289872               0.976190  0.566385  0.088712   \n",
      "3    ABR 2023-06-14     0.281477               0.979266  0.568159  0.136659   \n",
      "4    ABS 2023-06-14     0.302868               0.977524  0.572447  0.092493   \n",
      "\n",
      "    ema_5_z  ema_20_z  ema_50_z    macd_z  macd_signal_z  macd_diff_z  \\\n",
      "0  1.335124  1.662545  1.799046 -0.008320       0.591579    -1.164222   \n",
      "1 -0.860284 -0.664630 -0.242035 -0.764137      -0.817184    -0.109792   \n",
      "2  3.147082  3.376253  3.548276  2.967265       3.142393     2.231773   \n",
      "3  0.348835  1.002783  1.511919 -0.803966      -0.276326    -1.417017   \n",
      "4  2.772696  3.133127  3.354561  2.500178       2.788283     1.191728   \n",
      "\n",
      "      rsi_z  bollinger_hband_z  bollinger_lband_z     atr_z     obv_z  \\\n",
      "0 -1.530688           1.363061           1.839777  0.589827  1.405288   \n",
      "1 -0.549930          -1.111354           0.214963 -1.672962 -1.156616   \n",
      "2  1.285717           3.255245          -2.341308  3.090152  2.465147   \n",
      "3 -1.363102           0.856571           1.201947  0.576320 -0.556661   \n",
      "4  0.818367           2.953700           1.355816  2.352162  2.390705   \n",
      "\n",
      "     vwap_z  \n",
      "0  1.603355  \n",
      "1 -0.550497  \n",
      "2  3.222970  \n",
      "3  0.554186  \n",
      "4  2.919060  \n",
      "Shape sau khi scaling & dropna: (221135, 18)\n"
     ]
    }
   ],
   "source": [
    "# Block 5 — Feature engineering & scaling (NO regime, short version)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# --- Danh sách cột FA & TA ---\n",
    "fa_features = [\"Debt/Equity\", \"Net Profit Margin (%)\", \"P/E\", \"P/B\"]\n",
    "\n",
    "ta_features = [\n",
    "    \"ema_5\",\"ema_20\",\"ema_50\",\"macd\",\"macd_signal\",\"macd_diff\",\n",
    "    \"rsi\",\"bollinger_hband\",\"bollinger_lband\",\"atr\",\"obv\",\"vwap\"\n",
    "]\n",
    "\n",
    "# --- Chuẩn hoá FA: cross-section min-max scaling theo ngày ---\n",
    "def scale_fa_minmax(df):\n",
    "    df_scaled = df.copy()\n",
    "    for f in fa_features:\n",
    "        vals = pd.to_numeric(df[f], errors=\"coerce\")\n",
    "        vmin, vmax = vals.min(), vals.max()\n",
    "        if np.isfinite(vmin) and np.isfinite(vmax) and vmax > vmin:\n",
    "            df_scaled[f] = (vals - vmin) / (vmax - vmin)\n",
    "        else:\n",
    "            df_scaled[f] = np.nan\n",
    "    return df_scaled\n",
    "\n",
    "df_scaled_fa = df_with_ta.groupby(\"timestamp\", group_keys=False).apply(scale_fa_minmax)\n",
    "\n",
    "# --- Chuẩn hoá TA: rolling z-score theo từng ticker ---\n",
    "def zscore_rolling(series, window=60):\n",
    "    return (series - series.rolling(window).mean()) / series.rolling(window).std()\n",
    "\n",
    "df_scaled = df_scaled_fa.groupby(\"ticker\", group_keys=False).apply(\n",
    "    lambda g: g.assign(**{f\"{col}_z\": zscore_rolling(g[col], 60) for col in ta_features})\n",
    ")\n",
    "\n",
    "# --- Drop các cột gốc TA, giữ bản z-score ---\n",
    "keep_cols = [\"ticker\",\"timestamp\"] + fa_features + [f\"{col}_z\" for col in ta_features]\n",
    "df_features = df_scaled[keep_cols].dropna().reset_index(drop=True)\n",
    "\n",
    "print(\"Sample features:\")\n",
    "print(df_features.head())\n",
    "print(\"Shape sau khi scaling & dropna:\", df_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44f5d94",
   "metadata": {},
   "source": [
    "**Xóa các biến df_with_ta, df_scaled, df_scaled_fa không cần thiết nữa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fee3d19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_with_ta, df_scaled, df_scaled_fa\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3245a6ca",
   "metadata": {},
   "source": [
    "**Block 6: Giảm chiều dữ liệu bằng t-SNE và phân cụm bằng DBSCAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "466d47e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 255, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster sample:\n",
      "  ticker  timestamp  cluster     tsne_x     tsne_y    month\n",
      "0    AAA 2023-06-14       -1  17.444849 -43.739433  2023-06\n",
      "1    AAA 2023-06-15       -1  17.398275 -43.821537  2023-06\n",
      "2    AAA 2023-06-16       -1   5.181763 -58.317707  2023-06\n",
      "3    AAA 2023-06-19       -1   4.829109 -57.954765  2023-06\n",
      "4    AAA 2023-06-20       -1   4.363069 -57.532513  2023-06\n",
      "Số cụm mỗi tháng:\n",
      "month\n",
      "2023-06     28\n",
      "2023-07    127\n",
      "2023-08    118\n",
      "2023-09     61\n",
      "2023-10    115\n",
      "2023-11     74\n",
      "2023-12    110\n",
      "2024-01    126\n",
      "2024-02     47\n",
      "2024-03     96\n",
      "2024-04     68\n",
      "2024-05     75\n",
      "2024-06    109\n",
      "2024-07    110\n",
      "2024-08    100\n",
      "2024-09     97\n",
      "2024-10    151\n",
      "2024-11    108\n",
      "2024-12    107\n",
      "2025-01     62\n",
      "2025-02     97\n",
      "2025-03    113\n",
      "2025-04     62\n",
      "2025-05     99\n",
      "2025-06    135\n",
      "2025-07    141\n",
      "2025-08    110\n",
      "2025-09     77\n",
      "2025-10      1\n",
      "Name: cluster, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Block 6 — Giảm chiều dữ liệu & phân cụm (t-SNE + DBSCAN)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# --- Chọn các cột features để phân cụm ---\n",
    "# FA features: khớp với Block 3 & Block 5\n",
    "fa_features = [\"Debt/Equity\", \"Net Profit Margin (%)\", \"P/E\", \"P/B\"]\n",
    "\n",
    "# TA features đã được chuẩn hoá z-score ở Block 5\n",
    "ta_features_z = [c for c in df_features.columns if c.endswith(\"_z\")]\n",
    "\n",
    "feature_cols = fa_features + ta_features_z\n",
    "\n",
    "# --- Thêm cột tháng để snapshot ---\n",
    "df_features[\"month\"] = df_features[\"timestamp\"].dt.to_period(\"M\")\n",
    "\n",
    "cluster_results = []\n",
    "\n",
    "for (month, g) in df_features.groupby(\"month\"):\n",
    "    if len(g) < 10:   # quá ít cổ phiếu thì bỏ\n",
    "        continue\n",
    "\n",
    "    X = g[feature_cols].values\n",
    "\n",
    "    # --- t-SNE giảm chiều còn 2D ---\n",
    "    tsne = TSNE(n_components=2, perplexity=30, learning_rate=\"auto\", init=\"random\", random_state=42)\n",
    "    X_emb = tsne.fit_transform(X)\n",
    "\n",
    "    # --- DBSCAN phân cụm ---\n",
    "    db = DBSCAN(eps=0.5, min_samples=5).fit(X_emb)\n",
    "    labels = db.labels_\n",
    "\n",
    "    temp = g[[\"ticker\",\"timestamp\"]].copy()\n",
    "    temp[\"cluster\"] = labels\n",
    "    temp[\"tsne_x\"] = X_emb[:,0]\n",
    "    temp[\"tsne_y\"] = X_emb[:,1]\n",
    "    temp[\"month\"]  = str(month)\n",
    "\n",
    "    cluster_results.append(temp)\n",
    "\n",
    "df_clusters = pd.concat(cluster_results, ignore_index=True)\n",
    "\n",
    "print(\"Cluster sample:\")\n",
    "print(df_clusters.head())\n",
    "print(\"Số cụm mỗi tháng:\")\n",
    "print(df_clusters.groupby(\"month\")[\"cluster\"].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdde0916",
   "metadata": {},
   "source": [
    "**Block 7: Xây tensors (clusters mapping) và masks (active stocks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d88b8d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Tensor data directory: C:/tensors_out\n",
      "✅ Cluster 0: tensor (512, 64, 15, 16), mask (512, 64, 15, 16) saved.\n",
      "✅ Cluster 1: tensor (512, 64, 14, 16), mask (512, 64, 14, 16) saved.\n",
      "✅ Cluster 2: tensor (512, 64, 20, 16), mask (512, 64, 20, 16) saved.\n",
      "✅ Cluster 3: tensor (512, 64, 21, 16), mask (512, 64, 21, 16) saved.\n",
      "✅ Cluster 4: tensor (512, 64, 28, 16), mask (512, 64, 28, 16) saved.\n",
      "✅ Cluster 5: tensor (512, 64, 25, 16), mask (512, 64, 25, 16) saved.\n",
      "✅ Cluster 6: tensor (512, 64, 25, 16), mask (512, 64, 25, 16) saved.\n",
      "✅ Cluster 7: tensor (512, 64, 22, 16), mask (512, 64, 22, 16) saved.\n",
      "✅ Cluster 8: tensor (512, 64, 22, 16), mask (512, 64, 22, 16) saved.\n",
      "✅ Cluster 9: tensor (512, 64, 25, 16), mask (512, 64, 25, 16) saved.\n",
      "✅ Cluster 10: tensor (512, 64, 30, 16), mask (512, 64, 30, 16) saved.\n",
      "✅ Cluster 11: tensor (512, 64, 26, 16), mask (512, 64, 26, 16) saved.\n",
      "✅ Cluster 12: tensor (512, 64, 27, 16), mask (512, 64, 27, 16) saved.\n",
      "✅ Cluster 13: tensor (512, 64, 25, 16), mask (512, 64, 25, 16) saved.\n",
      "✅ Cluster 14: tensor (512, 64, 27, 16), mask (512, 64, 27, 16) saved.\n",
      "✅ Cluster 15: tensor (512, 64, 32, 16), mask (512, 64, 32, 16) saved.\n",
      "✅ Cluster 16: tensor (512, 64, 29, 16), mask (512, 64, 29, 16) saved.\n",
      "✅ Cluster 17: tensor (512, 64, 31, 16), mask (512, 64, 31, 16) saved.\n",
      "✅ Cluster 18: tensor (512, 64, 29, 16), mask (512, 64, 29, 16) saved.\n",
      "✅ Cluster 19: tensor (512, 64, 31, 16), mask (512, 64, 31, 16) saved.\n",
      "✅ Cluster 20: tensor (512, 64, 26, 16), mask (512, 64, 26, 16) saved.\n",
      "✅ Cluster 21: tensor (512, 64, 33, 16), mask (512, 64, 33, 16) saved.\n",
      "✅ Cluster 22: tensor (512, 64, 28, 16), mask (512, 64, 28, 16) saved.\n",
      "✅ Cluster 23: tensor (512, 64, 30, 16), mask (512, 64, 30, 16) saved.\n",
      "✅ Cluster 24: tensor (512, 64, 30, 16), mask (512, 64, 30, 16) saved.\n",
      "✅ Cluster 25: tensor (512, 64, 33, 16), mask (512, 64, 33, 16) saved.\n",
      "✅ Cluster 26: tensor (512, 64, 29, 16), mask (512, 64, 29, 16) saved.\n",
      "✅ Cluster 27: tensor (512, 64, 25, 16), mask (512, 64, 25, 16) saved.\n",
      "✅ Cluster 28: tensor (512, 64, 26, 16), mask (512, 64, 26, 16) saved.\n",
      "✅ Cluster 29: tensor (512, 64, 32, 16), mask (512, 64, 32, 16) saved.\n",
      "✅ Cluster 30: tensor (512, 64, 28, 16), mask (512, 64, 28, 16) saved.\n",
      "✅ Cluster 31: tensor (512, 64, 27, 16), mask (512, 64, 27, 16) saved.\n",
      "✅ Cluster 32: tensor (512, 64, 25, 16), mask (512, 64, 25, 16) saved.\n",
      "✅ Cluster 33: tensor (512, 64, 28, 16), mask (512, 64, 28, 16) saved.\n",
      "✅ Cluster 34: tensor (512, 64, 29, 16), mask (512, 64, 29, 16) saved.\n",
      "✅ Cluster 35: tensor (512, 64, 30, 16), mask (512, 64, 30, 16) saved.\n",
      "✅ Cluster 36: tensor (512, 64, 30, 16), mask (512, 64, 30, 16) saved.\n",
      "✅ Cluster 37: tensor (512, 64, 32, 16), mask (512, 64, 32, 16) saved.\n",
      "✅ Cluster 38: tensor (512, 64, 30, 16), mask (512, 64, 30, 16) saved.\n",
      "✅ Cluster 39: tensor (512, 64, 27, 16), mask (512, 64, 27, 16) saved.\n",
      "✅ Cluster 40: tensor (512, 64, 32, 16), mask (512, 64, 32, 16) saved.\n",
      "✅ Cluster 41: tensor (512, 64, 26, 16), mask (512, 64, 26, 16) saved.\n",
      "✅ Cluster 42: tensor (512, 64, 26, 16), mask (512, 64, 26, 16) saved.\n",
      "✅ Cluster 43: tensor (512, 64, 32, 16), mask (512, 64, 32, 16) saved.\n",
      "✅ Cluster 44: tensor (512, 64, 28, 16), mask (512, 64, 28, 16) saved.\n",
      "✅ Cluster 45: tensor (512, 64, 27, 16), mask (512, 64, 27, 16) saved.\n",
      "✅ Cluster 46: tensor (512, 64, 28, 16), mask (512, 64, 28, 16) saved.\n",
      "✅ Cluster 47: tensor (512, 64, 29, 16), mask (512, 64, 29, 16) saved.\n",
      "✅ Cluster 48: tensor (512, 64, 28, 16), mask (512, 64, 28, 16) saved.\n",
      "✅ Cluster 49: tensor (512, 64, 31, 16), mask (512, 64, 31, 16) saved.\n",
      "✅ Cluster 50: tensor (512, 64, 29, 16), mask (512, 64, 29, 16) saved.\n",
      "✅ Cluster 51: tensor (512, 64, 25, 16), mask (512, 64, 25, 16) saved.\n",
      "✅ Cluster 52: tensor (512, 64, 31, 16), mask (512, 64, 31, 16) saved.\n",
      "✅ Cluster 53: tensor (512, 64, 30, 16), mask (512, 64, 30, 16) saved.\n",
      "✅ Cluster 54: tensor (512, 64, 28, 16), mask (512, 64, 28, 16) saved.\n",
      "✅ Cluster 55: tensor (512, 64, 27, 16), mask (512, 64, 27, 16) saved.\n",
      "✅ Cluster 56: tensor (512, 64, 24, 16), mask (512, 64, 24, 16) saved.\n",
      "✅ Cluster 57: tensor (512, 64, 32, 16), mask (512, 64, 32, 16) saved.\n",
      "✅ Cluster 58: tensor (512, 64, 28, 16), mask (512, 64, 28, 16) saved.\n",
      "✅ Cluster 59: tensor (512, 64, 27, 16), mask (512, 64, 27, 16) saved.\n",
      "✅ Cluster 60: tensor (512, 64, 27, 16), mask (512, 64, 27, 16) saved.\n",
      "✅ Cluster 61: tensor (512, 64, 24, 16), mask (512, 64, 24, 16) saved.\n",
      "✅ Cluster 62: tensor (512, 64, 25, 16), mask (512, 64, 25, 16) saved.\n",
      "✅ Cluster 63: tensor (512, 64, 23, 16), mask (512, 64, 23, 16) saved.\n",
      "✅ Cluster 64: tensor (512, 64, 23, 16), mask (512, 64, 23, 16) saved.\n",
      "✅ Cluster 65: tensor (512, 64, 27, 16), mask (512, 64, 27, 16) saved.\n",
      "✅ Cluster 66: tensor (512, 64, 27, 16), mask (512, 64, 27, 16) saved.\n",
      "✅ Cluster 67: tensor (512, 64, 25, 16), mask (512, 64, 25, 16) saved.\n",
      "✅ Cluster 68: tensor (512, 64, 26, 16), mask (512, 64, 26, 16) saved.\n",
      "✅ Cluster 69: tensor (512, 64, 25, 16), mask (512, 64, 25, 16) saved.\n",
      "✅ Cluster 70: tensor (512, 64, 23, 16), mask (512, 64, 23, 16) saved.\n",
      "✅ Cluster 71: tensor (512, 64, 24, 16), mask (512, 64, 24, 16) saved.\n",
      "✅ Cluster 72: tensor (512, 64, 25, 16), mask (512, 64, 25, 16) saved.\n",
      "✅ Cluster 73: tensor (512, 64, 20, 16), mask (512, 64, 20, 16) saved.\n",
      "✅ Cluster 74: tensor (512, 64, 22, 16), mask (512, 64, 22, 16) saved.\n",
      "✅ Cluster 75: tensor (512, 64, 23, 16), mask (512, 64, 23, 16) saved.\n",
      "✅ Cluster 76: tensor (512, 64, 19, 16), mask (512, 64, 19, 16) saved.\n",
      "✅ Cluster 77: tensor (512, 64, 19, 16), mask (512, 64, 19, 16) saved.\n",
      "✅ Cluster 78: tensor (512, 64, 21, 16), mask (512, 64, 21, 16) saved.\n",
      "✅ Cluster 79: tensor (512, 64, 21, 16), mask (512, 64, 21, 16) saved.\n",
      "✅ Cluster 80: tensor (512, 64, 26, 16), mask (512, 64, 26, 16) saved.\n",
      "✅ Cluster 81: tensor (512, 64, 19, 16), mask (512, 64, 19, 16) saved.\n",
      "✅ Cluster 82: tensor (512, 64, 20, 16), mask (512, 64, 20, 16) saved.\n",
      "✅ Cluster 83: tensor (512, 64, 25, 16), mask (512, 64, 25, 16) saved.\n",
      "✅ Cluster 84: tensor (512, 64, 23, 16), mask (512, 64, 23, 16) saved.\n",
      "✅ Cluster 85: tensor (512, 64, 19, 16), mask (512, 64, 19, 16) saved.\n",
      "✅ Cluster 86: tensor (512, 64, 21, 16), mask (512, 64, 21, 16) saved.\n",
      "✅ Cluster 87: tensor (512, 64, 18, 16), mask (512, 64, 18, 16) saved.\n",
      "✅ Cluster 88: tensor (512, 64, 19, 16), mask (512, 64, 19, 16) saved.\n",
      "✅ Cluster 89: tensor (512, 64, 19, 16), mask (512, 64, 19, 16) saved.\n",
      "✅ Cluster 90: tensor (512, 64, 22, 16), mask (512, 64, 22, 16) saved.\n",
      "✅ Cluster 91: tensor (512, 64, 18, 16), mask (512, 64, 18, 16) saved.\n",
      "✅ Cluster 92: tensor (512, 64, 16, 16), mask (512, 64, 16, 16) saved.\n",
      "✅ Cluster 93: tensor (512, 64, 18, 16), mask (512, 64, 18, 16) saved.\n",
      "✅ Cluster 94: tensor (512, 64, 24, 16), mask (512, 64, 24, 16) saved.\n",
      "✅ Cluster 95: tensor (512, 64, 22, 16), mask (512, 64, 22, 16) saved.\n",
      "✅ Cluster 96: tensor (512, 64, 16, 16), mask (512, 64, 16, 16) saved.\n",
      "✅ Cluster 97: tensor (512, 64, 18, 16), mask (512, 64, 18, 16) saved.\n",
      "✅ Cluster 98: tensor (512, 64, 16, 16), mask (512, 64, 16, 16) saved.\n",
      "✅ Cluster 99: tensor (512, 64, 15, 16), mask (512, 64, 15, 16) saved.\n",
      "✅ Cluster 100: tensor (512, 64, 13, 16), mask (512, 64, 13, 16) saved.\n",
      "✅ Cluster 101: tensor (512, 64, 14, 16), mask (512, 64, 14, 16) saved.\n",
      "✅ Cluster 102: tensor (512, 64, 12, 16), mask (512, 64, 12, 16) saved.\n",
      "✅ Cluster 103: tensor (512, 64, 22, 16), mask (512, 64, 22, 16) saved.\n",
      "✅ Cluster 104: tensor (512, 64, 13, 16), mask (512, 64, 13, 16) saved.\n",
      "✅ Cluster 105: tensor (512, 64, 13, 16), mask (512, 64, 13, 16) saved.\n",
      "✅ Cluster 106: tensor (512, 64, 14, 16), mask (512, 64, 14, 16) saved.\n",
      "✅ Cluster 107: tensor (512, 64, 12, 16), mask (512, 64, 12, 16) saved.\n",
      "✅ Cluster 108: tensor (512, 64, 13, 16), mask (512, 64, 13, 16) saved.\n",
      "✅ Cluster 109: tensor (512, 64, 9, 16), mask (512, 64, 9, 16) saved.\n",
      "✅ Cluster 110: tensor (512, 64, 9, 16), mask (512, 64, 9, 16) saved.\n",
      "✅ Cluster 111: tensor (512, 64, 11, 16), mask (512, 64, 11, 16) saved.\n",
      "✅ Cluster 112: tensor (512, 64, 6, 16), mask (512, 64, 6, 16) saved.\n",
      "✅ Cluster 113: tensor (512, 64, 6, 16), mask (512, 64, 6, 16) saved.\n",
      "✅ Cluster 114: tensor (512, 64, 6, 16), mask (512, 64, 6, 16) saved.\n",
      "✅ Cluster 115: tensor (512, 64, 6, 16), mask (512, 64, 6, 16) saved.\n",
      "✅ Cluster 116: tensor (512, 64, 8, 16), mask (512, 64, 8, 16) saved.\n",
      "✅ Cluster 117: tensor (512, 64, 5, 16), mask (512, 64, 5, 16) saved.\n",
      "✅ Cluster 118: tensor (512, 64, 5, 16), mask (512, 64, 5, 16) saved.\n",
      "✅ Cluster 119: tensor (512, 64, 5, 16), mask (512, 64, 5, 16) saved.\n",
      "✅ Cluster 120: tensor (512, 64, 5, 16), mask (512, 64, 5, 16) saved.\n",
      "✅ Cluster 121: tensor (512, 64, 8, 16), mask (512, 64, 8, 16) saved.\n",
      "✅ Cluster 122: tensor (512, 64, 6, 16), mask (512, 64, 6, 16) saved.\n",
      "✅ Cluster 123: tensor (512, 64, 4, 16), mask (512, 64, 4, 16) saved.\n",
      "✅ Cluster 124: tensor (512, 64, 5, 16), mask (512, 64, 5, 16) saved.\n",
      "✅ Cluster 125: tensor (512, 64, 4, 16), mask (512, 64, 4, 16) saved.\n",
      "✅ Cluster 126: tensor (512, 64, 3, 16), mask (512, 64, 3, 16) saved.\n",
      "✅ Cluster 127: tensor (512, 64, 3, 16), mask (512, 64, 3, 16) saved.\n",
      "✅ Cluster 128: tensor (512, 64, 4, 16), mask (512, 64, 4, 16) saved.\n",
      "✅ Cluster 129: tensor (512, 64, 3, 16), mask (512, 64, 3, 16) saved.\n",
      "✅ Cluster 130: tensor (512, 64, 3, 16), mask (512, 64, 3, 16) saved.\n",
      "✅ Cluster 131: tensor (512, 64, 5, 16), mask (512, 64, 5, 16) saved.\n",
      "✅ Cluster 132: tensor (512, 64, 3, 16), mask (512, 64, 3, 16) saved.\n",
      "✅ Cluster 133: tensor (512, 64, 3, 16), mask (512, 64, 3, 16) saved.\n",
      "✅ Cluster 134: tensor (512, 64, 2, 16), mask (512, 64, 2, 16) saved.\n",
      "✅ Cluster 135: tensor (512, 64, 2, 16), mask (512, 64, 2, 16) saved.\n",
      "✅ Cluster 136: tensor (512, 64, 2, 16), mask (512, 64, 2, 16) saved.\n",
      "✅ Cluster 137: tensor (512, 64, 3, 16), mask (512, 64, 3, 16) saved.\n",
      "✅ Cluster 138: tensor (512, 64, 2, 16), mask (512, 64, 2, 16) saved.\n",
      "✅ Cluster 139: tensor (512, 64, 2, 16), mask (512, 64, 2, 16) saved.\n",
      "✅ Cluster 140: tensor (512, 64, 1, 16), mask (512, 64, 1, 16) saved.\n",
      "✅ Cluster 141: tensor (512, 64, 1, 16), mask (512, 64, 1, 16) saved.\n",
      "✅ Cluster 142: tensor (512, 64, 1, 16), mask (512, 64, 1, 16) saved.\n",
      "✅ Cluster 143: tensor (512, 64, 1, 16), mask (512, 64, 1, 16) saved.\n",
      "✅ Cluster 144: tensor (512, 64, 1, 16), mask (512, 64, 1, 16) saved.\n",
      "✅ Cluster 145: tensor (512, 64, 1, 16), mask (512, 64, 1, 16) saved.\n",
      "✅ Cluster 146: tensor (511, 64, 1, 16), mask (511, 64, 1, 16) saved.\n",
      "✅ Cluster 147: tensor (511, 64, 1, 16), mask (511, 64, 1, 16) saved.\n",
      "✅ Cluster 148: tensor (512, 64, 1, 16), mask (512, 64, 1, 16) saved.\n",
      "✅ Cluster 149: tensor (512, 64, 1, 16), mask (512, 64, 1, 16) saved.\n",
      "🎯 Done Block 7.2: tensors + masks saved for all clusters.\n"
     ]
    }
   ],
   "source": [
    "# Block 7.2 — Tensors & Masks (fix: lưu ra folder khác)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, gc, json\n",
    "\n",
    "LOOKBACK = 64   # window size\n",
    "DATA_DIR = \"C:/tensors_out\"   # đổi sang C ổ cho đơn giản\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "print(\"📂 Tensor data directory:\", DATA_DIR)\n",
    "\n",
    "feature_cols = [c for c in df_features.columns if c not in [\"ticker\",\"timestamp\",\"cluster\",\"month\"]]\n",
    "\n",
    "tensor_index = []\n",
    "\n",
    "for c_id, g in df_clusters.groupby(\"cluster\"):\n",
    "    if c_id == -1:   # noise bỏ qua\n",
    "        continue\n",
    "\n",
    "    tickers = sorted(g[\"ticker\"].unique())\n",
    "    g_feat = df_features[df_features[\"ticker\"].isin(tickers)].copy()\n",
    "\n",
    "    # Pivot: index = timestamp, columns = (ticker, feature)\n",
    "    pivoted = g_feat.pivot(index=\"timestamp\", columns=\"ticker\", values=feature_cols)\n",
    "    pivoted.columns = pd.MultiIndex.from_product([tickers, feature_cols])\n",
    "\n",
    "    # Mask\n",
    "    mask_df = ~pivoted.isna()\n",
    "    pivoted_filled = pivoted.ffill().bfill()\n",
    "\n",
    "    T, N, F = len(pivoted_filled.index), len(tickers), len(feature_cols)\n",
    "    X = pivoted_filled.values.reshape(T, N, F)\n",
    "    M = mask_df.values.reshape(T, N, F).astype(np.int8)\n",
    "\n",
    "    cluster_tensors, cluster_masks, cluster_dates = [], [], []\n",
    "    for i in range(LOOKBACK, T):\n",
    "        cluster_tensors.append(X[i-LOOKBACK:i])\n",
    "        cluster_masks.append(M[i-LOOKBACK:i])\n",
    "        cluster_dates.append(pivoted_filled.index[i])  # ngày cuối của window\n",
    "\n",
    "    if cluster_tensors:\n",
    "        X_arr = np.array(cluster_tensors, dtype=np.float16)  # tiết kiệm RAM\n",
    "        M_arr = np.array(cluster_masks, dtype=np.int8)\n",
    "\n",
    "        tensor_file = f\"cluster_{c_id}_tensor.npy\"\n",
    "        mask_file   = f\"cluster_{c_id}_mask.npy\"\n",
    "\n",
    "        np.save(os.path.join(DATA_DIR, tensor_file), X_arr)\n",
    "        np.save(os.path.join(DATA_DIR, mask_file), M_arr)\n",
    "\n",
    "        tensor_index.append({\n",
    "            \"cluster\": int(c_id),\n",
    "            \"tickers\": tickers,\n",
    "            \"dates\": [str(d) for d in cluster_dates],\n",
    "            \"dates_shifted\": [str(d+pd.Timedelta(days=1)) for d in cluster_dates],\n",
    "            \"tensor_file\": tensor_file,\n",
    "            \"mask_file\": mask_file\n",
    "        })\n",
    "\n",
    "        print(f\"✅ Cluster {c_id}: tensor {X_arr.shape}, mask {M_arr.shape} saved.\")\n",
    "\n",
    "    del g_feat, pivoted, pivoted_filled, mask_df, X, M, cluster_tensors, cluster_masks\n",
    "    gc.collect()\n",
    "\n",
    "# Save metadata\n",
    "with open(os.path.join(DATA_DIR, \"tensor_index.json\"), \"w\") as f:\n",
    "    json.dump(tensor_index, f, indent=2)\n",
    "\n",
    "print(\"🎯 Done Block 7.2: tensors + masks saved for all clusters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95417aff",
   "metadata": {},
   "source": [
    "**Block 7.5: Chuẩn bị dữ liệu backtest(loại bỏ các cột dữ liệu không cần thiết nữa)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9bfded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done Block 7.5: df_backtest sẵn sàng cho reward.\n",
      "Kích thước df_backtest: (264721, 3)\n",
      "Số tickers unique: 391\n",
      "Khoảng thời gian: 2023-01-03 00:00:00 → 2025-10-02 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Block 7.5 — Chuẩn bị dữ liệu backtest cho reward thật\n",
    "import gc\n",
    "import pandas as pd\n",
    "\n",
    "# Lấy close price để tính reward\n",
    "df_backtest = df_price[[\"ticker\", \"timestamp\", \"close\"]].copy()\n",
    "df_backtest[\"timestamp\"] = pd.to_datetime(df_backtest[\"timestamp\"])\n",
    "df_backtest = df_backtest.sort_values([\"timestamp\",\"ticker\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"✅ Done Block 7.5: df_backtest sẵn sàng cho reward.\")\n",
    "print(\"Kích thước df_backtest:\", df_backtest.shape)\n",
    "print(\"Số tickers unique:\", df_backtest[\"ticker\"].nunique())\n",
    "print(\"Khoảng thời gian:\", df_backtest[\"timestamp\"].min(), \"→\", df_backtest[\"timestamp\"].max())\n",
    "\n",
    "# Giải phóng RAM\n",
    "del df_price\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c7aa4e",
   "metadata": {},
   "source": [
    "**Block 8: Huấn luyện A3C theo từng cụm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e993a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 | X=(512, 64, 15, 19)\n",
      "  Epoch 1/3, Loss=0.5582\n",
      "  Epoch 2/3, Loss=-0.0633\n",
      "  Epoch 3/3, Loss=-0.3345\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_0.pt\n",
      "Cluster 1 | X=(512, 64, 14, 19)\n",
      "  Epoch 1/3, Loss=-0.3479\n",
      "  Epoch 2/3, Loss=-0.1559\n",
      "  Epoch 3/3, Loss=-0.3015\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_1.pt\n",
      "Cluster 2 | X=(512, 64, 20, 19)\n",
      "  Epoch 1/3, Loss=-0.5230\n",
      "  Epoch 2/3, Loss=-0.3853\n",
      "  Epoch 3/3, Loss=-0.4694\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_2.pt\n",
      "Cluster 3 | X=(512, 64, 21, 19)\n",
      "  Epoch 1/3, Loss=-0.4557\n",
      "  Epoch 2/3, Loss=-0.4514\n",
      "  Epoch 3/3, Loss=-0.4496\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_3.pt\n",
      "Cluster 4 | X=(512, 64, 28, 19)\n",
      "  Epoch 1/3, Loss=-1.1942\n",
      "  Epoch 2/3, Loss=-0.5445\n",
      "  Epoch 3/3, Loss=-0.6573\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_4.pt\n",
      "Cluster 5 | X=(512, 64, 25, 19)\n",
      "  Epoch 1/3, Loss=0.3239\n",
      "  Epoch 2/3, Loss=-0.4962\n",
      "  Epoch 3/3, Loss=-0.5282\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_5.pt\n",
      "Cluster 6 | X=(512, 64, 25, 19)\n",
      "  Epoch 1/3, Loss=-0.4335\n",
      "  Epoch 2/3, Loss=-0.5409\n",
      "  Epoch 3/3, Loss=-0.5386\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_6.pt\n",
      "Cluster 7 | X=(512, 64, 22, 19)\n",
      "  Epoch 1/3, Loss=-0.9845\n",
      "  Epoch 2/3, Loss=-0.5491\n",
      "  Epoch 3/3, Loss=-0.4934\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_7.pt\n",
      "Cluster 8 | X=(512, 64, 22, 19)\n",
      "  Epoch 1/3, Loss=-0.4024\n",
      "  Epoch 2/3, Loss=-0.4782\n",
      "  Epoch 3/3, Loss=-0.4702\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_8.pt\n",
      "Cluster 9 | X=(512, 64, 25, 19)\n",
      "  Epoch 1/3, Loss=-0.6432\n",
      "  Epoch 2/3, Loss=-0.5165\n",
      "  Epoch 3/3, Loss=-0.5443\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_9.pt\n",
      "Cluster 10 | X=(512, 64, 30, 19)\n",
      "  Epoch 1/3, Loss=-0.3029\n",
      "  Epoch 2/3, Loss=-0.6139\n",
      "  Epoch 3/3, Loss=-0.6449\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_10.pt\n",
      "Cluster 11 | X=(512, 64, 26, 19)\n",
      "  Epoch 1/3, Loss=-0.5145\n",
      "  Epoch 2/3, Loss=-0.5636\n",
      "  Epoch 3/3, Loss=-0.5615\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_11.pt\n",
      "Cluster 12 | X=(512, 64, 27, 19)\n",
      "  Epoch 1/3, Loss=0.5481\n",
      "  Epoch 2/3, Loss=-0.5373\n",
      "  Epoch 3/3, Loss=-0.5595\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_12.pt\n",
      "Cluster 13 | X=(512, 64, 25, 19)\n",
      "  Epoch 1/3, Loss=-0.7032\n",
      "  Epoch 2/3, Loss=-0.4939\n",
      "  Epoch 3/3, Loss=-0.5515\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_13.pt\n",
      "Cluster 14 | X=(512, 64, 27, 19)\n",
      "  Epoch 1/3, Loss=-0.2425\n",
      "  Epoch 2/3, Loss=-0.5659\n",
      "  Epoch 3/3, Loss=-0.5618\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_14.pt\n",
      "Cluster 15 | X=(512, 64, 32, 19)\n",
      "  Epoch 1/3, Loss=-0.2747\n",
      "  Epoch 2/3, Loss=-0.6492\n",
      "  Epoch 3/3, Loss=-0.6779\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_15.pt\n",
      "Cluster 16 | X=(512, 64, 29, 19)\n",
      "  Epoch 1/3, Loss=-0.7736\n",
      "  Epoch 2/3, Loss=-0.6496\n",
      "  Epoch 3/3, Loss=-0.6374\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_16.pt\n",
      "Cluster 17 | X=(512, 64, 31, 19)\n",
      "  Epoch 1/3, Loss=-1.0665\n",
      "  Epoch 2/3, Loss=-0.7277\n",
      "  Epoch 3/3, Loss=-0.6796\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_17.pt\n",
      "Cluster 18 | X=(512, 64, 29, 19)\n",
      "  Epoch 1/3, Loss=-0.5634\n",
      "  Epoch 2/3, Loss=-0.6225\n",
      "  Epoch 3/3, Loss=-0.6191\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_18.pt\n",
      "Cluster 19 | X=(512, 64, 31, 19)\n",
      "  Epoch 1/3, Loss=-0.3552\n",
      "  Epoch 2/3, Loss=-0.6359\n",
      "  Epoch 3/3, Loss=-0.6643\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_19.pt\n",
      "Cluster 20 | X=(512, 64, 26, 19)\n",
      "  Epoch 1/3, Loss=0.0165\n",
      "  Epoch 2/3, Loss=-0.6326\n",
      "  Epoch 3/3, Loss=-0.5143\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_20.pt\n",
      "Cluster 21 | X=(512, 64, 33, 19)\n",
      "  Epoch 1/3, Loss=-0.9341\n",
      "  Epoch 2/3, Loss=-0.7226\n",
      "  Epoch 3/3, Loss=-0.7126\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_21.pt\n",
      "Cluster 22 | X=(512, 64, 28, 19)\n",
      "  Epoch 1/3, Loss=-0.5063\n",
      "  Epoch 2/3, Loss=-0.5642\n",
      "  Epoch 3/3, Loss=-0.5919\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_22.pt\n",
      "Cluster 23 | X=(512, 64, 30, 19)\n",
      "  Epoch 1/3, Loss=-0.6184\n",
      "  Epoch 2/3, Loss=-0.6074\n",
      "  Epoch 3/3, Loss=-0.6394\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_23.pt\n",
      "Cluster 24 | X=(512, 64, 30, 19)\n",
      "  Epoch 1/3, Loss=-0.4364\n",
      "  Epoch 2/3, Loss=-0.6551\n",
      "  Epoch 3/3, Loss=-0.6243\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_24.pt\n",
      "Cluster 25 | X=(512, 64, 33, 19)\n",
      "  Epoch 1/3, Loss=-0.5929\n",
      "  Epoch 2/3, Loss=-0.7038\n",
      "  Epoch 3/3, Loss=-0.7135\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_25.pt\n",
      "Cluster 26 | X=(512, 64, 29, 19)\n",
      "  Epoch 1/3, Loss=-1.7090\n",
      "  Epoch 2/3, Loss=-0.6740\n",
      "  Epoch 3/3, Loss=-0.6250\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_26.pt\n",
      "Cluster 27 | X=(512, 64, 25, 19)\n",
      "  Epoch 1/3, Loss=-1.2411\n",
      "  Epoch 2/3, Loss=-0.5643\n",
      "  Epoch 3/3, Loss=-0.5446\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_27.pt\n",
      "Cluster 28 | X=(512, 64, 26, 19)\n",
      "  Epoch 1/3, Loss=-0.3974\n",
      "  Epoch 2/3, Loss=-0.5706\n",
      "  Epoch 3/3, Loss=-0.5686\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_28.pt\n",
      "Cluster 29 | X=(512, 64, 32, 19)\n",
      "  Epoch 1/3, Loss=-0.6149\n",
      "  Epoch 2/3, Loss=-0.6932\n",
      "  Epoch 3/3, Loss=-0.6760\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_29.pt\n",
      "Cluster 30 | X=(512, 64, 28, 19)\n",
      "  Epoch 1/3, Loss=-0.6443\n",
      "  Epoch 2/3, Loss=-0.6113\n",
      "  Epoch 3/3, Loss=-0.6065\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_30.pt\n",
      "Cluster 31 | X=(512, 64, 27, 19)\n",
      "  Epoch 1/3, Loss=-1.0250\n",
      "  Epoch 2/3, Loss=-0.4655\n",
      "  Epoch 3/3, Loss=-0.6428\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_31.pt\n",
      "Cluster 32 | X=(512, 64, 25, 19)\n",
      "  Epoch 1/3, Loss=-1.0769\n",
      "  Epoch 2/3, Loss=-0.5461\n",
      "  Epoch 3/3, Loss=-0.5598\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_32.pt\n",
      "Cluster 33 | X=(512, 64, 28, 19)\n",
      "  Epoch 1/3, Loss=-0.5713\n",
      "  Epoch 2/3, Loss=-0.6105\n",
      "  Epoch 3/3, Loss=-0.6067\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_33.pt\n",
      "Cluster 34 | X=(512, 64, 29, 19)\n",
      "  Epoch 1/3, Loss=-0.6555\n",
      "  Epoch 2/3, Loss=-0.6207\n",
      "  Epoch 3/3, Loss=-0.6214\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_34.pt\n",
      "Cluster 35 | X=(512, 64, 30, 19)\n",
      "  Epoch 1/3, Loss=-0.9553\n",
      "  Epoch 2/3, Loss=-0.6309\n",
      "  Epoch 3/3, Loss=-0.6406\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_35.pt\n",
      "Cluster 36 | X=(512, 64, 30, 19)\n",
      "  Epoch 1/3, Loss=0.0665\n",
      "  Epoch 2/3, Loss=-0.6320\n",
      "  Epoch 3/3, Loss=-0.6358\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_36.pt\n",
      "Cluster 37 | X=(512, 64, 32, 19)\n",
      "  Epoch 1/3, Loss=-0.3783\n",
      "  Epoch 2/3, Loss=-0.6718\n",
      "  Epoch 3/3, Loss=-0.6800\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_37.pt\n",
      "Cluster 38 | X=(512, 64, 30, 19)\n",
      "  Epoch 1/3, Loss=-0.6578\n",
      "  Epoch 2/3, Loss=-0.6354\n",
      "  Epoch 3/3, Loss=-0.6428\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_38.pt\n",
      "Cluster 39 | X=(512, 64, 27, 19)\n",
      "  Epoch 1/3, Loss=-0.5593\n",
      "  Epoch 2/3, Loss=-0.5831\n",
      "  Epoch 3/3, Loss=-0.5818\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_39.pt\n",
      "Cluster 40 | X=(512, 64, 32, 19)\n",
      "  Epoch 1/3, Loss=-0.6748\n",
      "  Epoch 2/3, Loss=-0.6897\n",
      "  Epoch 3/3, Loss=-0.6989\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_40.pt\n",
      "Cluster 41 | X=(512, 64, 26, 19)\n",
      "  Epoch 1/3, Loss=-0.4468\n",
      "  Epoch 2/3, Loss=-0.6141\n",
      "  Epoch 3/3, Loss=-0.5584\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_41.pt\n",
      "Cluster 42 | X=(512, 64, 26, 19)\n",
      "  Epoch 1/3, Loss=-0.9033\n",
      "  Epoch 2/3, Loss=-0.5137\n",
      "  Epoch 3/3, Loss=-0.5792\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_42.pt\n",
      "Cluster 43 | X=(512, 64, 32, 19)\n",
      "  Epoch 1/3, Loss=-0.7674\n",
      "  Epoch 2/3, Loss=-0.6952\n",
      "  Epoch 3/3, Loss=-0.6923\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_43.pt\n",
      "Cluster 44 | X=(512, 64, 28, 19)\n",
      "  Epoch 1/3, Loss=-0.6038\n",
      "  Epoch 2/3, Loss=-0.5894\n",
      "  Epoch 3/3, Loss=-0.6087\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_44.pt\n",
      "Cluster 45 | X=(512, 64, 27, 19)\n",
      "  Epoch 1/3, Loss=-0.6411\n",
      "  Epoch 2/3, Loss=-0.6097\n",
      "  Epoch 3/3, Loss=-0.5945\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_45.pt\n",
      "Cluster 46 | X=(512, 64, 28, 19)\n",
      "  Epoch 1/3, Loss=-0.5107\n",
      "  Epoch 2/3, Loss=-0.5644\n",
      "  Epoch 3/3, Loss=-0.6010\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_46.pt\n",
      "Cluster 47 | X=(512, 64, 29, 19)\n",
      "  Epoch 1/3, Loss=-0.0991\n",
      "  Epoch 2/3, Loss=-0.5959\n",
      "  Epoch 3/3, Loss=-0.5828\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_47.pt\n",
      "Cluster 48 | X=(512, 64, 28, 19)\n",
      "  Epoch 1/3, Loss=-0.5451\n",
      "  Epoch 2/3, Loss=-0.5975\n",
      "  Epoch 3/3, Loss=-0.5880\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_48.pt\n",
      "Cluster 49 | X=(512, 64, 31, 19)\n",
      "  Epoch 1/3, Loss=-1.0121\n",
      "  Epoch 2/3, Loss=-0.6964\n",
      "  Epoch 3/3, Loss=-0.6630\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_49.pt\n",
      "Cluster 50 | X=(512, 64, 29, 19)\n",
      "  Epoch 1/3, Loss=-0.3921\n",
      "  Epoch 2/3, Loss=-0.5810\n",
      "  Epoch 3/3, Loss=-0.6085\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_50.pt\n",
      "Cluster 51 | X=(512, 64, 25, 19)\n",
      "  Epoch 1/3, Loss=-0.3510\n",
      "  Epoch 2/3, Loss=-0.5216\n",
      "  Epoch 3/3, Loss=-0.5301\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_51.pt\n",
      "Cluster 52 | X=(512, 64, 31, 19)\n",
      "  Epoch 1/3, Loss=-0.6226\n",
      "  Epoch 2/3, Loss=-0.6760\n",
      "  Epoch 3/3, Loss=-0.6559\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_52.pt\n",
      "Cluster 53 | X=(512, 64, 30, 19)\n",
      "  Epoch 1/3, Loss=-1.0019\n",
      "  Epoch 2/3, Loss=-0.6680\n",
      "  Epoch 3/3, Loss=-0.6544\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_53.pt\n",
      "Cluster 54 | X=(512, 64, 28, 19)\n",
      "  Epoch 1/3, Loss=0.1730\n",
      "  Epoch 2/3, Loss=-0.6335\n",
      "  Epoch 3/3, Loss=-0.5750\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_54.pt\n",
      "Cluster 55 | X=(512, 64, 27, 19)\n",
      "  Epoch 1/3, Loss=-0.6616\n",
      "  Epoch 2/3, Loss=-0.6126\n",
      "  Epoch 3/3, Loss=-0.5924\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_55.pt\n",
      "Cluster 56 | X=(512, 64, 24, 19)\n",
      "  Epoch 1/3, Loss=-0.3877\n",
      "  Epoch 2/3, Loss=-0.4902\n",
      "  Epoch 3/3, Loss=-0.5148\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_56.pt\n",
      "Cluster 57 | X=(512, 64, 32, 19)\n",
      "  Epoch 1/3, Loss=-0.4254\n",
      "  Epoch 2/3, Loss=-0.6701\n",
      "  Epoch 3/3, Loss=-0.6939\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_57.pt\n",
      "Cluster 58 | X=(512, 64, 28, 19)\n",
      "  Epoch 1/3, Loss=-1.5535\n",
      "  Epoch 2/3, Loss=-0.6368\n",
      "  Epoch 3/3, Loss=-0.6133\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_58.pt\n",
      "Cluster 59 | X=(512, 64, 27, 19)\n",
      "  Epoch 1/3, Loss=-1.3874\n",
      "  Epoch 2/3, Loss=-0.5675\n",
      "  Epoch 3/3, Loss=-0.6178\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_59.pt\n",
      "Cluster 60 | X=(512, 64, 27, 19)\n",
      "  Epoch 1/3, Loss=0.0647\n",
      "  Epoch 2/3, Loss=-0.5609\n",
      "  Epoch 3/3, Loss=-0.5522\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_60.pt\n",
      "Cluster 61 | X=(512, 64, 24, 19)\n",
      "  Epoch 1/3, Loss=-0.6405\n",
      "  Epoch 2/3, Loss=-0.4591\n",
      "  Epoch 3/3, Loss=-0.5345\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_61.pt\n",
      "Cluster 62 | X=(512, 64, 25, 19)\n",
      "  Epoch 1/3, Loss=-0.6686\n",
      "  Epoch 2/3, Loss=-0.4707\n",
      "  Epoch 3/3, Loss=-0.5798\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_62.pt\n",
      "Cluster 63 | X=(512, 64, 23, 19)\n",
      "  Epoch 1/3, Loss=-0.4048\n",
      "  Epoch 2/3, Loss=-0.5393\n",
      "  Epoch 3/3, Loss=-0.4782\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_63.pt\n",
      "Cluster 64 | X=(512, 64, 23, 19)\n",
      "  Epoch 1/3, Loss=-0.4737\n",
      "  Epoch 2/3, Loss=-0.4657\n",
      "  Epoch 3/3, Loss=-0.4844\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_64.pt\n",
      "Cluster 65 | X=(512, 64, 27, 19)\n",
      "  Epoch 1/3, Loss=-0.1270\n",
      "  Epoch 2/3, Loss=-0.6514\n",
      "  Epoch 3/3, Loss=-0.5354\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_65.pt\n",
      "Cluster 66 | X=(512, 64, 27, 19)\n",
      "  Epoch 1/3, Loss=-1.2823\n",
      "  Epoch 2/3, Loss=-0.6042\n",
      "  Epoch 3/3, Loss=-0.6166\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_66.pt\n",
      "Cluster 67 | X=(512, 64, 25, 19)\n",
      "  Epoch 1/3, Loss=-0.4903\n",
      "  Epoch 2/3, Loss=-0.5786\n",
      "  Epoch 3/3, Loss=-0.5100\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_67.pt\n",
      "Cluster 68 | X=(512, 64, 26, 19)\n",
      "  Epoch 1/3, Loss=-0.8498\n",
      "  Epoch 2/3, Loss=-0.5221\n",
      "  Epoch 3/3, Loss=-0.5661\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_68.pt\n",
      "Cluster 69 | X=(512, 64, 25, 19)\n",
      "  Epoch 1/3, Loss=-0.1835\n",
      "  Epoch 2/3, Loss=-0.6102\n",
      "  Epoch 3/3, Loss=-0.5258\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_69.pt\n",
      "Cluster 70 | X=(512, 64, 23, 19)\n",
      "  Epoch 1/3, Loss=-0.3281\n",
      "  Epoch 2/3, Loss=-0.4795\n",
      "  Epoch 3/3, Loss=-0.4988\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_70.pt\n",
      "Cluster 71 | X=(512, 64, 24, 19)\n",
      "  Epoch 1/3, Loss=-0.4584\n",
      "  Epoch 2/3, Loss=-0.5225\n",
      "  Epoch 3/3, Loss=-0.5025\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_71.pt\n",
      "Cluster 72 | X=(512, 64, 25, 19)\n",
      "  Epoch 1/3, Loss=-0.7304\n",
      "  Epoch 2/3, Loss=-0.5274\n",
      "  Epoch 3/3, Loss=-0.5460\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_72.pt\n",
      "Cluster 73 | X=(512, 64, 20, 19)\n",
      "  Epoch 1/3, Loss=-0.9691\n",
      "  Epoch 2/3, Loss=-0.4552\n",
      "  Epoch 3/3, Loss=-0.4147\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_73.pt\n",
      "Cluster 74 | X=(512, 64, 22, 19)\n",
      "  Epoch 1/3, Loss=0.9843\n",
      "  Epoch 2/3, Loss=-0.4030\n",
      "  Epoch 3/3, Loss=-0.4593\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_74.pt\n",
      "Cluster 75 | X=(512, 64, 23, 19)\n",
      "  Epoch 1/3, Loss=0.4647\n",
      "  Epoch 2/3, Loss=-0.4584\n",
      "  Epoch 3/3, Loss=-0.4685\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_75.pt\n",
      "Cluster 76 | X=(512, 64, 19, 19)\n",
      "  Epoch 1/3, Loss=-0.3757\n",
      "  Epoch 2/3, Loss=-0.0143\n",
      "  Epoch 3/3, Loss=-0.4284\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_76.pt\n",
      "Cluster 77 | X=(512, 64, 19, 19)\n",
      "  Epoch 1/3, Loss=-0.2752\n",
      "  Epoch 2/3, Loss=-0.5146\n",
      "  Epoch 3/3, Loss=-0.2830\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_77.pt\n",
      "Cluster 78 | X=(512, 64, 21, 19)\n",
      "  Epoch 1/3, Loss=0.0682\n",
      "  Epoch 2/3, Loss=-0.4128\n",
      "  Epoch 3/3, Loss=-0.4062\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_78.pt\n",
      "Cluster 79 | X=(512, 64, 21, 19)\n",
      "  Epoch 1/3, Loss=-0.6123\n",
      "  Epoch 2/3, Loss=-0.4405\n",
      "  Epoch 3/3, Loss=-0.5071\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_79.pt\n",
      "Cluster 80 | X=(512, 64, 26, 19)\n",
      "  Epoch 1/3, Loss=-0.5093\n",
      "  Epoch 2/3, Loss=-0.4865\n",
      "  Epoch 3/3, Loss=-0.5839\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_80.pt\n",
      "Cluster 81 | X=(512, 64, 19, 19)\n",
      "  Epoch 1/3, Loss=0.2528\n",
      "  Epoch 2/3, Loss=-0.5223\n",
      "  Epoch 3/3, Loss=-0.2311\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_81.pt\n",
      "Cluster 82 | X=(512, 64, 20, 19)\n",
      "  Epoch 1/3, Loss=-0.2139\n",
      "  Epoch 2/3, Loss=-0.4147\n",
      "  Epoch 3/3, Loss=-0.4257\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_82.pt\n",
      "Cluster 83 | X=(512, 64, 25, 19)\n",
      "  Epoch 1/3, Loss=-0.1658\n",
      "  Epoch 2/3, Loss=-0.5738\n",
      "  Epoch 3/3, Loss=-0.5185\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_83.pt\n",
      "Cluster 84 | X=(512, 64, 23, 19)\n",
      "  Epoch 1/3, Loss=0.1668\n",
      "  Epoch 2/3, Loss=-0.3145\n",
      "  Epoch 3/3, Loss=-0.4735\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_84.pt\n",
      "Cluster 85 | X=(512, 64, 19, 19)\n",
      "  Epoch 1/3, Loss=-0.3730\n",
      "  Epoch 2/3, Loss=-0.0293\n",
      "  Epoch 3/3, Loss=-0.6091\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_85.pt\n",
      "Cluster 86 | X=(512, 64, 21, 19)\n",
      "  Epoch 1/3, Loss=-0.1642\n",
      "  Epoch 2/3, Loss=-0.4291\n",
      "  Epoch 3/3, Loss=-0.4316\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_86.pt\n",
      "Cluster 87 | X=(512, 64, 18, 19)\n",
      "  Epoch 1/3, Loss=0.1419\n",
      "  Epoch 2/3, Loss=-0.3176\n",
      "  Epoch 3/3, Loss=-0.3628\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_87.pt\n",
      "Cluster 88 | X=(512, 64, 19, 19)\n",
      "  Epoch 1/3, Loss=-0.2240\n",
      "  Epoch 2/3, Loss=-0.7140\n",
      "  Epoch 3/3, Loss=-0.0946\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_88.pt\n",
      "Cluster 89 | X=(512, 64, 19, 19)\n",
      "  Epoch 1/3, Loss=-0.5589\n",
      "  Epoch 2/3, Loss=-0.2764\n",
      "  Epoch 3/3, Loss=-0.4801\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_89.pt\n",
      "Cluster 90 | X=(512, 64, 22, 19)\n",
      "  Epoch 1/3, Loss=-0.3435\n",
      "  Epoch 2/3, Loss=-0.4402\n",
      "  Epoch 3/3, Loss=-0.4718\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_90.pt\n",
      "Cluster 91 | X=(512, 64, 18, 19)\n",
      "  Epoch 1/3, Loss=-0.3022\n",
      "  Epoch 2/3, Loss=-0.3791\n",
      "  Epoch 3/3, Loss=-0.4207\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_91.pt\n",
      "Cluster 92 | X=(512, 64, 16, 19)\n",
      "  Epoch 1/3, Loss=-0.2989\n",
      "  Epoch 2/3, Loss=-0.2928\n",
      "  Epoch 3/3, Loss=-0.3534\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_92.pt\n",
      "Cluster 93 | X=(512, 64, 18, 19)\n",
      "  Epoch 1/3, Loss=0.3772\n",
      "  Epoch 2/3, Loss=-0.3868\n",
      "  Epoch 3/3, Loss=-0.3592\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_93.pt\n",
      "Cluster 94 | X=(512, 64, 24, 19)\n",
      "  Epoch 1/3, Loss=-0.1446\n",
      "  Epoch 2/3, Loss=-0.5464\n",
      "  Epoch 3/3, Loss=-0.5075\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_94.pt\n",
      "Cluster 95 | X=(512, 64, 22, 19)\n",
      "  Epoch 1/3, Loss=-0.4695\n",
      "  Epoch 2/3, Loss=-0.4226\n",
      "  Epoch 3/3, Loss=-0.4900\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_95.pt\n",
      "Cluster 96 | X=(512, 64, 16, 19)\n",
      "  Epoch 1/3, Loss=-0.3350\n",
      "  Epoch 2/3, Loss=-0.3316\n",
      "  Epoch 3/3, Loss=-0.3384\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_96.pt\n",
      "Cluster 97 | X=(512, 64, 18, 19)\n",
      "  Epoch 1/3, Loss=-0.9776\n",
      "  Epoch 2/3, Loss=-0.4606\n",
      "  Epoch 3/3, Loss=-0.3922\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_97.pt\n",
      "Cluster 98 | X=(512, 64, 16, 19)\n",
      "  Epoch 1/3, Loss=-0.3678\n",
      "  Epoch 2/3, Loss=-0.3102\n",
      "  Epoch 3/3, Loss=-0.3426\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_98.pt\n",
      "Cluster 99 | X=(512, 64, 15, 19)\n",
      "  Epoch 1/3, Loss=-0.1916\n",
      "  Epoch 2/3, Loss=-0.3929\n",
      "  Epoch 3/3, Loss=-0.3282\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_99.pt\n",
      "Cluster 100 | X=(512, 64, 13, 19)\n",
      "  Epoch 1/3, Loss=-0.5142\n",
      "  Epoch 2/3, Loss=-0.4437\n",
      "  Epoch 3/3, Loss=-0.2434\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_100.pt\n",
      "Cluster 101 | X=(512, 64, 14, 19)\n",
      "  Epoch 1/3, Loss=-0.7956\n",
      "  Epoch 2/3, Loss=-0.5824\n",
      "  Epoch 3/3, Loss=-0.2303\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_101.pt\n",
      "Cluster 102 | X=(512, 64, 12, 19)\n",
      "  Epoch 1/3, Loss=-0.0301\n",
      "  Epoch 2/3, Loss=-0.2037\n",
      "  Epoch 3/3, Loss=-0.2809\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_102.pt\n",
      "Cluster 103 | X=(512, 64, 22, 19)\n",
      "  Epoch 1/3, Loss=-0.2892\n",
      "  Epoch 2/3, Loss=-0.4851\n",
      "  Epoch 3/3, Loss=-0.4663\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_103.pt\n",
      "Cluster 104 | X=(512, 64, 13, 19)\n",
      "  Epoch 1/3, Loss=0.1424\n",
      "  Epoch 2/3, Loss=-0.2099\n",
      "  Epoch 3/3, Loss=-0.2465\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_104.pt\n",
      "Cluster 105 | X=(512, 64, 13, 19)\n",
      "  Epoch 1/3, Loss=-0.4720\n",
      "  Epoch 2/3, Loss=-0.3574\n",
      "  Epoch 3/3, Loss=-0.2921\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_105.pt\n",
      "Cluster 106 | X=(512, 64, 14, 19)\n",
      "  Epoch 1/3, Loss=-0.2352\n",
      "  Epoch 2/3, Loss=-0.3171\n",
      "  Epoch 3/3, Loss=-0.2680\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_106.pt\n",
      "Cluster 107 | X=(512, 64, 12, 19)\n",
      "  Epoch 1/3, Loss=-0.3141\n",
      "  Epoch 2/3, Loss=-0.2019\n",
      "  Epoch 3/3, Loss=-0.2446\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_107.pt\n",
      "Cluster 108 | X=(512, 64, 13, 19)\n",
      "  Epoch 1/3, Loss=-0.2392\n",
      "  Epoch 2/3, Loss=-0.4495\n",
      "  Epoch 3/3, Loss=-0.2110\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_108.pt\n",
      "Cluster 109 | X=(512, 64, 9, 19)\n",
      "  Epoch 1/3, Loss=-0.6104\n",
      "  Epoch 2/3, Loss=-0.1940\n",
      "  Epoch 3/3, Loss=-0.1972\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_109.pt\n",
      "Cluster 110 | X=(512, 64, 9, 19)\n",
      "  Epoch 1/3, Loss=-0.3339\n",
      "  Epoch 2/3, Loss=-0.1327\n",
      "  Epoch 3/3, Loss=-0.1981\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_110.pt\n",
      "Cluster 111 | X=(512, 64, 11, 19)\n",
      "  Epoch 1/3, Loss=-0.3905\n",
      "  Epoch 2/3, Loss=-0.2762\n",
      "  Epoch 3/3, Loss=-0.2258\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_111.pt\n",
      "Cluster 112 | X=(512, 64, 6, 19)\n",
      "  Epoch 1/3, Loss=0.4291\n",
      "  Epoch 2/3, Loss=-0.1949\n",
      "  Epoch 3/3, Loss=-0.1462\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_112.pt\n",
      "Cluster 113 | X=(512, 64, 6, 19)\n",
      "  Epoch 1/3, Loss=-0.0743\n",
      "  Epoch 2/3, Loss=-0.0126\n",
      "  Epoch 3/3, Loss=-0.1880\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_113.pt\n",
      "Cluster 114 | X=(512, 64, 6, 19)\n",
      "  Epoch 1/3, Loss=-0.4774\n",
      "  Epoch 2/3, Loss=0.0843\n",
      "  Epoch 3/3, Loss=-0.2337\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_114.pt\n",
      "Cluster 115 | X=(512, 64, 6, 19)\n",
      "  Epoch 1/3, Loss=-0.2998\n",
      "  Epoch 2/3, Loss=-0.0070\n",
      "  Epoch 3/3, Loss=-0.1864\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_115.pt\n",
      "Cluster 116 | X=(512, 64, 8, 19)\n",
      "  Epoch 1/3, Loss=-0.2676\n",
      "  Epoch 2/3, Loss=-0.0968\n",
      "  Epoch 3/3, Loss=-0.2078\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_116.pt\n",
      "Cluster 117 | X=(512, 64, 5, 19)\n",
      "  Epoch 1/3, Loss=1.0025\n",
      "  Epoch 2/3, Loss=-0.2416\n",
      "  Epoch 3/3, Loss=-0.2608\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_117.pt\n",
      "Cluster 118 | X=(512, 64, 5, 19)\n",
      "  Epoch 1/3, Loss=0.1202\n",
      "  Epoch 2/3, Loss=-0.0775\n",
      "  Epoch 3/3, Loss=-0.1483\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_118.pt\n",
      "Cluster 119 | X=(512, 64, 5, 19)\n",
      "  Epoch 1/3, Loss=0.1959\n",
      "  Epoch 2/3, Loss=-0.0940\n",
      "  Epoch 3/3, Loss=-0.1591\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_119.pt\n",
      "Cluster 120 | X=(512, 64, 5, 19)\n",
      "  Epoch 1/3, Loss=0.5773\n",
      "  Epoch 2/3, Loss=-0.1968\n",
      "  Epoch 3/3, Loss=-0.1273\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_120.pt\n",
      "Cluster 121 | X=(512, 64, 8, 19)\n",
      "  Epoch 1/3, Loss=-0.1357\n",
      "  Epoch 2/3, Loss=-0.1354\n",
      "  Epoch 3/3, Loss=-0.1881\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_121.pt\n",
      "Cluster 122 | X=(512, 64, 6, 19)\n",
      "  Epoch 1/3, Loss=0.7546\n",
      "  Epoch 2/3, Loss=-0.1507\n",
      "  Epoch 3/3, Loss=-0.1279\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_122.pt\n",
      "Cluster 123 | X=(512, 64, 4, 19)\n",
      "  Epoch 1/3, Loss=-0.0078\n",
      "  Epoch 2/3, Loss=-0.1092\n",
      "  Epoch 3/3, Loss=-0.1093\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_123.pt\n",
      "Cluster 124 | X=(512, 64, 5, 19)\n",
      "  Epoch 1/3, Loss=0.7967\n",
      "  Epoch 2/3, Loss=-0.0394\n",
      "  Epoch 3/3, Loss=-0.0865\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_124.pt\n",
      "Cluster 125 | X=(512, 64, 4, 19)\n",
      "  Epoch 1/3, Loss=-0.0368\n",
      "  Epoch 2/3, Loss=-0.0887\n",
      "  Epoch 3/3, Loss=-0.1660\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_125.pt\n",
      "Cluster 126 | X=(512, 64, 3, 19)\n",
      "  Epoch 1/3, Loss=-0.3935\n",
      "  Epoch 2/3, Loss=-0.0500\n",
      "  Epoch 3/3, Loss=0.0225\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_126.pt\n",
      "Cluster 127 | X=(512, 64, 3, 19)\n",
      "  Epoch 1/3, Loss=0.6859\n",
      "  Epoch 2/3, Loss=-0.0847\n",
      "  Epoch 3/3, Loss=-0.2500\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_127.pt\n",
      "Cluster 128 | X=(512, 64, 4, 19)\n",
      "  Epoch 1/3, Loss=-0.1281\n",
      "  Epoch 2/3, Loss=0.0511\n",
      "  Epoch 3/3, Loss=-0.0862\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_128.pt\n",
      "Cluster 129 | X=(512, 64, 3, 19)\n",
      "  Epoch 1/3, Loss=-0.0126\n",
      "  Epoch 2/3, Loss=-0.1328\n",
      "  Epoch 3/3, Loss=-0.0177\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_129.pt\n",
      "Cluster 130 | X=(512, 64, 3, 19)\n",
      "  Epoch 1/3, Loss=0.2724\n",
      "  Epoch 2/3, Loss=-0.0170\n",
      "  Epoch 3/3, Loss=-0.0627\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_130.pt\n",
      "Cluster 131 | X=(512, 64, 5, 19)\n",
      "  Epoch 1/3, Loss=-0.2460\n",
      "  Epoch 2/3, Loss=0.0162\n",
      "  Epoch 3/3, Loss=-0.2378\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_131.pt\n",
      "Cluster 132 | X=(512, 64, 3, 19)\n",
      "  Epoch 1/3, Loss=0.6014\n",
      "  Epoch 2/3, Loss=-0.1678\n",
      "  Epoch 3/3, Loss=-0.2973\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_132.pt\n",
      "Cluster 133 | X=(512, 64, 3, 19)\n",
      "  Epoch 1/3, Loss=-0.5889\n",
      "  Epoch 2/3, Loss=0.0307\n",
      "  Epoch 3/3, Loss=0.0874\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_133.pt\n",
      "Cluster 134 | X=(512, 64, 2, 19)\n",
      "  Epoch 1/3, Loss=0.2909\n",
      "  Epoch 2/3, Loss=-0.0146\n",
      "  Epoch 3/3, Loss=-0.1218\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_134.pt\n",
      "Cluster 135 | X=(512, 64, 2, 19)\n",
      "  Epoch 1/3, Loss=-0.2410\n",
      "  Epoch 2/3, Loss=-0.0207\n",
      "  Epoch 3/3, Loss=0.0105\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_135.pt\n",
      "Cluster 136 | X=(512, 64, 2, 19)\n",
      "  Epoch 1/3, Loss=0.2103\n",
      "  Epoch 2/3, Loss=-0.0243\n",
      "  Epoch 3/3, Loss=-0.0845\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_136.pt\n",
      "Cluster 137 | X=(512, 64, 3, 19)\n",
      "  Epoch 1/3, Loss=-0.2543\n",
      "  Epoch 2/3, Loss=-0.0817\n",
      "  Epoch 3/3, Loss=-0.0210\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_137.pt\n",
      "Cluster 138 | X=(512, 64, 2, 19)\n",
      "  Epoch 1/3, Loss=-0.2255\n",
      "  Epoch 2/3, Loss=-0.0626\n",
      "  Epoch 3/3, Loss=-0.0312\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_138.pt\n",
      "Cluster 139 | X=(512, 64, 2, 19)\n",
      "  Epoch 1/3, Loss=-0.3222\n",
      "  Epoch 2/3, Loss=-0.1677\n",
      "  Epoch 3/3, Loss=-0.0283\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_139.pt\n",
      "Cluster 140 | X=(512, 64, 1, 19)\n",
      "  Epoch 1/3, Loss=0.1418\n",
      "  Epoch 2/3, Loss=0.0041\n",
      "  Epoch 3/3, Loss=-0.0704\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_140.pt\n",
      "Cluster 141 | X=(512, 64, 1, 19)\n",
      "  Epoch 1/3, Loss=0.1560\n",
      "  Epoch 2/3, Loss=0.0607\n",
      "  Epoch 3/3, Loss=-0.0168\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_141.pt\n",
      "Cluster 142 | X=(512, 64, 1, 19)\n",
      "  Epoch 1/3, Loss=0.2465\n",
      "  Epoch 2/3, Loss=0.1405\n",
      "  Epoch 3/3, Loss=0.0513\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_142.pt\n",
      "Cluster 143 | X=(512, 64, 1, 19)\n",
      "  Epoch 1/3, Loss=0.1929\n",
      "  Epoch 2/3, Loss=0.0497\n",
      "  Epoch 3/3, Loss=-0.0227\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_143.pt\n",
      "Cluster 144 | X=(512, 64, 1, 19)\n",
      "  Epoch 1/3, Loss=-0.0496\n",
      "  Epoch 2/3, Loss=-0.0454\n",
      "  Epoch 3/3, Loss=-0.0074\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_144.pt\n",
      "Cluster 145 | X=(512, 64, 1, 19)\n",
      "  Epoch 1/3, Loss=0.0627\n",
      "  Epoch 2/3, Loss=-0.0436\n",
      "  Epoch 3/3, Loss=-0.0750\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_145.pt\n",
      "Cluster 146 | X=(511, 64, 1, 19)\n",
      "  Epoch 1/3, Loss=-0.1636\n",
      "  Epoch 2/3, Loss=-0.0772\n",
      "  Epoch 3/3, Loss=0.0076\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_146.pt\n",
      "Cluster 147 | X=(511, 64, 1, 19)\n",
      "  Epoch 1/3, Loss=-0.0449\n",
      "  Epoch 2/3, Loss=0.0284\n",
      "  Epoch 3/3, Loss=-0.0196\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_147.pt\n",
      "Cluster 148 | X=(512, 64, 1, 19)\n",
      "  Epoch 1/3, Loss=0.0305\n",
      "  Epoch 2/3, Loss=-0.0530\n",
      "  Epoch 3/3, Loss=-0.0388\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_148.pt\n",
      "Cluster 149 | X=(512, 64, 1, 19)\n",
      "  Epoch 1/3, Loss=-0.0056\n",
      "  Epoch 2/3, Loss=0.0320\n",
      "  Epoch 3/3, Loss=-0.0237\n",
      "  ✅ Saved model checkpoint: ./models/a3c_cluster_149.pt\n",
      "✅ Done Block 8: signals saved to ./signals/a3c_signals.csv, models in ./models/\n"
     ]
    }
   ],
   "source": [
    "# Block 8 — A3C multi-stock per-cluster (clean version)\n",
    "\n",
    "import os, gc, json, csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "DATA_DIR   = \"./tensors/\"\n",
    "SIG_DIR    = \"./signals/\"\n",
    "MODEL_DIR  = \"./models/\"\n",
    "os.makedirs(SIG_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "SIG_FILE = os.path.join(SIG_DIR, \"a3c_signals.csv\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Reset signals file\n",
    "if os.path.exists(SIG_FILE):\n",
    "    os.remove(SIG_FILE)\n",
    "with open(SIG_FILE, \"w\", newline=\"\") as f:\n",
    "    csv.writer(f).writerow([\"date\",\"ticker\",\"signal\"])\n",
    "\n",
    "# Load metadata\n",
    "with open(os.path.join(DATA_DIR, \"tensor_index.json\"), \"r\") as f:\n",
    "    tensor_index = json.load(f)\n",
    "\n",
    "# --- Model ---\n",
    "class A3CNet(nn.Module):\n",
    "    def __init__(self, n_features, hidden=64):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=n_features, hidden_size=hidden, batch_first=True)\n",
    "        self.actor = nn.Linear(hidden, 3)   # short, flat, long\n",
    "        self.critic = nn.Linear(hidden, 1)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        h = out[:, -1, :]\n",
    "        return self.actor(h), self.critic(h)\n",
    "\n",
    "# --- Loss ---\n",
    "def a3c_loss(logits, values, actions, rewards, beta=0.01):\n",
    "    adv = rewards - values.squeeze(-1)\n",
    "    critic = adv.pow(2).mean()\n",
    "    logp = torch.log_softmax(logits, dim=-1)\n",
    "    actor = -(logp.gather(1, actions.unsqueeze(1)).squeeze(1) * adv.detach()).mean()\n",
    "    entropy = -(torch.softmax(logits, dim=-1) * logp).sum(-1).mean()\n",
    "    return actor + 0.5*critic - beta*entropy\n",
    "\n",
    "# --- Training & inference ---\n",
    "def process_cluster(meta, epochs=3, lr=1e-3, batch_size=256):\n",
    "    c_id, tickers = meta[\"cluster\"], meta[\"tickers\"]\n",
    "    dates = pd.to_datetime(meta[\"dates\"])\n",
    "    dates_shifted = pd.to_datetime(meta[\"dates_shifted\"])\n",
    "\n",
    "    X = np.load(os.path.join(DATA_DIR, meta[\"tensor_file\"]), mmap_mode=\"r\")\n",
    "    M = np.load(os.path.join(DATA_DIR, meta[\"mask_file\"]), mmap_mode=\"r\")\n",
    "    if X.size == 0:\n",
    "        return\n",
    "    B, T, N, F = X.shape\n",
    "    print(f\"Cluster {c_id} | X={X.shape}\")\n",
    "\n",
    "    # --- Lấy giá để tính reward ---\n",
    "    px = []\n",
    "    for tk in tickers:\n",
    "        s = df_backtest[df_backtest[\"ticker\"]==tk].set_index(\"timestamp\")[\"close\"]\n",
    "        s = s.reindex(dates_shifted).ffill().bfill().values\n",
    "        px.append(s)\n",
    "    px = np.stack(px, axis=1)  # (B,N)\n",
    "    r = np.zeros_like(px, dtype=np.float32)\n",
    "    r[1:] = np.log(px[1:] / np.maximum(px[:-1], 1e-9))  # daily log-return\n",
    "\n",
    "    # --- Model + optimizer ---\n",
    "    model = A3CNet(F).to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Mini-batch generator\n",
    "    total = B*N\n",
    "    def iterator():\n",
    "        for start in range(0, total, batch_size):\n",
    "            end = min(total, start+batch_size)\n",
    "            xb, mb, rb, idx = [], [], [], []\n",
    "            for s in range(start,end):\n",
    "                b, n = divmod(s, N)\n",
    "                xb.append(X[b,:,n,:])\n",
    "                mb.append(M[b,:,n,:])\n",
    "                rb.append(r[b,n])\n",
    "                idx.append((b,n))\n",
    "            yield np.stack(xb), np.stack(mb), np.array(rb), idx\n",
    "\n",
    "    # --- Train ---\n",
    "    for ep in range(epochs):\n",
    "        loss_ep = 0\n",
    "        for xb, mb, rb, _ in iterator():\n",
    "            xb = torch.tensor(xb, dtype=torch.float32).to(device)\n",
    "            rb = torch.tensor(rb, dtype=torch.float32).to(device)\n",
    "            xb = xb * torch.tensor(mb, dtype=torch.float32).to(device)\n",
    "\n",
    "            logits, vals = model(xb)\n",
    "            dist = torch.distributions.Categorical(logits=logits)\n",
    "            act = dist.sample()\n",
    "\n",
    "            # Mapping: 0=short, 1=flat, 2=long\n",
    "            reward = torch.where(act==2, rb, torch.where(act==0, -rb, torch.zeros_like(rb)))\n",
    "            loss = a3c_loss(logits, vals, act, reward)\n",
    "\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            loss_ep += loss.item()\n",
    "        print(f\"  Epoch {ep+1}/{epochs}, Loss={loss_ep:.4f}\")\n",
    "        gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "    # --- Save model ---\n",
    "    model_path = os.path.join(MODEL_DIR, f\"a3c_cluster_{c_id}.pt\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"  ✅ Saved model checkpoint: {model_path}\")\n",
    "\n",
    "    # --- Inference & save signals ---\n",
    "    with open(SIG_FILE,\"a\",newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        with torch.no_grad():\n",
    "            for xb, mb, _, idx in iterator():\n",
    "                xb = torch.tensor(xb, dtype=torch.float32).to(device)\n",
    "                xb = xb * torch.tensor(mb, dtype=torch.float32).to(device)\n",
    "                raw_acts = torch.argmax(model(xb)[0], dim=-1).cpu().numpy()  # 0,1,2\n",
    "                acts = np.where(raw_acts==2, 1, np.where(raw_acts==0, -1, 0))  # map -> -1,0,1\n",
    "                for k,(b,n) in enumerate(idx):\n",
    "                    w.writerow([dates_shifted[b], tickers[n], int(acts[k])])\n",
    "                del xb, acts\n",
    "                gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "    del X, M, px, r, model, opt\n",
    "    gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "# --- Run all clusters ---\n",
    "for meta in tensor_index:\n",
    "    process_cluster(meta)\n",
    "\n",
    "print(f\"✅ Done Block 8: signals saved to {SIG_FILE}, models in {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7418f9a1",
   "metadata": {},
   "source": [
    "**Block 9: Suy luận từ mô hình A3C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e2629b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Inference] Cluster 0 | X=(512, 64, 15, 19)\n",
      "[Inference] Cluster 1 | X=(512, 64, 14, 19)\n",
      "[Inference] Cluster 2 | X=(512, 64, 20, 19)\n",
      "[Inference] Cluster 3 | X=(512, 64, 21, 19)\n",
      "[Inference] Cluster 4 | X=(512, 64, 28, 19)\n",
      "[Inference] Cluster 5 | X=(512, 64, 25, 19)\n",
      "[Inference] Cluster 6 | X=(512, 64, 25, 19)\n",
      "[Inference] Cluster 7 | X=(512, 64, 22, 19)\n",
      "[Inference] Cluster 8 | X=(512, 64, 22, 19)\n",
      "[Inference] Cluster 9 | X=(512, 64, 25, 19)\n",
      "[Inference] Cluster 10 | X=(512, 64, 30, 19)\n",
      "[Inference] Cluster 11 | X=(512, 64, 26, 19)\n",
      "[Inference] Cluster 12 | X=(512, 64, 27, 19)\n",
      "[Inference] Cluster 13 | X=(512, 64, 25, 19)\n"
     ]
    }
   ],
   "source": [
    "# Block 9 — Inference từ checkpoint A3C\n",
    "\n",
    "import os, gc, json, csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "DATA_DIR = \"./tensors/\"\n",
    "MODEL_DIR = \"./models/\"\n",
    "SIG_DIR   = \"./signals/\"\n",
    "os.makedirs(SIG_DIR, exist_ok=True)\n",
    "\n",
    "SIG_FILE = os.path.join(SIG_DIR, \"a3c_signals_infer.csv\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Reset signals file\n",
    "if os.path.exists(SIG_FILE):\n",
    "    os.remove(SIG_FILE)\n",
    "with open(SIG_FILE, \"w\", newline=\"\") as f:\n",
    "    csv.writer(f).writerow([\"date\",\"ticker\",\"signal\"])\n",
    "\n",
    "# Load metadata\n",
    "with open(os.path.join(DATA_DIR, \"tensor_index.json\"), \"r\") as f:\n",
    "    tensor_index = json.load(f)\n",
    "\n",
    "# --- Model định nghĩa lại (giống Block 8) ---\n",
    "class A3CNet(nn.Module):\n",
    "    def __init__(self, n_features, hidden=64):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=n_features, hidden_size=hidden, batch_first=True)\n",
    "        self.actor = nn.Linear(hidden, 3)   # short, flat, long\n",
    "        self.critic = nn.Linear(hidden, 1)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        h = out[:, -1, :]\n",
    "        return self.actor(h), self.critic(h)\n",
    "\n",
    "# --- Inference function ---\n",
    "def infer_cluster(meta, batch_size=256):\n",
    "    c_id, tickers, dates, dates_shifted = meta[\"cluster\"], meta[\"tickers\"], meta[\"dates\"], meta[\"dates_shifted\"]\n",
    "    X = np.load(os.path.join(DATA_DIR, meta[\"tensor_file\"]), mmap_mode=\"r\")\n",
    "    M = np.load(os.path.join(DATA_DIR, meta[\"mask_file\"]), mmap_mode=\"r\")\n",
    "    if X.size == 0:\n",
    "        return\n",
    "    B, T, N, F = X.shape\n",
    "    print(f\"[Inference] Cluster {c_id} | X={X.shape}\")\n",
    "\n",
    "    # Load model checkpoint\n",
    "    model_path = os.path.join(MODEL_DIR, f\"a3c_cluster_{c_id}.pt\")\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"⚠️ Model checkpoint not found: {model_path}, skip\")\n",
    "        return\n",
    "    model = A3CNet(F).to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    # Inference & save signals\n",
    "    total = B * N\n",
    "    with open(SIG_FILE, \"a\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        with torch.no_grad():\n",
    "            for start in range(0, total, batch_size):\n",
    "                end = min(total, start+batch_size)\n",
    "                xb, mb, idx = [], [], []\n",
    "                for s in range(start, end):\n",
    "                    b, n = divmod(s, N)\n",
    "                    xb.append(X[b, :, n, :])\n",
    "                    mb.append(M[b, :, n, :])\n",
    "                    idx.append((b, n))\n",
    "                xb = torch.tensor(np.stack(xb), dtype=torch.float32).to(device)\n",
    "                mb = torch.tensor(np.stack(mb), dtype=torch.float32).to(device)\n",
    "\n",
    "                # Áp dụng mask\n",
    "                xb = xb * mb\n",
    "\n",
    "                acts = torch.argmax(model(xb)[0], dim=-1).cpu().numpy() - 1  # (-1,0,1)\n",
    "                for k,(b,n) in enumerate(idx):\n",
    "                    # dùng dates[b] (ngày cuối window), nhưng reward tính T+1 (dates_shifted)\n",
    "                    w.writerow([dates[b], tickers[n], int(acts[k])])\n",
    "                del xb, mb, acts\n",
    "                gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "    del X, M, model\n",
    "    gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "# --- Run inference all clusters ---\n",
    "for meta in tensor_index:\n",
    "    infer_cluster(meta)\n",
    "\n",
    "print(f\"✅ Done Block 9: inference signals saved to {SIG_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df4f8af",
   "metadata": {},
   "source": [
    "**Block 10 : Huấn luyện Cluster DDPG (chỉ với trường hợp vị thế long)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89195ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 10 — Cluster DDPG + Execution Lag + Turnover Cost \n",
    "\n",
    "import os, gc, json, csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from FiinQuantX import FiinSession\n",
    "\n",
    "# ===== Paths =====\n",
    "DATA_DIR   = \"./tensors/\"\n",
    "SIG_DIR    = \"./signals/\"\n",
    "OUTPUT_DIR = \"./backtest_ddpg/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ===== Hyper-params & config =====\n",
    "INIT_CAPITAL   = 10_000\n",
    "BENCHMARK_TKR  = \"VNINDEX\"\n",
    "EXECUTION_LAG  = 2         # tín hiệu T -> return T+2\n",
    "COST_BPS       = 30        # phí theo turnover 0.30% = 30bps\n",
    "STATE_LKBK     = 10         # số ngày lịch sử dùng làm state\n",
    "MIN_NAMES_PER_CLUSTER = 2  # tối thiểu số mã active trong 1 cụm\n",
    "SEED = 42\n",
    "\n",
    "# DDPG \n",
    "EPOCHS       = 60\n",
    "BATCH_SIZE   = 64\n",
    "LR_ACTOR     = 1e-4\n",
    "LR_CRITIC    = 5e-4\n",
    "GAMMA        = 0.95\n",
    "TAU          = 1e-2\n",
    "NOISE_STD    = 0.05   # nhiễu nhẹ trên logits\n",
    "HIDDEN       = 128\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "# ===== Load artifacts từ các block trước =====\n",
    "# (1) A3C signals\n",
    "signals = pd.read_csv(os.path.join(SIG_DIR, \"a3c_signals_infer.csv\"))\n",
    "signals[\"date\"] = pd.to_datetime(signals[\"date\"])\n",
    "\n",
    "# (2) Giá để tính return\n",
    "df_px = df_backtest.rename(columns={\"timestamp\": \"date\"}).copy()\n",
    "df_px[\"date\"] = pd.to_datetime(df_px[\"date\"])\n",
    "px_wide = df_px.pivot(index=\"date\", columns=\"ticker\", values=\"close\").sort_index()\n",
    "ret_wide = px_wide.pct_change().fillna(0.0)\n",
    "\n",
    "# (3) Map ticker -> cluster\n",
    "with open(os.path.join(DATA_DIR, \"tensor_index.json\"), \"r\") as f:\n",
    "    tensor_index = json.load(f)\n",
    "ticker2cluster = {}\n",
    "for meta in tensor_index:\n",
    "    for tk in meta[\"tickers\"]:\n",
    "        # nếu 1 mã gặp nhiều cụm theo thời gian, giữ cụm đầu tiên để đơn giản\n",
    "        ticker2cluster.setdefault(tk, meta[\"cluster\"])\n",
    "ticker2cluster = pd.Series(ticker2cluster)\n",
    "\n",
    "# ===== Train/Test split =====\n",
    "TRAIN_START = pd.Timestamp(\"2023-01-01\")\n",
    "TRAIN_END   = pd.Timestamp(\"2024-12-31\")\n",
    "TEST_START  = pd.Timestamp(\"2025-01-01\")\n",
    "TEST_END    = ret_wide.index.max()\n",
    "\n",
    "# ===== Chuẩn bị signal với execution lag =====\n",
    "sig_wide_raw = signals.pivot_table(index=\"date\", columns=\"ticker\", values=\"signal\", aggfunc=\"last\").sort_index()\n",
    "idx_all = ret_wide.index.union(sig_wide_raw.index)\n",
    "ret_wide = ret_wide.reindex(idx_all).fillna(0.0)\n",
    "sig_wide = sig_wide_raw.reindex(idx_all).fillna(0.0)\n",
    "sig_wide_lag = sig_wide.shift(EXECUTION_LAG)  # <- execution lag\n",
    "\n",
    "# chỉ giữ tickers có trong map cụm & có return\n",
    "tickers = [t for t in ret_wide.columns if t in ticker2cluster.index]\n",
    "ret_wide = ret_wide[tickers].astype(\"float32\")\n",
    "sig_wide_lag = sig_wide_lag[tickers].astype(\"float32\")\n",
    "cluster_of = ticker2cluster.loc[tickers]\n",
    "\n",
    "# ===== Danh sách cụm và thành viên =====\n",
    "clusters = sorted(cluster_of.unique().tolist())\n",
    "cluster_members = {c: cluster_of[cluster_of == c].index.tolist() for c in clusters}\n",
    "C = len(clusters)\n",
    "\n",
    "# ===== Helpers =====\n",
    "def build_state_arrays(ret_w, sig_lag, start, end, K=STATE_LKBK):\n",
    "    \"\"\"\n",
    "    Xây state ở cấp cụm (long-only):\n",
    "      - activity[c,t] = tỷ lệ mã trong cụm c có signal>0 tại ngày t\n",
    "      - cluster_ret[c,t] = mean return của các mã active (signal>0) trong cụm c tại ngày t\n",
    "    Trả ra:\n",
    "      S_mat: (T, 2*C*K)  -> [activity(K ngày), cluster_ret(K ngày)]\n",
    "      R_mat: (T, C)      -> return cụm tại ngày t (dùng để tính reward)\n",
    "      dates: index tương ứng\n",
    "      ACTIVE_masks: dict[c] -> DataFrame mask active của cụm c trên khoảng thời gian này\n",
    "    \"\"\"\n",
    "    R = ret_w.loc[start:end]\n",
    "    S = sig_lag.loc[start:end]\n",
    "    dates = R.index\n",
    "\n",
    "    # tính activity và return cụm từng ngày, theo cụm\n",
    "    act_cols, ret_cols = [], []\n",
    "    ACTIVE_masks = {}\n",
    "\n",
    "    for c in clusters:\n",
    "        tks = cluster_members[c]\n",
    "        if not tks:\n",
    "            # tạo cột 0 nếu cụm rỗng (hiếm)\n",
    "            act_c = pd.Series(0.0, index=dates, name=c)\n",
    "            ret_c = pd.Series(0.0, index=dates, name=c)\n",
    "            ACTIVE_masks[c] = pd.DataFrame(0.0, index=dates, columns=tks)\n",
    "        else:\n",
    "            S_c = S[tks]\n",
    "            R_c = R[tks]\n",
    "\n",
    "            active_mask = (S_c > 0).astype(\"float32\")  # long-only\n",
    "            ACTIVE_masks[c] = active_mask\n",
    "\n",
    "            denom = active_mask.sum(axis=1).replace(0, np.nan)\n",
    "            w = active_mask.div(denom, axis=0)  # chia đều trong các mã active\n",
    "            w = w.fillna(0.0)\n",
    "\n",
    "            act_c = (active_mask.mean(axis=1)).astype(\"float32\")  # % mã active\n",
    "            ret_c = ((R_c * w).sum(axis=1)).astype(\"float32\")     # mean ret của mã active\n",
    "\n",
    "        act_cols.append(act_c.rename(c))\n",
    "        ret_cols.append(ret_c.rename(c))\n",
    "\n",
    "    act_df = pd.concat(act_cols, axis=1).astype(\"float32\")\n",
    "    cret_df = pd.concat(ret_cols, axis=1).astype(\"float32\")\n",
    "\n",
    "    # dựng state = concat K ngày gần nhất cho activity & cluster_ret\n",
    "    def stack_lookback(df, K):\n",
    "        mats = []\n",
    "        for k in range(K):\n",
    "            mats.append(df.shift(k).fillna(0.0))\n",
    "        return np.concatenate([m.values[:, :, None] for m in mats], axis=2)  # (T, C, K)\n",
    "\n",
    "    A3 = stack_lookback(act_df, K)    # (T,C,K)\n",
    "    R3 = stack_lookback(cret_df, K)   # (T,C,K)\n",
    "\n",
    "    # Loại bỏ những ngày đầu chưa đủ lookback\n",
    "    valid = np.arange(A3.shape[0]) >= (K - 1)\n",
    "    A3 = A3[valid]   # (T',C,K)\n",
    "    R3_look = R3[valid]\n",
    "    dates2 = dates[valid]\n",
    "\n",
    "    # Flatten state: (T', 2*C*K)\n",
    "    S_mat = np.concatenate([A3.reshape(len(dates2), -1), R3_look.reshape(len(dates2), -1)], axis=1).astype(\"float32\")\n",
    "    # Reward dùng return cụm (không lookback): lấy cret_df tại ngày tương ứng\n",
    "    R_mat = cret_df.loc[dates2].values.astype(\"float32\")\n",
    "\n",
    "    # đồng bộ ACTIVE_masks về dates2\n",
    "    ACTIVE_masks = {c: ACTIVE_masks[c].loc[dates2] for c in clusters}\n",
    "    return S_mat, R_mat, dates2, ACTIVE_masks\n",
    "\n",
    "# ===== Chuẩn bị Train & Test =====\n",
    "S_train, R_train, d_train, ACTIVE_train = build_state_arrays(ret_wide, sig_wide_lag, TRAIN_START, TRAIN_END, K=STATE_LKBK)\n",
    "S_test,  R_test,  d_test,  ACTIVE_test  = build_state_arrays(ret_wide, sig_wide_lag, TEST_START,  TEST_END,  K=STATE_LKBK)\n",
    "\n",
    "# ===== DDPG (long-only simplex) =====\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, s_dim, a_dim, hidden=HIDDEN):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(s_dim, hidden), nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden), nn.ReLU(),\n",
    "            nn.Linear(hidden, a_dim)  # logits\n",
    "        )\n",
    "    def forward(self, s):\n",
    "        return torch.softmax(self.net(s), dim=-1)  # long-only, sum=1\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, s_dim, a_dim, hidden=HIDDEN):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(s_dim + a_dim, hidden), nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden), nn.ReLU(),\n",
    "            nn.Linear(hidden, 1)\n",
    "        )\n",
    "    def forward(self, s, a):\n",
    "        return self.net(torch.cat([s, a], dim=-1))\n",
    "\n",
    "class Buffer:\n",
    "    def __init__(self, maxlen=20000):\n",
    "        self.maxlen = maxlen; self.buf=[]\n",
    "    def push(self, s,a,r,s2):\n",
    "        if len(self.buf)>=self.maxlen: self.buf.pop(0)\n",
    "        self.buf.append((s,a,r,s2))\n",
    "    def sample(self, bs):\n",
    "        n=min(bs,len(self.buf))\n",
    "        idx=np.random.choice(len(self.buf), n, replace=False)\n",
    "        s,a,r,s2 = zip(*[self.buf[i] for i in idx])\n",
    "        return (np.array(s, np.float32), np.array(a, np.float32),\n",
    "                np.array(r, np.float32).reshape(-1,1), np.array(s2, np.float32))\n",
    "\n",
    "def step_soft_update(src, tgt, tau):\n",
    "    with torch.no_grad():\n",
    "        for p, tp in zip(src.parameters(), tgt.parameters()):\n",
    "            tp.data.mul_(1-tau); tp.data.add_(tau*p.data)\n",
    "\n",
    "def port_reward_longonly(w_c, r_c, prev_w_c=None):\n",
    "    gross = float(np.dot(w_c, r_c))\n",
    "    fee = 0.0\n",
    "    # phí ở cấp cụm đã được tính ở cấp mã trong mô phỏng cuối, nên ở training giữ đơn giản để ổn định\n",
    "    return gross - fee\n",
    "\n",
    "s_dim = S_train.shape[1]; a_dim = C\n",
    "actor = Actor(s_dim, a_dim).to(device)\n",
    "critic = Critic(s_dim, a_dim).to(device)\n",
    "t_actor = Actor(s_dim, a_dim).to(device); t_actor.load_state_dict(actor.state_dict())\n",
    "t_critic= Critic(s_dim, a_dim).to(device); t_critic.load_state_dict(critic.state_dict())\n",
    "optA = optim.Adam(actor.parameters(), lr=LR_ACTOR)\n",
    "optC = optim.Adam(critic.parameters(), lr=LR_CRITIC)\n",
    "mse = nn.MSELoss()\n",
    "buf = Buffer()\n",
    "\n",
    "# ---- Train  ----\n",
    "S_tr = S_train; R_tr = R_train\n",
    "prev_w = None\n",
    "for ep in range(EPOCHS):\n",
    "    c_loss=a_loss=0.0\n",
    "    prev_w = None\n",
    "    for t in range(len(S_tr)-1):\n",
    "        s  = torch.from_numpy(S_tr[t]).to(device).unsqueeze(0)\n",
    "        s2 = torch.from_numpy(S_tr[t+1]).to(device).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            w = actor(s).cpu().numpy()[0]\n",
    "        # exploration trong simplex\n",
    "        logits = np.log(w + 1e-9) + np.random.normal(0, NOISE_STD, size=a_dim)\n",
    "        w_e = np.exp(logits); w_e = (w_e / w_e.sum()).astype(\"float32\")\n",
    "\n",
    "        r = port_reward_longonly(w_e, R_tr[t], prev_w)\n",
    "        prev_w = w_e.copy()\n",
    "        buf.push(S_tr[t], w_e, r, S_tr[t+1])\n",
    "\n",
    "        if len(buf.buf) >= BATCH_SIZE:\n",
    "            sb, ab, rb, s2b = buf.sample(BATCH_SIZE)\n",
    "            sb  = torch.from_numpy(sb).to(device)\n",
    "            ab  = torch.from_numpy(ab).to(device)\n",
    "            rb  = torch.from_numpy(rb).to(device)\n",
    "            s2b = torch.from_numpy(s2b).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                a2 = t_actor(s2b)\n",
    "                q2 = t_critic(s2b, a2)\n",
    "                y  = rb + GAMMA * q2\n",
    "\n",
    "            q  = critic(sb, ab)\n",
    "            lc = mse(q, y)\n",
    "            optC.zero_grad(); lc.backward(); optC.step()\n",
    "\n",
    "            ap = actor(sb)\n",
    "            la = -critic(sb, ap).mean()\n",
    "            optA.zero_grad(); la.backward(); optA.step()\n",
    "\n",
    "            step_soft_update(actor, t_actor, TAU)\n",
    "            step_soft_update(critic, t_critic, TAU)\n",
    "\n",
    "            c_loss += float(lc.item()); a_loss += float(la.item())\n",
    "    print(f\"[DDPG] Epoch {ep+1}/{EPOCHS} | Critic {c_loss:.4f} | Actor {a_loss:.4f}\")\n",
    "    gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "# ===== Backtest (Test) — long-only với phí theo turnover ở cấp mã =====\n",
    "dates = d_test\n",
    "capital = INIT_CAPITAL\n",
    "portfolio_value = pd.Series(index=dates, dtype=\"float64\")\n",
    "portfolio_value.iloc[0] = capital\n",
    "\n",
    "# stream save cluster weights để không tốn RAM\n",
    "cw_path = os.path.join(OUTPUT_DIR, \"cluster_weights_test.csv\")\n",
    "with open(cw_path, \"w\", newline=\"\") as f:\n",
    "    cw = csv.writer(f); cw.writerow([\"date\"] + [f\"cluster_{c}\" for c in clusters])\n",
    "\n",
    "prev_w_ticker = pd.Series(0.0, index=tickers, dtype=\"float32\")\n",
    "\n",
    "for i, dt in enumerate(dates):\n",
    "    # dùng state của ngày trước (action lag 1 step để chắc chắn không leak)\n",
    "    s_dt = dates[i-1] if i>0 else dates[i]\n",
    "    s = torch.from_numpy(S_test[i-1].astype(\"float32\") if i>0 else S_test[i].astype(\"float32\")).to(device).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        w_c = actor(s).cpu().numpy()[0].astype(\"float32\")\n",
    "    w_c = np.clip(w_c, 0, 1); ssum = w_c.sum(); w_c = w_c/ssum if ssum>0 else np.ones_like(w_c)/len(w_c)\n",
    "\n",
    "    # phân bổ xuống mã: trong mỗi cụm, chia đều cho mã active (signal>0)\n",
    "    w_ticker = pd.Series(0.0, index=tickers, dtype=\"float32\")\n",
    "    for j, c in enumerate(clusters):\n",
    "        members = cluster_members[c]\n",
    "        if not members: continue\n",
    "        act_row = ACTIVE_test[c].iloc[i]  # mask của ngày dt\n",
    "        valid = [tk for tk in members if (tk in act_row.index and act_row[tk] > 0)]\n",
    "        if len(valid) >= MIN_NAMES_PER_CLUSTER:\n",
    "            share = w_c[j] / len(valid)\n",
    "            w_ticker.loc[valid] += share\n",
    "\n",
    "    # nếu không cụm nào active -> phân bổ đều toàn thị trường (đảm bảo sum=1)\n",
    "    ssum = float(w_ticker.sum())\n",
    "    if ssum <= 1e-12:\n",
    "        w_ticker[:] = 1.0 / len(w_ticker)\n",
    "    else:\n",
    "        w_ticker /= ssum\n",
    "\n",
    "    # lưu cluster weights (stream)\n",
    "    with open(cw_path, \"a\", newline=\"\") as f:\n",
    "        cw = csv.writer(f); cw.writerow([dt.strftime(\"%Y-%m-%d\")] + [float(x) for x in w_c])\n",
    "\n",
    "    # lợi nhuận ngày dt & phí turnover\n",
    "    r_vec = ret_wide.loc[dt, w_ticker.index].values.astype(\"float32\")\n",
    "    turnover = float(np.sum(np.abs(w_ticker.values - prev_w_ticker.values)))\n",
    "    fee = (COST_BPS/1e4) * turnover\n",
    "\n",
    "    r_net = float(np.dot(w_ticker.values, r_vec)) - fee\n",
    "    capital = capital * (1.0 + r_net)\n",
    "    portfolio_value.iloc[i] = capital\n",
    "\n",
    "    prev_w_ticker = w_ticker\n",
    "    if (i % 50) == 0:\n",
    "        gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "# ===== Benchmark (buy & hold VNINDEX) =====\n",
    "print(\"Fetching VNINDEX for benchmark (buy & hold)...\")\n",
    "client = FiinSession(username=\"DSTC_18@fiinquant.vn\", password=\"Fiinquant0606\").login()\n",
    "bench = client.Fetch_Trading_Data(\n",
    "    realtime=False, tickers=BENCHMARK_TKR, fields=['close'],\n",
    "    adjusted=True, by=\"1d\", from_date=str(dates.min().date())\n",
    ").get_data()\n",
    "bench[\"date\"] = pd.to_datetime(bench[\"timestamp\"])\n",
    "bench = bench.set_index(\"date\")[\"close\"].sort_index().reindex(dates).ffill().bfill()\n",
    "bench_ret = bench.pct_change().fillna(0.0)\n",
    "benchmark_value = (1 + bench_ret).cumprod() * INIT_CAPITAL\n",
    "\n",
    "# ===== Save outputs (gọn) =====\n",
    "portfolio_value.to_frame(\"portfolio_value\").to_csv(os.path.join(OUTPUT_DIR, \"portfolio_value_test.csv\"))\n",
    "benchmark_value.to_frame(\"benchmark_value\").to_csv(os.path.join(OUTPUT_DIR, \"benchmark_value_test.csv\"))\n",
    "\n",
    "print(\"✅ Done Block 10 (long-only, lag, turnover, cluster-DDPG, RAM-optimized).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1ea5e2",
   "metadata": {},
   "source": [
    "**code mới nhất nằm ngày trên**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1798fda1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8f1314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1957cc4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20116a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7dc72b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f49e0e1c",
   "metadata": {},
   "source": [
    "**BLOCK 10.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27593e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 10.5 — Save full results (DDPG inference artifacts)\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ===== Đường dẫn =====\n",
    "OUTPUT_DIR = \"./backtest_ddpg/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# 1. Lưu giá trị danh mục & benchmark (đã có trong Block 10)\n",
    "# -> portfolio_value.csv, benchmark_value.csv đã được lưu\n",
    "\n",
    "# 2. Lưu allocation theo từng ticker (tỷ trọng vốn mỗi ngày)\n",
    "weights_by_ticker_path = os.path.join(OUTPUT_DIR, \"weights_by_ticker.csv\")\n",
    "weights_df = pd.DataFrame(index=dates, columns=tickers, dtype=\"float32\")\n",
    "\n",
    "prev_w_ticker = pd.Series(0.0, index=tickers, dtype=\"float32\")\n",
    "capital = INIT_CAPITAL\n",
    "\n",
    "for i, dt in enumerate(dates):\n",
    "    # dùng state của ngày trước (action lag 1 step để chắc chắn không leak)\n",
    "    s_dt = dates[i-1] if i>0 else dates[i]\n",
    "    s = torch.from_numpy(S_test[i-1].astype(\"float32\") if i>0 else S_test[i].astype(\"float32\")).to(device).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        w_c = actor(s).cpu().numpy()[0].astype(\"float32\")\n",
    "    w_c = np.clip(w_c, 0, 1)\n",
    "    ssum = w_c.sum()\n",
    "    w_c = w_c/ssum if ssum>0 else np.ones_like(w_c)/len(w_c)\n",
    "\n",
    "    # phân bổ xuống ticker\n",
    "    w_ticker = pd.Series(0.0, index=tickers, dtype=\"float32\")\n",
    "    for j, c in enumerate(clusters):\n",
    "        members = cluster_members[c]\n",
    "        if not members: continue\n",
    "        act_row = ACTIVE_test[c].iloc[i]\n",
    "        valid = [tk for tk in members if (tk in act_row.index and act_row[tk] > 0)]\n",
    "        if len(valid) >= MIN_NAMES_PER_CLUSTER:\n",
    "            share = w_c[j] / len(valid)\n",
    "            w_ticker.loc[valid] += share\n",
    "\n",
    "    ssum = float(w_ticker.sum())\n",
    "    if ssum <= 1e-12:\n",
    "        w_ticker[:] = 1.0 / len(w_ticker)\n",
    "    else:\n",
    "        w_ticker /= ssum\n",
    "\n",
    "    # Lưu allocation\n",
    "    weights_df.loc[dt] = w_ticker\n",
    "\n",
    "# Ghi file\n",
    "weights_df.to_csv(weights_by_ticker_path)\n",
    "print(f\"✅ Saved ticker weights to {weights_by_ticker_path}\")\n",
    "\n",
    "# 3. Lưu daily returns (log lợi nhuận hàng ngày)\n",
    "returns = weights_df.shift(1).fillna(0.0).mul(ret_wide.loc[weights_df.index].values).sum(axis=1)\n",
    "returns.name = \"daily_return\"\n",
    "returns.to_csv(os.path.join(OUTPUT_DIR, \"returns.csv\"))\n",
    "print(\"✅ Saved daily returns\")\n",
    "\n",
    "# 4. Lưu log giao dịch (turnover)\n",
    "turnover_log = (weights_df.diff().abs().sum(axis=1))\n",
    "turnover_log.name = \"turnover\"\n",
    "turnover_log.to_csv(os.path.join(OUTPUT_DIR, \"trades_log.csv\"))\n",
    "print(\"✅ Saved trades log\")\n",
    "\n",
    "print(\"🎯 Done Block 10.5 — All DDPG inference artifacts saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209d678d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4dc5b470",
   "metadata": {},
   "source": [
    "**Block 11: Thống kê kết quả và vẽ biểu đồ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3329dda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Kết quả Test:\n",
      "Ngày bắt đầu                        2025-02-05\n",
      "Ngày kết thúc                       2025-09-29\n",
      "Giá trị cuối                      11690.494071\n",
      "ROI (%)                              17.104017\n",
      "Biến động (năm, %)                   28.069246\n",
      "Sharpe                                1.008656\n",
      "Sortino                               1.591649\n",
      "MaxDrawdown (%)                     -19.096715\n",
      "Tỷ lệ phiên thắng (%)                41.717791\n",
      "Số ngày                                    163\n",
      "Skewness                              0.511906\n",
      "Kurtosis                              1.987763\n",
      "Calmar                                 1.44777\n",
      "Giá trị cuối (VNINDEX)            13125.920558\n",
      "ROI VNINDEX (%)                      31.259206\n",
      "Chênh lệch so với VNINDEX (pp)      -14.155188\n",
      "InformationRatio                     -0.541155\n",
      "Alpha (daily)                         0.000426\n",
      "Beta                                  0.395968\n",
      "dtype: object\n",
      "\n",
      "📊 Stress Test (Trump áp thuế 46%):\n",
      "Ngày bắt đầu                        2025-03-26\n",
      "Ngày kết thúc                       2025-04-15\n",
      "Giá trị cuối                      12208.217189\n",
      "ROI (%)                              -3.607095\n",
      "Biến động (năm, %)                   53.411159\n",
      "Sharpe                               -0.989252\n",
      "Sortino                              -2.161474\n",
      "MaxDrawdown (%)                     -17.601508\n",
      "Tỷ lệ phiên thắng (%)                42.857143\n",
      "Số ngày                                     14\n",
      "Skewness                              0.275881\n",
      "Kurtosis                             -0.978011\n",
      "Calmar                               -2.748674\n",
      "Giá trị cuối (VNINDEX)             9670.607509\n",
      "ROI VNINDEX (%)                       -7.41277\n",
      "Chênh lệch so với VNINDEX (pp)        3.805675\n",
      "InformationRatio                      2.050711\n",
      "Alpha (daily)                         0.001597\n",
      "Beta                                  0.756845\n",
      "dtype: object\n",
      "\n",
      "📊 Trade stats:\n",
      "Turnover mean (daily)       0.349115\n",
      "Turnover median (daily)     0.010241\n",
      "Turnover max (daily)        1.959999\n",
      "Turnover annualized        87.976929\n",
      "dtype: float64\n",
      "\n",
      "📊 Regime performance:\n",
      "             mean       std  count    Sharpe\n",
      "regime                                      \n",
      "bear    -0.000931  0.024578     38 -0.601479\n",
      "bull     0.003127  0.016817     71  2.952161\n",
      "sideway -0.000065  0.012270     54 -0.084665\n",
      "\n",
      "✅ Block 11 hoàn tất. Stats saved: ./backtest_ddpg/stats_test.csv, Charts & files under: ./backtest_ddpg/\n"
     ]
    }
   ],
   "source": [
    "# Block 11 — Hiệu suất & Stress Test (Trump đánh thuế 46%)\n",
    "import os, numpy as np, pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "OUTPUT_DIR = \"./backtest_ddpg/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "STATS_FILE = os.path.join(OUTPUT_DIR, \"stats_test.csv\")\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def max_drawdown(series: pd.Series) -> float:\n",
    "    peak = series.cummax()\n",
    "    dd = (series / peak) - 1.0\n",
    "    return float(dd.min())\n",
    "\n",
    "def compute_stats(port_val: pd.Series, bench_val: pd.Series | None = None):\n",
    "    port_ret = port_val.pct_change().fillna(0.0)\n",
    "    stats = {\n",
    "        \"Ngày bắt đầu\": port_val.index.min().strftime(\"%Y-%m-%d\"),\n",
    "        \"Ngày kết thúc\": port_val.index.max().strftime(\"%Y-%m-%d\"),\n",
    "        \"Giá trị cuối\": float(port_val.iloc[-1]),\n",
    "        \"ROI (%)\": float((port_val.iloc[-1] / port_val.iloc[0] - 1.0) * 100),\n",
    "        \"Biến động (năm, %)\": float(port_ret.std() * np.sqrt(252) * 100),\n",
    "        \"Sharpe\": float((port_ret.mean() / port_ret.std()) * np.sqrt(252)) if port_ret.std() > 0 else 0,\n",
    "        \"Sortino\": float((port_ret.mean() / port_ret[port_ret < 0].std()) * np.sqrt(252)) if port_ret[port_ret < 0].std() > 0 else 0,\n",
    "        \"MaxDrawdown (%)\": float(max_drawdown(port_val) * 100),\n",
    "        \"Tỷ lệ phiên thắng (%)\": float((port_ret > 0).mean() * 100),\n",
    "        \"Số ngày\": int(len(port_ret))\n",
    "    }\n",
    "    if bench_val is not None and len(bench_val) > 1:\n",
    "        stats.update({\n",
    "            \"Giá trị cuối (VNINDEX)\": float(bench_val.iloc[-1]),\n",
    "            \"ROI VNINDEX (%)\": float((bench_val.iloc[-1] / bench_val.iloc[0] - 1.0) * 100),\n",
    "            \"Chênh lệch so với VNINDEX (pp)\": stats[\"ROI (%)\"] - ((bench_val.iloc[-1] / bench_val.iloc[0] - 1.0) * 100)\n",
    "        })\n",
    "    return stats\n",
    "\n",
    "def plot_equity(port_val, bench_val, title, path):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(port_val, label=\"Chiến lược\", linewidth=1.6)\n",
    "    if bench_val is not None:\n",
    "        plt.plot(bench_val, label=\"VNINDEX (Buy&Hold)\", linewidth=1.2)\n",
    "    plt.title(title); plt.legend(); plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(path, dpi=150); plt.close()\n",
    "\n",
    "def plot_hist(port_ret, title, path, bench_ret=None):\n",
    "    plt.figure(figsize=(9,5))\n",
    "    plt.hist(port_ret.dropna(), bins=50, alpha=0.6, label=\"Chiến lược\")\n",
    "    if bench_ret is not None:\n",
    "        plt.hist(bench_ret.dropna(), bins=50, alpha=0.6, label=\"VNINDEX\")\n",
    "    plt.title(title); plt.xlabel(\"Daily Return\"); plt.ylabel(\"Tần suất\")\n",
    "    plt.legend(); plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(path, dpi=150); plt.close()\n",
    "\n",
    "# ---------- Load kết quả ----------\n",
    "port_val = pd.read_csv(os.path.join(OUTPUT_DIR, \"portfolio_value_test.csv\"), index_col=0, parse_dates=True).iloc[:,0].sort_index()\n",
    "bench_val = pd.read_csv(os.path.join(OUTPUT_DIR, \"benchmark_value_test.csv\"), index_col=0, parse_dates=True).iloc[:,0].sort_index().reindex(port_val.index).ffill().bfill()\n",
    "returns = port_val.pct_change().fillna(0.0)\n",
    "bench_ret = bench_val.pct_change().fillna(0.0)\n",
    "\n",
    "# ---------- Stats (Test tổng thể) ----------\n",
    "stats_test = compute_stats(port_val, bench_val)\n",
    "\n",
    "# Equity + Histogram toàn kỳ\n",
    "plot_equity(port_val, bench_val, \"Equity Curve (Test)\", os.path.join(OUTPUT_DIR, \"equity_test.png\"))\n",
    "plot_hist(returns, \"Histogram lợi nhuận ngày (Test)\", os.path.join(OUTPUT_DIR, \"hist_test.png\"), bench_ret)\n",
    "\n",
    "# Drawdown toàn kỳ\n",
    "cum_ret = (1+returns).cumprod(); dd = cum_ret/cum_ret.cummax()-1\n",
    "plt.figure(figsize=(10,4)); plt.plot(dd, color=\"red\"); plt.title(\"Drawdown toàn kỳ\"); plt.grid(True,alpha=0.3)\n",
    "plt.savefig(os.path.join(OUTPUT_DIR,\"drawdown_test.png\")); plt.close()\n",
    "\n",
    "# Rolling Sharpe & Beta toàn kỳ\n",
    "window=60\n",
    "roll_sharpe = returns.rolling(window).mean()/returns.rolling(window).std()\n",
    "plt.figure(figsize=(10,4)); plt.plot(roll_sharpe,label=\"Rolling Sharpe (60d)\")\n",
    "plt.axhline(0,color=\"grey\",ls=\"--\"); plt.legend(); plt.grid(True,alpha=0.3)\n",
    "plt.title(\"Rolling Sharpe (toàn kỳ)\"); plt.savefig(os.path.join(OUTPUT_DIR,\"rolling_sharpe.png\")); plt.close()\n",
    "\n",
    "betas=[]\n",
    "for i in range(len(returns)-window):\n",
    "    y=returns.iloc[i:i+window]; x=bench_ret.iloc[i:i+window]\n",
    "    if x.std()==0: betas.append(np.nan); continue\n",
    "    X=sm.add_constant(x); model=sm.OLS(y,X).fit(); betas.append(model.params[1])\n",
    "roll_beta=pd.Series(betas,index=returns.index[window:])\n",
    "plt.figure(figsize=(10,4)); plt.plot(roll_beta,label=\"Rolling Beta (60d)\")\n",
    "plt.axhline(1,color=\"grey\",ls=\"--\"); plt.legend(); plt.grid(True,alpha=0.3)\n",
    "plt.title(\"Rolling Beta (toàn kỳ)\"); plt.savefig(os.path.join(OUTPUT_DIR,\"rolling_beta.png\")); plt.close()\n",
    "\n",
    "# ---------- Heatmap Monthly Return + số giao dịch + winrate ----------\n",
    "monthly = returns.resample(\"M\").agg([\"sum\",\"count\",lambda x:(x>0).mean()])\n",
    "monthly.columns=[\"Return\",\"Trades\",\"WinRate\"]\n",
    "pivot=monthly.pivot_table(values=\"Return\",index=monthly.index.year,columns=monthly.index.month)\n",
    "plt.figure(figsize=(12,6)); sns.heatmap(pivot,annot=True,fmt=\".2%\",cmap=\"RdYlGn\",center=0)\n",
    "plt.title(\"Heatmap lợi nhuận hàng tháng\"); plt.savefig(os.path.join(OUTPUT_DIR,\"heatmap_monthly.png\")); plt.close()\n",
    "monthly.to_csv(os.path.join(OUTPUT_DIR,\"monthly_stats.csv\"))\n",
    "\n",
    "# ---------- Stress Test ----------\n",
    "stress_start, stress_end = pd.Timestamp(\"2025-03-26\"), pd.Timestamp(\"2025-04-15\")\n",
    "stress_name = \"Trump thông báo đánh thuế 46% hàng hóa Việt Nam\"\n",
    "sub_port, sub_bench = port_val.loc[stress_start:stress_end], bench_val.loc[stress_start:stress_end]\n",
    "sub_ret=sub_port.pct_change().fillna(0.0)\n",
    "stats_stress={}\n",
    "if len(sub_port)>1:\n",
    "    stats_stress=compute_stats(sub_port,sub_bench)\n",
    "    plot_equity(sub_port,sub_bench,f\"Equity ({stress_name})\",os.path.join(OUTPUT_DIR,\"equity_stress.png\"))\n",
    "    plot_hist(sub_ret,f\"Histogram ({stress_name})\",os.path.join(OUTPUT_DIR,\"hist_stress.png\"))\n",
    "    # Drawdown so sánh benchmark\n",
    "    cum_p=(1+sub_ret).cumprod(); dd_p=cum_p/cum_p.cummax()-1\n",
    "    cum_b=(1+sub_bench.pct_change().fillna(0.0)).cumprod(); dd_b=cum_b/cum_b.cummax()-1\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(dd_p,label=\"Chiến lược\",color=\"red\"); plt.plot(dd_b,label=\"VNINDEX\",color=\"blue\")\n",
    "    plt.title(f\"Drawdown ({stress_name})\"); plt.legend(); plt.grid(True,alpha=0.3)\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR,\"drawdown_stress.png\")); plt.close()\n",
    "    # Rolling Sharpe\n",
    "    if len(sub_ret)>20:\n",
    "        rs=sub_ret.rolling(10).mean()/sub_ret.rolling(10).std()\n",
    "        plt.figure(figsize=(10,4)); plt.plot(rs,label=\"Rolling Sharpe (10d)\")\n",
    "        plt.axhline(0,color=\"grey\",ls=\"--\"); plt.legend(); plt.grid(True,alpha=0.3)\n",
    "        plt.title(f\"Rolling Sharpe ({stress_name})\"); plt.savefig(os.path.join(OUTPUT_DIR,\"rolling_sharpe_stress.png\")); plt.close()\n",
    "    # Rolling Beta\n",
    "    if len(sub_ret)>20:\n",
    "        beta_vals=[]; window=10; bench_r=sub_bench.pct_change().fillna(0.0)\n",
    "        for i in range(len(sub_ret)-window):\n",
    "            y=sub_ret.iloc[i:i+window]; x=bench_r.iloc[i:i+window]\n",
    "            X=sm.add_constant(x); model=sm.OLS(y,X).fit(); beta_vals.append(model.params[1])\n",
    "        rolling_beta=pd.Series(beta_vals,index=sub_ret.index[window:])\n",
    "        plt.figure(figsize=(10,4)); plt.plot(rolling_beta,label=\"Rolling Beta (10d)\")\n",
    "        plt.axhline(1,color=\"grey\",ls=\"--\"); plt.legend(); plt.grid(True,alpha=0.3)\n",
    "        plt.title(f\"Rolling Beta ({stress_name})\"); plt.savefig(os.path.join(OUTPUT_DIR,\"rolling_beta_stress.png\")); plt.close()\n",
    "\n",
    "# ---------- Top Holdings & Performance ----------\n",
    "weights_path = os.path.join(OUTPUT_DIR, \"ticker_weights_test.csv\")\n",
    "df_backtest_path = \"./backtest_ddpg/df_backtest.csv\"\n",
    "\n",
    "if os.path.exists(weights_path):\n",
    "    weights = pd.read_csv(weights_path, index_col=0, parse_dates=True)\n",
    "    mean_w=weights.mean().sort_values(ascending=False).head(10)\n",
    "    plt.figure(figsize=(10,6)); mean_w.plot(kind=\"bar\"); plt.title(\"Top 10 cổ phiếu phân bổ vốn cao nhất\"); plt.ylabel(\"Tỷ trọng\")\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR,\"top10_weights.png\")); plt.close()\n",
    "\n",
    "if os.path.exists(df_backtest_path):\n",
    "    df_backtest = pd.read_csv(df_backtest_path, parse_dates=[\"timestamp\"])\n",
    "    df_backtest = df_backtest.groupby([\"timestamp\",\"ticker\"],as_index=False).agg({\"close\":\"last\"})\n",
    "    px = df_backtest.pivot(index=\"timestamp\", columns=\"ticker\", values=\"close\").sort_index()\n",
    "    ret_wide = px.pct_change().fillna(0.0)\n",
    "    cum_ret_tk=(1+ret_wide).cumprod().iloc[-1]-1\n",
    "    top_gain=cum_ret_tk.sort_values(ascending=False).head(10)\n",
    "    top_loss=cum_ret_tk.sort_values().head(10)\n",
    "    plt.figure(figsize=(10,6)); top_gain.plot(kind=\"bar\",color=\"green\"); plt.title(\"Top 10 cổ phiếu lãi nhiều nhất\"); plt.savefig(os.path.join(OUTPUT_DIR,\"top10_gain.png\")); plt.close()\n",
    "    plt.figure(figsize=(10,6)); top_loss.plot(kind=\"bar\",color=\"red\"); plt.title(\"Top 10 cổ phiếu lỗ nhiều nhất\"); plt.savefig(os.path.join(OUTPUT_DIR,\"top10_loss.png\")); plt.close()\n",
    "\n",
    "# ---------- Save Stats ----------\n",
    "all_stats={\"Test\":stats_test}\n",
    "if stats_stress: all_stats[\"Stress Test\"]=stats_stress\n",
    "pd.DataFrame(all_stats).T.to_csv(STATS_FILE)\n",
    "\n",
    "print(\"📊 Kết quả Test:\"); print(pd.Series(stats_test))\n",
    "if stats_stress: print(f\"\\n📊 Stress Test ({stress_name}):\"); print(pd.Series(stats_stress))\n",
    "print(f\"\\n✅ Block 11 hoàn tất. Stats lưu tại: {STATS_FILE}, Charts in {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edd5497",
   "metadata": {},
   "source": [
    "**Block 12A: gửi tín hiệu lên telegram với dữ liệu quá khứ**\n",
    "\n",
    "`Lưu ý` tuy quá khứ nhưng nhóm không để bị nhìn trước tương lai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4ef6b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 12a — Hàm gửi tín hiệu Telegram (Offline replay, full version)\n",
    "\n",
    "import os, json, requests, time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "OUTPUT_DIR = \"./backtest_ddpg/\"\n",
    "\n",
    "# ==== Load config ====\n",
    "with open(\"config.json\",\"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "TG_TOKEN = cfg[\"telegram\"][\"bot_token\"]\n",
    "TG_CHAT_ID = cfg[\"telegram\"][\"chat_id\"]\n",
    "TG_THREAD_ID = cfg[\"telegram\"][\"message_thread_id\"]\n",
    "\n",
    "def send_daily_report(report_date: str | pd.Timestamp, sleep_sec:int=2):\n",
    "    \"\"\"\n",
    "    Gửi báo cáo Telegram cho 1 ngày bất kỳ trong backtest (offline replay).\n",
    "    - Hiển thị danh mục hiện tại (lọc tỷ trọng > 0)\n",
    "    - Hiển thị lệnh đóng hôm nay (PnL %)\n",
    "    - Hiển thị lệnh mở hôm nay (TP, SL, tỷ trọng)\n",
    "    - Gửi kèm chart equity\n",
    "    \"\"\"\n",
    "    report_date = pd.Timestamp(report_date)\n",
    "\n",
    "    # --- NAV ---\n",
    "    pv = pd.read_csv(os.path.join(OUTPUT_DIR,\"portfolio_value_test.csv\"), index_col=0, parse_dates=True).iloc[:,0]\n",
    "    if report_date not in pv.index:\n",
    "        print(f\"⚠️ {report_date.date()} không có trong NAV index\")\n",
    "        return\n",
    "    nav_today = pv.loc[:report_date].iloc[-1]\n",
    "\n",
    "    # --- Regime ---\n",
    "    regime_df = pd.read_csv(os.path.join(OUTPUT_DIR,\"regime_daily.csv\"), parse_dates=[\"date\"]).set_index(\"date\")\n",
    "    if report_date not in regime_df.index:\n",
    "        print(f\"⚠️ {report_date.date()} không có trong regime_daily.csv\")\n",
    "        return\n",
    "    row = regime_df.loc[report_date]\n",
    "    regime_today = row[\"regime\"]\n",
    "    cash_today = row[\"cash_buffer\"]\n",
    "\n",
    "    # --- Snapshot danh mục ---\n",
    "    snap_path = os.path.join(OUTPUT_DIR, f\"positions_snapshot_{report_date.date()}.csv\")\n",
    "    positions_txt = \"\"\n",
    "    if os.path.exists(snap_path):\n",
    "        pos = pd.read_csv(snap_path, parse_dates=[\"snapshot_date\",\"entry_date\"])\n",
    "        pos = pos[pos[\"position_size_pct\"] > 0]  # chỉ giữ vị thế còn vốn\n",
    "        if len(pos)>0:\n",
    "            for _,r in pos.iterrows():\n",
    "                positions_txt += (\n",
    "                    f\"— {r['ticker']}: Mua {r['entry_price']:.2f} ngày {r['entry_date'].date()}, \"\n",
    "                    f\"SL {r['sl_level']:.2f}, TP {r['tp_level']:.2f}, \"\n",
    "                    f\"Giá hiện {r['last_price']:.2f}, \"\n",
    "                    f\"Lãi/lỗ {r['current_unrealized_pct']:.2f}%, \"\n",
    "                    f\"Tỷ trọng {r['position_size_pct']*100:.1f}%\\n\"\n",
    "                )\n",
    "        else:\n",
    "            positions_txt = \"— Không có vị thế nào đang mở\\n\"\n",
    "    else:\n",
    "        positions_txt = \"— (Không tìm thấy snapshot)\\n\"\n",
    "\n",
    "    # --- Tín hiệu hôm đó ---\n",
    "    sig_path = os.path.join(OUTPUT_DIR, f\"signals_today_{report_date.date()}.csv\")\n",
    "    signals_txt, closed_txt, opened_txt = \"\", \"\", \"\"\n",
    "    if os.path.exists(sig_path):\n",
    "        sigs = pd.read_csv(sig_path, parse_dates=[\"entry_date\",\"exit_date\"])\n",
    "        if len(sigs)>0:\n",
    "            # Lệnh mở\n",
    "            opened = sigs[sigs[\"action\"]==\"BUY\"].copy()\n",
    "            if len(opened)>0:\n",
    "                for _,r in opened.iterrows():\n",
    "                    pos_size = r.get(\"position_size_pct\", 0.0) * 100\n",
    "                    opened_txt += (\n",
    "                        f\"— {r['ticker']}: Mua {r['entry_price']:.2f}, \"\n",
    "                        f\"TP {r['tp_level']:.2f}, SL {r['sl_level']:.2f}, \"\n",
    "                        f\"Tỷ trọng {pos_size:.1f}%\\n\"\n",
    "                    )\n",
    "            else:\n",
    "                opened_txt = \"— Không có lệnh mở nào\\n\"\n",
    "\n",
    "            # Lệnh đóng\n",
    "            closed = sigs[sigs[\"action\"]==\"SELL\"].copy()\n",
    "            if len(closed)>0:\n",
    "                for _,r in closed.iterrows():\n",
    "                    entry_price = r.get(\"entry_price\", None)\n",
    "                    exit_price  = r.get(\"exit_price\", None)\n",
    "                    pos_size    = r.get(\"position_size_pct\", 0.0) * 100\n",
    "                    if pd.notna(entry_price) and pd.notna(exit_price) and entry_price>0:\n",
    "                        pnl_pct = (exit_price/entry_price - 1)*100\n",
    "                    else:\n",
    "                        pnl_pct = float(\"nan\")\n",
    "                    closed_txt += (\n",
    "                        f\"— {r['ticker']}: Mua {entry_price:.2f} → \"\n",
    "                        f\"Bán {exit_price:.2f}, \"\n",
    "                        f\"{'Lãi' if pnl_pct>0 else 'Lỗ'} {pnl_pct:.2f}%, \"\n",
    "                        f\"Tỷ trọng {pos_size:.1f}%\\n\"\n",
    "                    )\n",
    "            else:\n",
    "                closed_txt = \"— Không có lệnh đóng nào\\n\"\n",
    "\n",
    "            # Tín hiệu gốc\n",
    "            for _,r in sigs.iterrows():\n",
    "                if r[\"action\"]==\"BUY\":\n",
    "                    signals_txt += (\n",
    "                        f\"🟢 MUA {r['ticker']} giá {r['entry_price']:.2f}, \"\n",
    "                        f\"TP {r['tp_level']:.2f}, SL {r['sl_level']:.2f}\\n\"\n",
    "                    )\n",
    "                else:\n",
    "                    exit_price = r[\"exit_price\"] if pd.notna(r[\"exit_price\"]) else 0.0\n",
    "                    signals_txt += (\n",
    "                        f\"🔴 BÁN {r['ticker']} giá {exit_price:.2f}, \"\n",
    "                        f\"loại {r.get('exit_type','NA')}\\n\"\n",
    "                    )\n",
    "        else:\n",
    "            signals_txt = \"— Không có tín hiệu giao dịch hôm nay\\n\"\n",
    "    else:\n",
    "        signals_txt = \"— (Không tìm thấy file tín hiệu)\\n\"\n",
    "        opened_txt = \"— (Không tìm thấy file tín hiệu)\\n\"\n",
    "        closed_txt = \"— (Không tìm thấy file tín hiệu)\\n\"\n",
    "\n",
    "    # --- Chart equity đến ngày đó ---\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(pv.loc[:report_date], label=\"Chiến lược\")\n",
    "    plt.title(f\"Equity đến {report_date.date()}\")\n",
    "    plt.grid(True, alpha=0.3); plt.legend()\n",
    "    chart_path = os.path.join(OUTPUT_DIR, f\"equity_until_{report_date.date()}.png\")\n",
    "    plt.savefig(chart_path, dpi=150); plt.close()\n",
    "\n",
    "    # --- Compose message ---\n",
    "    msg = f\"\"\"\n",
    "📅 Ngày {report_date.date()}\n",
    "\n",
    "💰 Giá trị tài sản: {nav_today:,.0f}\n",
    "💵 Tiền mặt: {cash_today*100:.1f}%\n",
    "📈 Chế độ thị trường: {regime_today}\n",
    "\n",
    "📊 Danh mục hiện tại:\n",
    "{positions_txt}\n",
    "\n",
    "💡 Lệnh đóng hôm nay:\n",
    "{closed_txt}\n",
    "\n",
    "🟢 Lệnh mở hôm nay:\n",
    "{opened_txt}\n",
    "\n",
    "📌 Tín hiệu trong ngày:\n",
    "{signals_txt}\n",
    "\"\"\".strip()\n",
    "\n",
    "    # --- Gửi text ---\n",
    "    send_url = f\"https://api.telegram.org/bot{TG_TOKEN}/sendMessage\"\n",
    "    requests.post(send_url, data={\n",
    "        \"chat_id\": TG_CHAT_ID,\n",
    "        \"message_thread_id\": TG_THREAD_ID,\n",
    "        \"text\": msg\n",
    "    })\n",
    "    time.sleep(sleep_sec)\n",
    "\n",
    "    # --- Gửi chart ---\n",
    "    photo_url = f\"https://api.telegram.org/bot{TG_TOKEN}/sendPhoto\"\n",
    "    with open(chart_path,\"rb\") as f:\n",
    "        requests.post(photo_url, data={\n",
    "            \"chat_id\": TG_CHAT_ID,\n",
    "            \"message_thread_id\": TG_THREAD_ID,\n",
    "            \"caption\": f\"Equity Curve đến {report_date.date()}\"\n",
    "        }, files={\"photo\":f})\n",
    "    time.sleep(sleep_sec)\n",
    "\n",
    "    print(f\"✅ Đã gửi báo cáo Telegram cho ngày {report_date.date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e98b3c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã gửi báo cáo Telegram cho ngày 2025-03-26\n",
      "✅ Đã gửi báo cáo Telegram cho ngày 2025-03-27\n",
      "✅ Đã gửi báo cáo Telegram cho ngày 2025-03-28\n",
      "⚠️ 2025-03-29 không có trong NAV index\n",
      "⚠️ 2025-03-30 không có trong NAV index\n",
      "✅ Đã gửi báo cáo Telegram cho ngày 2025-03-31\n",
      "✅ Đã gửi báo cáo Telegram cho ngày 2025-04-01\n",
      "✅ Đã gửi báo cáo Telegram cho ngày 2025-04-02\n",
      "✅ Đã gửi báo cáo Telegram cho ngày 2025-04-03\n",
      "✅ Đã gửi báo cáo Telegram cho ngày 2025-04-04\n",
      "⚠️ 2025-04-05 không có trong NAV index\n",
      "⚠️ 2025-04-06 không có trong NAV index\n",
      "⚠️ 2025-04-07 không có trong NAV index\n",
      "✅ Đã gửi báo cáo Telegram cho ngày 2025-04-08\n",
      "✅ Đã gửi báo cáo Telegram cho ngày 2025-04-09\n",
      "✅ Đã gửi báo cáo Telegram cho ngày 2025-04-10\n",
      "✅ Đã gửi báo cáo Telegram cho ngày 2025-04-11\n",
      "⚠️ 2025-04-12 không có trong NAV index\n",
      "⚠️ 2025-04-13 không có trong NAV index\n",
      "✅ Đã gửi báo cáo Telegram cho ngày 2025-04-14\n",
      "✅ Đã gửi báo cáo Telegram cho ngày 2025-04-15\n",
      "✅ Đã gửi báo cáo Telegram cho ngày 2025-04-16\n"
     ]
    }
   ],
   "source": [
    "# Cell runner — gửi báo cáo Telegram từ 26/03 đến 16/04/2025\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "start = pd.Timestamp(\"2025-03-26\")\n",
    "end   = pd.Timestamp(\"2025-04-16\")\n",
    "\n",
    "for d in pd.date_range(start, end, freq=\"D\"):\n",
    "    try:\n",
    "        send_daily_report(d, sleep_sec=10)  # sleep 2 giây giữa mỗi tin nhắn\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Lỗi khi gửi ngày {d.date()}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
