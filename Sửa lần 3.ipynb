{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5a2bf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số mã HOSE: 415\n",
      "Fetching data, it may take a while. Please wait...\n",
      "History ban đầu:   ticker         timestamp       open       high        low      close  \\\n",
      "0    AAA  2022-01-04 00:00  19302.030  20550.420  19302.030  19878.210   \n",
      "1    AAA  2022-01-05 00:00  19974.240  20934.540  19830.195  20118.285   \n",
      "2    AAA  2022-01-06 00:00  20070.270  21510.720  19974.240  21510.720   \n",
      "3    AAA  2022-01-07 00:00  22038.885  22230.945  21654.765  21894.840   \n",
      "4    AAA  2022-01-10 00:00  22086.900  22471.020  20406.375  20406.375   \n",
      "\n",
      "       volume         bu         sd            fs            fn  \n",
      "0   7354500.0  3727500.0  3474700.0  3.871515e+09  1.077420e+09  \n",
      "1   7187400.0  3248400.0  3816200.0  2.180410e+09 -1.785885e+09  \n",
      "2  12375600.0  5193100.0  6236500.0  2.383965e+09  1.195269e+10  \n",
      "3   7009900.0        0.0        0.0  5.174500e+09  3.160220e+09  \n",
      "4  11396800.0  5208000.0  5167700.0  9.241110e+09 -9.088565e+09  \n"
     ]
    }
   ],
   "source": [
    "# Block 1 — Login & Lấy dữ liệu tất cả HOSE/HNX/UPCOM\n",
    "import pandas as pd\n",
    "from FiinQuantX import FiinSession, BarDataUpdate\n",
    "\n",
    "# --- Login ---\n",
    "username = \"DSTC_18@fiinquant.vn\"\n",
    "password = \"Fiinquant0606\"\n",
    "\n",
    "client = FiinSession(\n",
    "    username=username,\n",
    "    password=password\n",
    ").login()\n",
    "\n",
    "# --- Lấy danh sách cổ phiếu từng sàn ---\n",
    "tickers_hose  = list(client.TickerList(ticker=\"VNINDEX\"))     # HOSE\n",
    "print(f\"Số mã HOSE: {len(tickers_hose)}\")\n",
    "\n",
    "# --- Lấy dữ liệu lịch sử toàn bộ (có thể nặng, nên lấy theo batch nếu cần) ---\n",
    "event_history = client.Fetch_Trading_Data(\n",
    "    realtime=False,\n",
    "    tickers=tickers_hose,\n",
    "    fields=['open','high','low','close','volume','bu','sd','fs','fn'], \n",
    "    adjusted=True,\n",
    "    by=\"1d\",\n",
    "    from_date=\"2022-01-01\"   # backtest từ 2022 tới nay\n",
    ")\n",
    "\n",
    "df_all = event_history.get_data()\n",
    "print(\"History ban đầu:\", df_all.head())\n",
    "\n",
    "# --- Callback realtime ---\n",
    "def onDataUpdate(data: BarDataUpdate):\n",
    "    global df_all\n",
    "    df_update = data.to_dataFrame()\n",
    "    df_all = pd.concat([df_all, df_update])\n",
    "    df_all = df_all.drop_duplicates()\n",
    "    print(\"Realtime update:\")\n",
    "    print(df_update.head())\n",
    "\n",
    "# --- Bật realtime nối tiếp dữ liệu ---\n",
    "event_realtime = client.Fetch_Trading_Data(\n",
    "    realtime=True,\n",
    "    tickers=tickers_hose,\n",
    "    fields=['open','high','low','close','volume','bu','sd','fs','fn'], \n",
    "    adjusted=True,\n",
    "    by=\"1d\",\n",
    "    period=1,\n",
    "    callback=onDataUpdate\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c93b463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Lỗi khi lấy FA cho FUETPVND: 'FUETPVND'\n",
      "Số mã HOSE ban đầu: 415\n",
      "Số mã có dữ liệu FA: 392\n",
      "FA Data sample:\n",
      "   organizationId ticker  year  quarter  \\\n",
      "0          894364    CCC  2023        4   \n",
      "1          894364    CCC  2024        1   \n",
      "2          894364    CCC  2024        2   \n",
      "3          894364    CCC  2024        3   \n",
      "4          894364    CCC  2024        4   \n",
      "\n",
      "                                              ratios ReportDate  \n",
      "0  {'SolvencyRatio': {'DebtToEquityRatio': 1.5102...        NaT  \n",
      "1  {'SolvencyRatio': {'DebtToEquityRatio': 0.7722...        NaT  \n",
      "2  {'SolvencyRatio': {'DebtToEquityRatio': 0.7357...        NaT  \n",
      "3  {'SolvencyRatio': {'DebtToEquityRatio': 0.7914...        NaT  \n",
      "4  {'SolvencyRatio': {'DebtToEquityRatio': 0.6437...        NaT  \n"
     ]
    }
   ],
   "source": [
    "# Block 2 — Lấy dữ liệu FA theo quý (HOSE only)\n",
    "\n",
    "def fetch_fa_quarterly(ticker, latest_year=2025, n_periods=32):\n",
    "    try:\n",
    "        fi_list = client.FundamentalAnalysis().get_ratios(\n",
    "            tickers=[ticker],\n",
    "            TimeFilter=\"Quarterly\",\n",
    "            LatestYear=latest_year,\n",
    "            NumberOfPeriod=n_periods,\n",
    "            Consolidated=True\n",
    "        )\n",
    "\n",
    "        # Nếu không có dữ liệu thì bỏ qua\n",
    "        if not fi_list or not isinstance(fi_list, list):\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        df = pd.DataFrame(fi_list)\n",
    "        if df.empty:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        df[\"ticker\"] = ticker\n",
    "        if \"ReportDate\" in df.columns:\n",
    "            df[\"ReportDate\"] = pd.to_datetime(df[\"ReportDate\"])\n",
    "        else:\n",
    "            # Nếu không có ReportDate thì tạo cột null để tránh lỗi concat\n",
    "            df[\"ReportDate\"] = pd.NaT\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Lỗi khi lấy FA cho {ticker}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "# --- Lọc danh sách: chỉ giữ những mã có dữ liệu FA ---\n",
    "fa_list = []\n",
    "valid_tickers = []\n",
    "\n",
    "for t in tickers_hose:   # lấy theo danh sách HOSE từ Block 1\n",
    "    df_fa = fetch_fa_quarterly(t, latest_year=2025, n_periods=32)\n",
    "    if not df_fa.empty:\n",
    "        fa_list.append(df_fa)\n",
    "        valid_tickers.append(t)\n",
    "\n",
    "# --- Gộp DataFrame ---\n",
    "if fa_list:\n",
    "    fa_data = pd.concat(fa_list, ignore_index=True)\n",
    "else:\n",
    "    fa_data = pd.DataFrame()\n",
    "\n",
    "print(f\"Số mã HOSE ban đầu: {len(tickers_hose)}\")\n",
    "print(f\"Số mã có dữ liệu FA: {len(valid_tickers)}\")\n",
    "print(\"FA Data sample:\")\n",
    "print(fa_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "831a3096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample merged:\n",
      "  ticker  timestamp       open       high        low      close      volume  \\\n",
      "0    AAA 2022-01-04  19302.030  20550.420  19302.030  19878.210   7354500.0   \n",
      "1    AAA 2022-01-05  19974.240  20934.540  19830.195  20118.285   7187400.0   \n",
      "2    AAA 2022-01-06  20070.270  21510.720  19974.240  21510.720  12375600.0   \n",
      "3    AAA 2022-01-07  22038.885  22230.945  21654.765  21894.840   7009900.0   \n",
      "4    AAA 2022-01-10  22086.900  22471.020  20406.375  20406.375  11396800.0   \n",
      "\n",
      "          bu         sd            fs  ...  DebtToEquityRatio  EBITMargin  \\\n",
      "0  3727500.0  3474700.0  3.871515e+09  ...           0.613528    0.016455   \n",
      "1  3248400.0  3816200.0  2.180410e+09  ...           0.613528    0.016455   \n",
      "2  5193100.0  6236500.0  2.383965e+09  ...           0.613528    0.016455   \n",
      "3        0.0        0.0  5.174500e+09  ...           0.613528    0.016455   \n",
      "4  5208000.0  5167700.0  9.241110e+09  ...           0.613528    0.016455   \n",
      "\n",
      "        ROA      ROE      ROIC    BasicEPS  PriceToBook  PriceToEarning  \\\n",
      "0  0.031244  0.06917  0.044605  185.389629     0.905535       13.822477   \n",
      "1  0.031244  0.06917  0.044605  185.389629     0.905535       13.822477   \n",
      "2  0.031244  0.06917  0.044605  185.389629     0.905535       13.822477   \n",
      "3  0.031244  0.06917  0.044605  185.389629     0.905535       13.822477   \n",
      "4  0.031244  0.06917  0.044605  185.389629     0.905535       13.822477   \n",
      "\n",
      "   NetRevenueGrowthYoY  GrossProfitGrowthYoY  \n",
      "0             0.982026              0.833824  \n",
      "1             0.982026              0.833824  \n",
      "2             0.982026              0.833824  \n",
      "3             0.982026              0.833824  \n",
      "4             0.982026              0.833824  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "Số mã merge thành công: 391\n"
     ]
    }
   ],
   "source": [
    "# Block 3 — Chuẩn hoá FA + Merge với giá (HOSE only, dựa theo Block 2)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# --- Các chỉ số FA cần lấy ---\n",
    "fa_fields = [\n",
    "    \"DebtToEquityRatio\",\"EBITMargin\",\"ROA\",\"ROE\",\"ROIC\",\n",
    "    \"BasicEPS\",\"PriceToBook\",\"PriceToEarning\",\n",
    "    \"NetRevenueGrowthYoY\",\"GrossProfitGrowthYoY\"\n",
    "]\n",
    "\n",
    "# --- Hàm nổ ratios ---\n",
    "def explode_ratios(df, fa_fields):\n",
    "    records = []\n",
    "    for _, row in df.iterrows():\n",
    "        d = {\n",
    "            \"ticker\": row[\"ticker\"],\n",
    "            \"fa_year\": int(row[\"year\"]),\n",
    "            \"fa_quarter\": int(row[\"quarter\"])\n",
    "        }\n",
    "        ratios = row.get(\"ratios\", {})\n",
    "        if isinstance(ratios, dict):   # ✅ fix chỗ lỗi\n",
    "            for f in fa_fields:\n",
    "                val = None\n",
    "                for section in ratios.values():\n",
    "                    if isinstance(section, dict) and f in section:\n",
    "                        val = section[f]\n",
    "                d[f] = val\n",
    "        else:\n",
    "            # nếu ratios không phải dict thì gán NaN hết\n",
    "            for f in fa_fields:\n",
    "                d[f] = None\n",
    "        records.append(d)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# --- Chuẩn hoá FA ---\n",
    "fa_clean = explode_ratios(fa_data, fa_fields)\n",
    "\n",
    "# --- Chuẩn hoá giá ---\n",
    "df_price = df_all[df_all[\"ticker\"].isin(valid_tickers)].copy()\n",
    "df_price[\"timestamp\"] = pd.to_datetime(df_price[\"timestamp\"])\n",
    "df_price = df_price.sort_values([\"ticker\",\"timestamp\"])\n",
    "\n",
    "# tạo key (fa_year, fa_quarter) = quý trước\n",
    "pi = df_price[\"timestamp\"].dt.to_period(\"Q\")\n",
    "prev_pi = pi - 1\n",
    "df_price[\"fa_year\"] = prev_pi.dt.year.astype(int)\n",
    "df_price[\"fa_quarter\"] = prev_pi.dt.quarter.astype(int)\n",
    "\n",
    "# --- Xử lý FA: giữ duy nhất bản cuối cùng mỗi quý\n",
    "fa_clean = (\n",
    "    fa_clean.sort_values([\"ticker\",\"fa_year\",\"fa_quarter\"])\n",
    "            .drop_duplicates(subset=[\"ticker\",\"fa_year\",\"fa_quarter\"], keep=\"last\")\n",
    ")\n",
    "\n",
    "# --- Merge giá + FA ---\n",
    "df_merged = df_price.merge(\n",
    "    fa_clean,\n",
    "    on=[\"ticker\",\"fa_year\",\"fa_quarter\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# FFill theo thời gian trong từng ticker để lấp chỗ trống\n",
    "df_merged = df_merged.sort_values([\"ticker\",\"timestamp\"])\n",
    "df_merged[fa_fields] = df_merged.groupby(\"ticker\")[fa_fields].ffill()\n",
    "\n",
    "print(\"Sample merged:\")\n",
    "print(df_merged.head())\n",
    "print(\"Số mã merge thành công:\", df_merged[\"ticker\"].nunique())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b0de3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample with TA:\n",
      "  ticker  timestamp       open       high        low      close      volume  \\\n",
      "0    AAA 2022-01-04  19302.030  20550.420  19302.030  19878.210   7354500.0   \n",
      "1    AAA 2022-01-05  19974.240  20934.540  19830.195  20118.285   7187400.0   \n",
      "2    AAA 2022-01-06  20070.270  21510.720  19974.240  21510.720  12375600.0   \n",
      "3    AAA 2022-01-07  22038.885  22230.945  21654.765  21894.840   7009900.0   \n",
      "4    AAA 2022-01-10  22086.900  22471.020  20406.375  20406.375  11396800.0   \n",
      "\n",
      "          bu         sd            fs  ...  ema_50  macd  macd_signal  \\\n",
      "0  3727500.0  3474700.0  3.871515e+09  ...     NaN   NaN          NaN   \n",
      "1  3248400.0  3816200.0  2.180410e+09  ...     NaN   NaN          NaN   \n",
      "2  5193100.0  6236500.0  2.383965e+09  ...     NaN   NaN          NaN   \n",
      "3        0.0        0.0  5.174500e+09  ...     NaN   NaN          NaN   \n",
      "4  5208000.0  5167700.0  9.241110e+09  ...     NaN   NaN          NaN   \n",
      "\n",
      "   macd_diff  rsi  bollinger_hband  bollinger_lband  atr         obv  vwap  \n",
      "0        NaN  NaN              NaN              NaN  NaN   7354500.0   NaN  \n",
      "1        NaN  NaN              NaN              NaN  NaN  14541900.0   NaN  \n",
      "2        NaN  NaN              NaN              NaN  NaN  26917500.0   NaN  \n",
      "3        NaN  NaN              NaN              NaN  NaN  33927400.0   NaN  \n",
      "4        NaN  NaN              NaN              NaN  NaN  22530600.0   NaN  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "Shape sau khi thêm TA: (351453, 35)\n"
     ]
    }
   ],
   "source": [
    "# Block 4 — Tính các chỉ số TA (trên df_merged từ Block 3)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# --- Khởi tạo Indicator ---\n",
    "fi = client.FiinIndicator()\n",
    "\n",
    "# --- Hàm tính TA theo từng ticker ---\n",
    "def add_ta_indicators(df):\n",
    "    df = df.sort_values(\"timestamp\").copy()\n",
    "\n",
    "    # EMA\n",
    "    df['ema_5']  = fi.ema(df['close'], window=5)\n",
    "    df['ema_20'] = fi.ema(df['close'], window=20)\n",
    "    df['ema_50'] = fi.ema(df['close'], window=50)\n",
    "\n",
    "    # MACD\n",
    "    df['macd']        = fi.macd(df['close'], window_fast=12, window_slow=26)\n",
    "    df['macd_signal'] = fi.macd_signal(df['close'], window_fast=12, window_slow=26, window_sign=9)\n",
    "    df['macd_diff']   = fi.macd_diff(df['close'], window_fast=12, window_slow=26, window_sign=9)\n",
    "\n",
    "    # RSI\n",
    "    df['rsi'] = fi.rsi(df['close'], window=14)\n",
    "\n",
    "    # Bollinger Bands\n",
    "    df['bollinger_hband'] = fi.bollinger_hband(df['close'], window=20, window_dev=2)\n",
    "    df['bollinger_lband'] = fi.bollinger_lband(df['close'], window=20, window_dev=2)\n",
    "\n",
    "    # ATR\n",
    "    df['atr'] = fi.atr(df['high'], df['low'], df['close'], window=14)\n",
    "\n",
    "    # OBV\n",
    "    df['obv'] = fi.obv(df['close'], df['volume'])\n",
    "\n",
    "    # VWAP\n",
    "    df['vwap'] = fi.vwap(df['high'], df['low'], df['close'], df['volume'], window=14)\n",
    "\n",
    "    return df\n",
    "\n",
    "# --- Áp dụng cho toàn bộ df_merged ---\n",
    "df_with_ta = df_merged.groupby(\"ticker\", group_keys=False).apply(add_ta_indicators)\n",
    "\n",
    "print(\"Sample with TA:\")\n",
    "print(df_with_ta.head())\n",
    "print(\"Shape sau khi thêm TA:\", df_with_ta.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbd7f105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample features:\n",
      "  ticker  timestamp  DebtToEquityRatio  EBITMargin       ROA       ROE  \\\n",
      "0    AAA 2022-06-15           0.864203    0.997114  0.368342  0.987969   \n",
      "1    AAA 2022-06-16           0.864203    0.997114  0.368342  0.987969   \n",
      "2    AAA 2022-06-17           0.864203    0.997114  0.368342  0.987969   \n",
      "3    AAA 2022-06-20           0.864203    0.997114  0.368342  0.987969   \n",
      "4    AAA 2022-06-21           0.864203    0.997114  0.368342  0.987969   \n",
      "\n",
      "       ROIC  BasicEPS  PriceToBook  PriceToEarning  ...  ema_50_z    macd_z  \\\n",
      "0  0.935557  0.144912     0.024681         0.19159  ... -1.537094  0.524295   \n",
      "1  0.935557  0.144912     0.024681         0.19159  ... -1.516392  0.494055   \n",
      "2  0.935557  0.144912     0.024681         0.19159  ... -1.511681  0.369820   \n",
      "3  0.935557  0.144912     0.024681         0.19159  ... -1.519197  0.188197   \n",
      "4  0.935557  0.144912     0.024681         0.19159  ... -1.510095  0.161472   \n",
      "\n",
      "   macd_signal_z  macd_diff_z     rsi_z  bollinger_hband_z  bollinger_lband_z  \\\n",
      "0       0.417864     0.363564  0.075104          -1.477430          -0.586666   \n",
      "1       0.444040     0.226141  0.049778          -1.422727          -0.561535   \n",
      "2       0.437887    -0.073867 -0.478265          -1.323034          -0.631196   \n",
      "3       0.393332    -0.426949 -0.828585          -1.195273          -0.759600   \n",
      "4       0.351995    -0.399987 -0.047044          -1.137571          -0.791685   \n",
      "\n",
      "      atr_z     obv_z    vwap_z  \n",
      "0 -0.655469 -0.647056 -0.940665  \n",
      "1 -0.894025 -0.767575 -0.922774  \n",
      "2 -0.775115 -1.058373 -0.941949  \n",
      "3 -0.576312 -1.246037 -0.956317  \n",
      "4 -0.463707 -1.019660 -0.962541  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "Shape sau khi scaling & dropna: (264469, 24)\n"
     ]
    }
   ],
   "source": [
    "# Block 5 — Feature engineering & scaling\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# --- Danh sách cột FA & TA ---\n",
    "fa_features = [\n",
    "    \"DebtToEquityRatio\",\"EBITMargin\",\"ROA\",\"ROE\",\"ROIC\",\n",
    "    \"BasicEPS\",\"PriceToBook\",\"PriceToEarning\",\n",
    "    \"NetRevenueGrowthYoY\",\"GrossProfitGrowthYoY\"\n",
    "]\n",
    "\n",
    "ta_features = [\n",
    "    \"ema_5\",\"ema_20\",\"ema_50\",\"macd\",\"macd_signal\",\"macd_diff\",\n",
    "    \"rsi\",\"bollinger_hband\",\"bollinger_lband\",\"atr\",\"obv\",\"vwap\"\n",
    "]\n",
    "\n",
    "# --- Chuẩn hoá FA: cross-section min-max scaling theo ngày ---\n",
    "def scale_fa_minmax(df):\n",
    "    df_scaled = df.copy()\n",
    "    for f in fa_features:\n",
    "        vals = df[f].astype(float)\n",
    "        vmin, vmax = vals.min(), vals.max()\n",
    "        if np.isfinite(vmin) and np.isfinite(vmax) and vmax > vmin:\n",
    "            df_scaled[f] = (vals - vmin) / (vmax - vmin)\n",
    "        else:\n",
    "            df_scaled[f] = np.nan\n",
    "    return df_scaled\n",
    "\n",
    "df_scaled_fa = df_with_ta.groupby(\"timestamp\", group_keys=False).apply(scale_fa_minmax)\n",
    "\n",
    "# --- Chuẩn hoá TA: rolling z-score theo từng ticker ---\n",
    "def zscore_rolling(series, window=60):\n",
    "    return (series - series.rolling(window).mean()) / series.rolling(window).std()\n",
    "\n",
    "df_scaled = df_scaled_fa.groupby(\"ticker\", group_keys=False).apply(\n",
    "    lambda g: g.assign(**{f\"{col}_z\": zscore_rolling(g[col], 60) for col in ta_features})\n",
    ")\n",
    "\n",
    "# --- Drop các cột gốc TA, giữ bản z-score ---\n",
    "keep_cols = [\"ticker\",\"timestamp\"] + fa_features + [f\"{col}_z\" for col in ta_features]\n",
    "df_features = df_scaled[keep_cols].dropna().reset_index(drop=True)\n",
    "\n",
    "print(\"Sample features:\")\n",
    "print(df_features.head())\n",
    "print(\"Shape sau khi scaling & dropna:\", df_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "466d47e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 255, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster sample:\n",
      "  ticker  timestamp  cluster     tsne_x     tsne_y    month\n",
      "0    AAA 2022-06-15       -1 -17.608253 -20.577604  2022-06\n",
      "1    AAA 2022-06-16       -1 -17.507252 -20.379070  2022-06\n",
      "2    AAA 2022-06-17       -1 -15.360531 -20.337601  2022-06\n",
      "3    AAA 2022-06-20       -1  -4.166707   1.878922  2022-06\n",
      "4    AAA 2022-06-21       -1 -18.837034 -15.488154  2022-06\n",
      "Số cụm mỗi tháng:\n",
      "month\n",
      "2022-06     13\n",
      "2022-07     69\n",
      "2022-08     69\n",
      "2022-09     49\n",
      "2022-10     54\n",
      "2022-11     56\n",
      "2022-12     64\n",
      "2023-01     45\n",
      "2023-02     64\n",
      "2023-03    139\n",
      "2023-04     68\n",
      "2023-05     84\n",
      "2023-06     73\n",
      "2023-07     76\n",
      "2023-08     76\n",
      "2023-09     45\n",
      "2023-10     77\n",
      "2023-11     60\n",
      "2023-12     89\n",
      "2024-01     95\n",
      "2024-02     34\n",
      "2024-03     64\n",
      "2024-04     51\n",
      "2024-05     67\n",
      "2024-06     96\n",
      "2024-07     97\n",
      "2024-08     69\n",
      "2024-09     94\n",
      "2024-10    116\n",
      "2024-11     91\n",
      "2024-12     86\n",
      "2025-01     57\n",
      "2025-02     76\n",
      "2025-03     90\n",
      "2025-04     48\n",
      "2025-05     77\n",
      "2025-06    109\n",
      "2025-07    106\n",
      "2025-08     76\n",
      "Name: cluster, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Block 6 — Dimensionality reduction & Clustering (t-SNE + DBSCAN)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# --- Chọn các cột features để clustering ---\n",
    "feature_cols = [\n",
    "    \"DebtToEquityRatio\",\"EBITMargin\",\"ROA\",\"ROE\",\"ROIC\",\n",
    "    \"BasicEPS\",\"PriceToBook\",\"PriceToEarning\",\n",
    "    \"NetRevenueGrowthYoY\",\"GrossProfitGrowthYoY\"\n",
    "] + [c for c in df_features.columns if c.endswith(\"_z\")]\n",
    "\n",
    "# --- Thêm cột tháng để snapshot ---\n",
    "df_features[\"month\"] = df_features[\"timestamp\"].dt.to_period(\"M\")\n",
    "\n",
    "cluster_results = []\n",
    "\n",
    "for (month, g) in df_features.groupby(\"month\"):\n",
    "    if len(g) < 10:   # quá ít cổ phiếu thì bỏ\n",
    "        continue\n",
    "\n",
    "    X = g[feature_cols].values\n",
    "\n",
    "    # --- t-SNE giảm chiều còn 2D ---\n",
    "    tsne = TSNE(n_components=2, perplexity=30, learning_rate=\"auto\", init=\"random\", random_state=42)\n",
    "    X_emb = tsne.fit_transform(X)\n",
    "\n",
    "    # --- DBSCAN clustering ---\n",
    "    db = DBSCAN(eps=0.5, min_samples=5).fit(X_emb)\n",
    "    labels = db.labels_\n",
    "\n",
    "    temp = g[[\"ticker\",\"timestamp\"]].copy()\n",
    "    temp[\"cluster\"] = labels\n",
    "    temp[\"tsne_x\"] = X_emb[:,0]\n",
    "    temp[\"tsne_y\"] = X_emb[:,1]\n",
    "    temp[\"month\"]  = str(month)\n",
    "\n",
    "    cluster_results.append(temp)\n",
    "\n",
    "df_clusters = pd.concat(cluster_results, ignore_index=True)\n",
    "\n",
    "print(\"Cluster sample:\")\n",
    "print(df_clusters.head())\n",
    "print(\"Số cụm mỗi tháng:\")\n",
    "print(df_clusters.groupby(\"month\")[\"cluster\"].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3fbcd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: tensor (773, 30, 22, 22), mask (773, 30, 22, 22)\n",
      "Cluster 1: tensor (773, 30, 23, 22), mask (773, 30, 23, 22)\n",
      "Cluster 2: tensor (773, 30, 20, 22), mask (773, 30, 20, 22)\n",
      "Cluster 3: tensor (773, 30, 22, 22), mask (773, 30, 22, 22)\n",
      "Cluster 4: tensor (773, 30, 31, 22), mask (773, 30, 31, 22)\n",
      "Cluster 5: tensor (773, 30, 25, 22), mask (773, 30, 25, 22)\n",
      "Cluster 6: tensor (773, 30, 33, 22), mask (773, 30, 33, 22)\n",
      "Cluster 7: tensor (773, 30, 31, 22), mask (773, 30, 31, 22)\n",
      "Cluster 8: tensor (773, 30, 30, 22), mask (773, 30, 30, 22)\n",
      "Cluster 9: tensor (773, 30, 30, 22), mask (773, 30, 30, 22)\n",
      "Cluster 10: tensor (773, 30, 34, 22), mask (773, 30, 34, 22)\n",
      "Cluster 11: tensor (773, 30, 35, 22), mask (773, 30, 35, 22)\n",
      "Cluster 12: tensor (773, 30, 34, 22), mask (773, 30, 34, 22)\n",
      "Cluster 13: tensor (773, 30, 33, 22), mask (773, 30, 33, 22)\n",
      "Cluster 14: tensor (773, 30, 32, 22), mask (773, 30, 32, 22)\n",
      "Cluster 15: tensor (773, 30, 36, 22), mask (773, 30, 36, 22)\n",
      "Cluster 16: tensor (773, 30, 38, 22), mask (773, 30, 38, 22)\n",
      "Cluster 17: tensor (773, 30, 37, 22), mask (773, 30, 37, 22)\n",
      "Cluster 18: tensor (773, 30, 41, 22), mask (773, 30, 41, 22)\n",
      "Cluster 19: tensor (773, 30, 39, 22), mask (773, 30, 39, 22)\n",
      "Cluster 20: tensor (773, 30, 38, 22), mask (773, 30, 38, 22)\n",
      "Cluster 21: tensor (773, 30, 34, 22), mask (773, 30, 34, 22)\n",
      "Cluster 22: tensor (773, 30, 40, 22), mask (773, 30, 40, 22)\n",
      "Cluster 23: tensor (773, 30, 38, 22), mask (773, 30, 38, 22)\n",
      "Cluster 24: tensor (773, 30, 35, 22), mask (773, 30, 35, 22)\n",
      "Cluster 25: tensor (773, 30, 38, 22), mask (773, 30, 38, 22)\n",
      "Cluster 26: tensor (773, 30, 37, 22), mask (773, 30, 37, 22)\n",
      "Cluster 27: tensor (773, 30, 33, 22), mask (773, 30, 33, 22)\n",
      "Cluster 28: tensor (773, 30, 36, 22), mask (773, 30, 36, 22)\n",
      "Cluster 29: tensor (773, 30, 39, 22), mask (773, 30, 39, 22)\n",
      "Cluster 30: tensor (773, 30, 35, 22), mask (773, 30, 35, 22)\n",
      "Cluster 31: tensor (773, 30, 34, 22), mask (773, 30, 34, 22)\n",
      "Cluster 32: tensor (773, 30, 37, 22), mask (773, 30, 37, 22)\n",
      "Cluster 33: tensor (773, 30, 36, 22), mask (773, 30, 36, 22)\n",
      "Cluster 34: tensor (773, 30, 38, 22), mask (773, 30, 38, 22)\n",
      "Cluster 35: tensor (773, 30, 35, 22), mask (773, 30, 35, 22)\n",
      "Cluster 36: tensor (773, 30, 33, 22), mask (773, 30, 33, 22)\n",
      "Cluster 37: tensor (773, 30, 34, 22), mask (773, 30, 34, 22)\n",
      "Cluster 38: tensor (773, 30, 36, 22), mask (773, 30, 36, 22)\n",
      "Cluster 39: tensor (773, 30, 37, 22), mask (773, 30, 37, 22)\n",
      "Cluster 40: tensor (773, 30, 38, 22), mask (773, 30, 38, 22)\n",
      "Cluster 41: tensor (773, 30, 41, 22), mask (773, 30, 41, 22)\n",
      "Cluster 42: tensor (773, 30, 38, 22), mask (773, 30, 38, 22)\n",
      "Cluster 43: tensor (773, 30, 37, 22), mask (773, 30, 37, 22)\n",
      "Cluster 44: tensor (773, 30, 36, 22), mask (773, 30, 36, 22)\n",
      "Cluster 45: tensor (773, 30, 35, 22), mask (773, 30, 35, 22)\n",
      "Cluster 46: tensor (773, 30, 34, 22), mask (773, 30, 34, 22)\n",
      "Cluster 47: tensor (773, 30, 29, 22), mask (773, 30, 29, 22)\n",
      "Cluster 48: tensor (773, 30, 30, 22), mask (773, 30, 30, 22)\n",
      "Cluster 49: tensor (773, 30, 36, 22), mask (773, 30, 36, 22)\n",
      "Cluster 50: tensor (773, 30, 30, 22), mask (773, 30, 30, 22)\n",
      "Cluster 51: tensor (773, 30, 35, 22), mask (773, 30, 35, 22)\n",
      "Cluster 52: tensor (773, 30, 31, 22), mask (773, 30, 31, 22)\n",
      "Cluster 53: tensor (773, 30, 32, 22), mask (773, 30, 32, 22)\n",
      "Cluster 54: tensor (773, 30, 30, 22), mask (773, 30, 30, 22)\n",
      "Cluster 55: tensor (773, 30, 28, 22), mask (773, 30, 28, 22)\n",
      "Cluster 56: tensor (773, 30, 27, 22), mask (773, 30, 27, 22)\n",
      "Cluster 57: tensor (773, 30, 26, 22), mask (773, 30, 26, 22)\n",
      "Cluster 58: tensor (773, 30, 28, 22), mask (773, 30, 28, 22)\n",
      "Cluster 59: tensor (773, 30, 25, 22), mask (773, 30, 25, 22)\n",
      "Cluster 60: tensor (773, 30, 29, 22), mask (773, 30, 29, 22)\n",
      "Cluster 61: tensor (773, 30, 28, 22), mask (773, 30, 28, 22)\n",
      "Cluster 62: tensor (773, 30, 28, 22), mask (773, 30, 28, 22)\n",
      "Cluster 63: tensor (773, 30, 23, 22), mask (773, 30, 23, 22)\n",
      "Cluster 64: tensor (773, 30, 23, 22), mask (773, 30, 23, 22)\n",
      "Cluster 65: tensor (773, 30, 25, 22), mask (773, 30, 25, 22)\n",
      "Cluster 66: tensor (773, 30, 25, 22), mask (773, 30, 25, 22)\n",
      "Cluster 67: tensor (773, 30, 23, 22), mask (773, 30, 23, 22)\n",
      "Cluster 68: tensor (773, 30, 20, 22), mask (773, 30, 20, 22)\n",
      "Cluster 69: tensor (773, 30, 21, 22), mask (773, 30, 21, 22)\n",
      "Cluster 70: tensor (773, 30, 20, 22), mask (773, 30, 20, 22)\n",
      "Cluster 71: tensor (773, 30, 19, 22), mask (773, 30, 19, 22)\n",
      "Cluster 72: tensor (773, 30, 19, 22), mask (773, 30, 19, 22)\n",
      "Cluster 73: tensor (773, 30, 17, 22), mask (773, 30, 17, 22)\n",
      "Cluster 74: tensor (773, 30, 20, 22), mask (773, 30, 20, 22)\n",
      "Cluster 75: tensor (773, 30, 15, 22), mask (773, 30, 15, 22)\n",
      "Cluster 76: tensor (773, 30, 13, 22), mask (773, 30, 13, 22)\n",
      "Cluster 77: tensor (773, 30, 13, 22), mask (773, 30, 13, 22)\n",
      "Cluster 78: tensor (773, 30, 12, 22), mask (773, 30, 12, 22)\n",
      "Cluster 79: tensor (773, 30, 13, 22), mask (773, 30, 13, 22)\n",
      "Cluster 80: tensor (773, 30, 12, 22), mask (773, 30, 12, 22)\n",
      "Cluster 81: tensor (773, 30, 13, 22), mask (773, 30, 13, 22)\n",
      "Cluster 82: tensor (773, 30, 14, 22), mask (773, 30, 14, 22)\n",
      "Cluster 83: tensor (773, 30, 11, 22), mask (773, 30, 11, 22)\n",
      "Cluster 84: tensor (773, 30, 10, 22), mask (773, 30, 10, 22)\n",
      "Cluster 85: tensor (773, 30, 11, 22), mask (773, 30, 11, 22)\n",
      "Cluster 86: tensor (773, 30, 10, 22), mask (773, 30, 10, 22)\n",
      "Cluster 87: tensor (773, 30, 10, 22), mask (773, 30, 10, 22)\n",
      "Cluster 88: tensor (773, 30, 10, 22), mask (773, 30, 10, 22)\n",
      "Cluster 89: tensor (773, 30, 9, 22), mask (773, 30, 9, 22)\n",
      "Cluster 90: tensor (773, 30, 9, 22), mask (773, 30, 9, 22)\n",
      "Cluster 91: tensor (773, 30, 7, 22), mask (773, 30, 7, 22)\n",
      "Cluster 92: tensor (773, 30, 8, 22), mask (773, 30, 8, 22)\n",
      "Cluster 93: tensor (773, 30, 7, 22), mask (773, 30, 7, 22)\n",
      "Cluster 94: tensor (773, 30, 5, 22), mask (773, 30, 5, 22)\n",
      "Cluster 95: tensor (773, 30, 6, 22), mask (773, 30, 6, 22)\n",
      "Cluster 96: tensor (773, 30, 5, 22), mask (773, 30, 5, 22)\n",
      "Cluster 97: tensor (773, 30, 4, 22), mask (773, 30, 4, 22)\n",
      "Cluster 98: tensor (773, 30, 4, 22), mask (773, 30, 4, 22)\n",
      "Cluster 99: tensor (773, 30, 4, 22), mask (773, 30, 4, 22)\n",
      "Cluster 100: tensor (773, 30, 4, 22), mask (773, 30, 4, 22)\n",
      "Cluster 101: tensor (773, 30, 5, 22), mask (773, 30, 5, 22)\n",
      "Cluster 102: tensor (773, 30, 6, 22), mask (773, 30, 6, 22)\n",
      "Cluster 103: tensor (773, 30, 5, 22), mask (773, 30, 5, 22)\n",
      "Cluster 104: tensor (773, 30, 4, 22), mask (773, 30, 4, 22)\n",
      "Cluster 105: tensor (773, 30, 3, 22), mask (773, 30, 3, 22)\n",
      "Cluster 106: tensor (773, 30, 5, 22), mask (773, 30, 5, 22)\n",
      "Cluster 107: tensor (773, 30, 3, 22), mask (773, 30, 3, 22)\n",
      "Cluster 108: tensor (773, 30, 2, 22), mask (773, 30, 2, 22)\n",
      "Cluster 109: tensor (773, 30, 2, 22), mask (773, 30, 2, 22)\n",
      "Cluster 110: tensor (773, 30, 2, 22), mask (773, 30, 2, 22)\n",
      "Cluster 111: tensor (773, 30, 2, 22), mask (773, 30, 2, 22)\n",
      "Cluster 112: tensor (773, 30, 3, 22), mask (773, 30, 3, 22)\n",
      "Cluster 113: tensor (773, 30, 2, 22), mask (773, 30, 2, 22)\n",
      "Cluster 114: tensor (773, 30, 2, 22), mask (773, 30, 2, 22)\n",
      "Cluster 115: tensor (773, 30, 1, 22), mask (773, 30, 1, 22)\n",
      "Cluster 116: tensor (773, 30, 1, 22), mask (773, 30, 1, 22)\n",
      "Cluster 117: tensor (773, 30, 1, 22), mask (773, 30, 1, 22)\n",
      "Cluster 118: tensor (773, 30, 1, 22), mask (773, 30, 1, 22)\n",
      "Cluster 119: tensor (773, 30, 1, 22), mask (773, 30, 1, 22)\n",
      "Cluster 120: tensor (773, 30, 1, 22), mask (773, 30, 1, 22)\n",
      "Cluster 121: tensor (773, 30, 1, 22), mask (773, 30, 1, 22)\n",
      "Cluster 122: tensor (773, 30, 1, 22), mask (773, 30, 1, 22)\n",
      "Cluster 123: tensor (773, 30, 1, 22), mask (773, 30, 1, 22)\n",
      "Cluster 124: tensor (773, 30, 1, 22), mask (773, 30, 1, 22)\n",
      "Cluster 125: tensor (773, 30, 1, 22), mask (773, 30, 1, 22)\n",
      "Cluster 126: tensor (773, 30, 1, 22), mask (773, 30, 1, 22)\n",
      "Cluster 127: tensor (773, 30, 1, 22), mask (773, 30, 1, 22)\n",
      "Cluster 128: tensor (773, 30, 2, 22), mask (773, 30, 2, 22)\n",
      "Cluster 129: tensor (773, 30, 1, 22), mask (773, 30, 1, 22)\n",
      "Cluster 130: tensor (773, 30, 1, 22), mask (773, 30, 1, 22)\n",
      "Cluster 131: tensor (773, 30, 1, 22), mask (773, 30, 1, 22)\n",
      "Cluster 132: tensor (773, 30, 1, 22), mask (773, 30, 1, 22)\n",
      "Cluster 133: tensor (773, 30, 1, 22), mask (773, 30, 1, 22)\n",
      "Cluster 134: tensor (773, 30, 1, 22), mask (773, 30, 1, 22)\n",
      "Cluster 135: tensor (773, 30, 1, 22), mask (773, 30, 1, 22)\n",
      "Cluster 136: tensor (761, 30, 1, 22), mask (761, 30, 1, 22)\n",
      "Cluster 137: tensor (773, 30, 1, 22), mask (773, 30, 1, 22)\n"
     ]
    }
   ],
   "source": [
    "# Block 7 — Tạo tensor dữ liệu cho A3C (per-cluster) kèm mask matrix\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "LOOKBACK = 30  # số ngày lookback\n",
    "tensors, masks = {}, {}\n",
    "\n",
    "# --- Lặp qua từng cluster ---\n",
    "for c_id, g in df_clusters.groupby(\"cluster\"):\n",
    "    if c_id == -1:   # DBSCAN noise bỏ qua\n",
    "        continue\n",
    "\n",
    "    tickers = g[\"ticker\"].unique()\n",
    "    g_feat = df_features[df_features[\"ticker\"].isin(tickers)].copy()\n",
    "\n",
    "    # Pivot (timestamp, ticker) -> feature matrix\n",
    "    pivoted = g_feat.pivot(index=\"timestamp\", columns=\"ticker\", values=feature_cols)\n",
    "\n",
    "    # Mask: 1 nếu dữ liệu thật, 0 nếu NaN\n",
    "    mask_df = ~pivoted.isna()\n",
    "\n",
    "    # Fill NaN để reshape được (dữ liệu dùng cho X, mask giữ sự thật)\n",
    "    pivoted_filled = pivoted.ffill().bfill()\n",
    "\n",
    "    T = len(pivoted_filled.index)\n",
    "    N = len(pivoted_filled.columns) // len(feature_cols)\n",
    "    F = len(feature_cols)\n",
    "\n",
    "    # Reshape thành (T, N, F)\n",
    "    X = pivoted_filled.values.reshape(T, N, F)\n",
    "    M = mask_df.values.reshape(T, N, F).astype(int)\n",
    "\n",
    "    # Rolling windows (LOOKBACK, N, F)\n",
    "    cluster_tensors, cluster_masks = [], []\n",
    "    for i in range(LOOKBACK, T):\n",
    "        cluster_tensors.append(X[i-LOOKBACK:i])\n",
    "        cluster_masks.append(M[i-LOOKBACK:i])\n",
    "\n",
    "    if cluster_tensors:\n",
    "        tensors[c_id] = np.array(cluster_tensors)\n",
    "        masks[c_id]   = np.array(cluster_masks)\n",
    "\n",
    "        print(f\"Cluster {c_id}: tensor {tensors[c_id].shape}, mask {masks[c_id].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1f4c40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 8 — A3C multi-stock per-cluster (theo nghiên cứu)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# --- Actor-Critic network ---\n",
    "class A3CClusterNet(nn.Module):\n",
    "    def __init__(self, n_stocks, n_features, hidden_size=64):\n",
    "        super().__init__()\n",
    "        self.n_stocks = n_stocks\n",
    "        self.n_features = n_features\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # LSTM để xử lý chuỗi (T steps)\n",
    "        self.lstm = nn.LSTM(input_size=n_features,\n",
    "                            hidden_size=hidden_size,\n",
    "                            batch_first=True)\n",
    "\n",
    "        # Actor: chính sách per-stock (3 actions: -1, 0, 1)\n",
    "        self.actor_head = nn.Linear(hidden_size, 3)\n",
    "\n",
    "        # Critic: giá trị per-stock\n",
    "        self.critic_head = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x shape = (batch, T, N, F)\n",
    "        \"\"\"\n",
    "        B, T, N, F = x.shape\n",
    "\n",
    "        # Reshape để đưa qua LSTM: (B*N, T, F)\n",
    "        x = x.view(B * N, T, F)\n",
    "\n",
    "        lstm_out, _ = self.lstm(x)   # (B*N, T, H)\n",
    "        h = lstm_out[:, -1, :]       # lấy hidden state cuối (B*N, H)\n",
    "\n",
    "        # Actor logits\n",
    "        policy_logits = self.actor_head(h)    # (B*N, 3)\n",
    "        policy_logits = policy_logits.view(B, N, 3)\n",
    "\n",
    "        # Critic values\n",
    "        values = self.critic_head(h)          # (B*N, 1)\n",
    "        values = values.view(B, N)\n",
    "\n",
    "        return policy_logits, values\n",
    "\n",
    "\n",
    "# --- Loss function ---\n",
    "def a3c_loss(policy_logits, values, actions, rewards, gamma=0.99, entropy_beta=0.01):\n",
    "    \"\"\"\n",
    "    policy_logits: (B, N, 3)\n",
    "    values:        (B, N)\n",
    "    actions:       (B, N)   # đã chọn (-1,0,1) mapped thành (0,1,2)\n",
    "    rewards:       (B, N)\n",
    "    \"\"\"\n",
    "    B, N, _ = policy_logits.shape\n",
    "\n",
    "    # --- Critic loss (TD error) ---\n",
    "    returns = rewards  # ở đây đơn giản reward = return, có thể mở rộng TD(lambda)\n",
    "    advantage = returns - values\n",
    "\n",
    "    critic_loss = advantage.pow(2).mean()\n",
    "\n",
    "    # --- Actor loss ---\n",
    "    log_probs = torch.log_softmax(policy_logits, dim=-1)\n",
    "    act_idx = actions.view(B, N, 1)\n",
    "    chosen_log_probs = log_probs.gather(-1, act_idx).squeeze(-1)\n",
    "\n",
    "    actor_loss = -(chosen_log_probs * advantage.detach()).mean()\n",
    "\n",
    "    # --- Entropy (exploration bonus) ---\n",
    "    entropy = -(torch.softmax(policy_logits, dim=-1) * log_probs).sum(-1).mean()\n",
    "\n",
    "    total_loss = actor_loss + 0.5 * critic_loss - entropy_beta * entropy\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "# --- Ví dụ huấn luyện 1 bước ---\n",
    "def train_step(model, optimizer, batch_x, batch_actions, batch_rewards):\n",
    "    policy_logits, values = model(batch_x)\n",
    "    loss = a3c_loss(policy_logits, values, batch_actions, batch_rewards)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c354048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block 9 — DDPG cho phân bổ vốn theo cụm\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "\n",
    "# ------------------------------\n",
    "# Env: Cluster Allocation\n",
    "# ------------------------------\n",
    "class ClusterAllocEnv(gym.Env):\n",
    "    def __init__(self, df_clusters, cluster_features, transaction_cost=0.0005, lam=0.1):\n",
    "        super().__init__()\n",
    "        self.df = df_clusters\n",
    "        self.cluster_features = cluster_features\n",
    "        self.transaction_cost = transaction_cost\n",
    "        self.lam = lam\n",
    "\n",
    "        self.cluster_ids = sorted(self.df[\"cluster\"].unique())\n",
    "        self.n_clusters = len(self.cluster_ids)\n",
    "        self.t_steps = sorted(self.df[\"timestamp\"].unique())\n",
    "        self.current_step = 0\n",
    "\n",
    "        # Action = phân bổ vốn [0,1], continuous\n",
    "        self.action_space = gym.spaces.Box(low=0, high=1, shape=(self.n_clusters,), dtype=np.float32)\n",
    "        # State = vector đặc trưng per-cluster\n",
    "        self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, \n",
    "                                                shape=(self.n_clusters, len(cluster_features)),\n",
    "                                                dtype=np.float32)\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        return self._get_state()\n",
    "\n",
    "    def step(self, action):\n",
    "        # Normalize action để tổng = 1\n",
    "        w = np.clip(action, 0, 1)\n",
    "        w = w / (w.sum() + 1e-8)\n",
    "\n",
    "        # Lấy returns và FA score từ ngày hiện tại\n",
    "        state = self._get_state()\n",
    "        returns = self._get_returns()\n",
    "        fa_score = self._get_fa_score()\n",
    "\n",
    "        # Reward = w·returns – cost + λ*fa_score\n",
    "        reward = np.dot(w, returns) - self.transaction_cost * np.sum(np.abs(np.diff(w))) + self.lam * np.dot(w, fa_score)\n",
    "\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.t_steps) - 1\n",
    "        next_state = self._get_state() if not done else np.zeros_like(state)\n",
    "\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def _get_state(self):\n",
    "        t = self.t_steps[self.current_step]\n",
    "        g = self.df[self.df[\"timestamp\"] == t]\n",
    "        state = []\n",
    "        for c in self.cluster_ids:\n",
    "            sub = g[g[\"cluster\"] == c]\n",
    "            if sub.empty:\n",
    "                state.append(np.zeros(len(self.cluster_features)))\n",
    "            else:\n",
    "                state.append(sub[self.cluster_features].mean().values)\n",
    "        return np.array(state, dtype=np.float32)\n",
    "\n",
    "    def _get_returns(self):\n",
    "        # Ví dụ: lấy return trung bình trong cluster\n",
    "        t = self.t_steps[self.current_step]\n",
    "        g = self.df[self.df[\"timestamp\"] == t]\n",
    "        returns = []\n",
    "        for c in self.cluster_ids:\n",
    "            sub = g[g[\"cluster\"] == c]\n",
    "            if \"return\" in sub.columns and not sub.empty:\n",
    "                returns.append(sub[\"return\"].mean())\n",
    "            else:\n",
    "                returns.append(0.0)\n",
    "        return np.array(returns, dtype=np.float32)\n",
    "\n",
    "    def _get_fa_score(self):\n",
    "        t = self.t_steps[self.current_step]\n",
    "        g = self.df[self.df[\"timestamp\"] == t]\n",
    "        scores = []\n",
    "        for c in self.cluster_ids:\n",
    "            sub = g[g[\"cluster\"] == c]\n",
    "            if \"ROE\" in sub.columns and not sub.empty:\n",
    "                scores.append(sub[\"ROE\"].mean())\n",
    "            else:\n",
    "                scores.append(0.0)\n",
    "        return np.array(scores, dtype=np.float32)\n",
    "\n",
    "# ------------------------------\n",
    "# DDPG Agent\n",
    "# ------------------------------\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, n_clusters, hidden=64):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(n_clusters*10, hidden),  # giả định mỗi cluster có 10 features\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, n_clusters),\n",
    "            nn.Softmax(dim=-1)   # để đảm bảo sum = 1\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.fc(x.view(x.size(0), -1))\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, n_clusters, hidden=64):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(n_clusters*10 + n_clusters, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, 1)\n",
    "        )\n",
    "    def forward(self, state, action):\n",
    "        x = torch.cat([state.view(state.size(0), -1), action], dim=-1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# ------------------------------\n",
    "# Training skeleton\n",
    "# ------------------------------\n",
    "def ddpg_train(env, actor, critic, episodes=10):\n",
    "    optimizerA = optim.Adam(actor.parameters(), lr=1e-3)\n",
    "    optimizerC = optim.Adam(critic.parameters(), lr=1e-3)\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        state = env.reset()\n",
    "        state = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "\n",
    "        while not done:\n",
    "            with torch.no_grad():\n",
    "                action = actor(state).squeeze(0).numpy()\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            next_state = torch.tensor(next_state, dtype=torch.float32).unsqueeze(0)\n",
    "            reward_t = torch.tensor([reward], dtype=torch.float32)\n",
    "\n",
    "            # Critic loss\n",
    "            q_val = critic(state, torch.tensor(action, dtype=torch.float32).unsqueeze(0))\n",
    "            target = reward_t\n",
    "            lossC = (q_val - target.detach()).pow(2).mean()\n",
    "\n",
    "            optimizerC.zero_grad()\n",
    "            lossC.backward()\n",
    "            optimizerC.step()\n",
    "\n",
    "            # Actor loss (maximize Q)\n",
    "            pred_action = actor(state)\n",
    "            lossA = -critic(state, pred_action).mean()\n",
    "\n",
    "            optimizerA.zero_grad()\n",
    "            lossA.backward()\n",
    "            optimizerA.step()\n",
    "\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "\n",
    "        print(f\"Episode {ep}, total reward {total_reward:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75f0e6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã build 138 models A3C cho 138 clusters\n"
     ]
    }
   ],
   "source": [
    "# Block X — Build models_a3c cho tất cả clusters (sau Block 7 + Block 8)\n",
    "\n",
    "models_a3c = {}\n",
    "\n",
    "for cid, X in tensors.items():\n",
    "    _, T, N, F = X.shape   # batch_size, lookback, n_stocks, n_features\n",
    "    \n",
    "    # Tạo model cho cluster này\n",
    "    model = A3CClusterNet(n_stocks=N, n_features=F)\n",
    "    models_a3c[cid] = model\n",
    "\n",
    "print(f\"✅ Đã build {len(models_a3c)} models A3C cho {len(tensors)} clusters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6b95acb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 12\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Đảm bảo model A3C cho từng cluster đã có trong models_a3c\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# models_a3c[cid] = A3CClusterNet(...)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m all_signals \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cid, X_all \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtensors\u001b[49m\u001b[38;5;241m.\u001b[39mitems():  \u001b[38;5;66;03m# từ Block 7\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cid \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m models_a3c:\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⚠️ Chưa có model cho cluster \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, bỏ qua.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tensors' is not defined"
     ]
    }
   ],
   "source": [
    "# Block Export A3C Signals — Safe Memory Version\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "# Đảm bảo model A3C cho từng cluster đã có trong models_a3c\n",
    "# models_a3c[cid] = A3CClusterNet(...)\n",
    "\n",
    "all_signals = []\n",
    "\n",
    "for cid, X_all in tensors.items():  # từ Block 7\n",
    "    if cid not in models_a3c:\n",
    "        print(f\"⚠️ Chưa có model cho cluster {cid}, bỏ qua.\")\n",
    "        continue\n",
    "\n",
    "    model = models_a3c[cid]\n",
    "    model.eval()\n",
    "\n",
    "    # (T, LOOKBACK, N, F)\n",
    "    T, L, N, F = X_all.shape\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for t in range(T):\n",
    "            X_batch = torch.tensor(X_all[t:t+1], dtype=torch.float32)  # (1, L, N, F)\n",
    "\n",
    "            # Forward\n",
    "            policy_logits, _ = model(X_batch)\n",
    "            probs = torch.softmax(policy_logits, dim=-1)  # (1, N, 3)\n",
    "\n",
    "            # Chọn action\n",
    "            actions = torch.argmax(probs, dim=-1).squeeze(0).cpu().numpy()  # (N,)\n",
    "            actions = actions - 1  # map [0,1,2] -> [-1,0,1]\n",
    "\n",
    "            # Lưu kết quả\n",
    "            all_signals.append({\n",
    "                \"cluster\": cid,\n",
    "                \"t_index\": t,\n",
    "                \"signals\": actions.tolist()\n",
    "            })\n",
    "\n",
    "            # Giải phóng batch để tránh tràn RAM\n",
    "            del X_batch, policy_logits, probs, actions\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "df_signals_a3c = pd.DataFrame(all_signals)\n",
    "print(\"✅ Export xong A3C signals, shape:\", df_signals_a3c.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be09b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Tham số ---\n",
    "INIT_CAPITAL = 1_000_000_000   # 1 tỷ VND\n",
    "TRANSACTION_COST = 0.0005      # 0.05%\n",
    "\n",
    "def backtest(df_clusters, signals_a3c, weights_ddpg, df_price):\n",
    "    capital = INIT_CAPITAL\n",
    "    portfolio_value = []\n",
    "    positions = {}   # {ticker: số lượng cổ phiếu đang nắm giữ}\n",
    "\n",
    "    # sort ngày\n",
    "    all_days = sorted(df_clusters[\"timestamp\"].unique())\n",
    "\n",
    "    for t in range(len(all_days)-1):  \n",
    "        day = all_days[t]\n",
    "        next_day = all_days[t+1]\n",
    "\n",
    "        # --- 1. Lấy signals ---\n",
    "        signals_today = signals_a3c.get(day, {})\n",
    "        weights_today = weights_ddpg.get(day, {})\n",
    "\n",
    "        # --- 2. Cluster mapping ---\n",
    "        today_clusters = df_clusters[df_clusters[\"timestamp\"] == day][[\"ticker\",\"cluster\"]]\n",
    "        cluster_map = dict(zip(today_clusters[\"ticker\"], today_clusters[\"cluster\"]))\n",
    "\n",
    "        # --- 3. Tính vốn phân bổ theo cluster ---\n",
    "        cluster_alloc = {c: capital * w for c, w in weights_today.items()}\n",
    "\n",
    "        # --- 4. Xử lý lệnh mua/bán ---\n",
    "        # clear positions theo signals -1\n",
    "        for ticker, sig in signals_today.items():\n",
    "            if sig == -1 and ticker in positions:\n",
    "                # bán hết ở giá close\n",
    "                price = df_price.loc[(df_price[\"ticker\"]==ticker) & (df_price[\"timestamp\"]==day), \"close\"]\n",
    "                if not price.empty:\n",
    "                    capital += positions[ticker] * float(price.iloc[0]) * (1 - TRANSACTION_COST)\n",
    "                    del positions[ticker]\n",
    "\n",
    "        # mở vị thế long theo signals +1\n",
    "        for ticker, sig in signals_today.items():\n",
    "            if sig == 1:\n",
    "                cluster = cluster_map.get(ticker, None)\n",
    "                if cluster is None: \n",
    "                    continue\n",
    "                price = df_price.loc[(df_price[\"ticker\"]==ticker) & (df_price[\"timestamp\"]==day), \"close\"]\n",
    "                if price.empty: \n",
    "                    continue\n",
    "                price = float(price.iloc[0])\n",
    "\n",
    "                # vốn chia đều cho các cổ phiếu long trong cluster\n",
    "                n_long = sum(1 for tk,s in signals_today.items() if s==1 and cluster_map.get(tk)==cluster)\n",
    "                if n_long == 0: \n",
    "                    continue\n",
    "\n",
    "                alloc = cluster_alloc.get(cluster, 0) / n_long\n",
    "                n_shares = alloc // price\n",
    "                if n_shares > 0:\n",
    "                    cost = n_shares * price * (1 + TRANSACTION_COST)\n",
    "                    if capital >= cost:\n",
    "                        capital -= cost\n",
    "                        positions[ticker] = positions.get(ticker, 0) + n_shares\n",
    "\n",
    "        # --- 5. Đánh giá NAV cuối ngày ---\n",
    "        value = capital\n",
    "        for ticker, qty in positions.items():\n",
    "            price = df_price.loc[(df_price[\"ticker\"]==ticker) & (df_price[\"timestamp\"]==day), \"close\"]\n",
    "            if not price.empty:\n",
    "                value += qty * float(price.iloc[0])\n",
    "        portfolio_value.append({\"date\": day, \"nav\": value})\n",
    "\n",
    "    df_nav = pd.DataFrame(portfolio_value)\n",
    "    return df_nav\n",
    "\n",
    "\n",
    "# --- Ví dụ chạy thử ---\n",
    "# df_nav = backtest(df_clusters, signals_a3c, weights_ddpg, df_all)\n",
    "# print(df_nav.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
